{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabpfn\n",
      "  Using cached tabpfn-0.1.10-py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /root/.cache/pypoetry/virtualenvs/aquamind-3o0A5rGC-py3.10/lib/python3.10/site-packages (from tabpfn) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /root/.cache/pypoetry/virtualenvs/aquamind-3o0A5rGC-py3.10/lib/python3.10/site-packages (from tabpfn) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /root/.cache/pypoetry/virtualenvs/aquamind-3o0A5rGC-py3.10/lib/python3.10/site-packages (from tabpfn) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /root/.cache/pypoetry/virtualenvs/aquamind-3o0A5rGC-py3.10/lib/python3.10/site-packages (from tabpfn) (1.4.1.post1)\n",
      "Collecting torch>=1.9.0 (from tabpfn)\n",
      "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/755.5 MB\u001b[0m \u001b[31m60.7 kB/s\u001b[0m eta \u001b[36m3:27:01\u001b[0m^C\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/755.5 MB\u001b[0m \u001b[31m61.0 kB/s\u001b[0m eta \u001b[36m3:25:42\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tabpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Using cached optuna-3.5.0-py3-none-any.whl (413 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Using cached alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Using cached colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: numpy in /root/.cache/pypoetry/virtualenvs/aquamind-3o0A5rGC-py3.10/lib/python3.10/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.cache/pypoetry/virtualenvs/aquamind-3o0A5rGC-py3.10/lib/python3.10/site-packages (from optuna) (23.2)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.27-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/3.1 MB\u001b[0m \u001b[31m53.1 kB/s\u001b[0m eta \u001b[36m0:00:50\u001b[0m^C\n",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/3.1 MB\u001b[0m \u001b[31m53.1 kB/s\u001b[0m eta \u001b[36m0:00:50\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28044/1038826202.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sweetviz as sv\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import optuna\n",
    "# from tabpfn import TabPFNClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_domain = pd.read_csv(\"../data/dataset.csv\")\n",
    "data_img = pd.read_csv(\"../data/features(1).csv\")\n",
    "data_domain_valid = pd.read_csv(\"../data/dataset_valid.csv\")\n",
    "data_img_valid = pd.read_csv(\"../data/features_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data_domain, data_img, on=\"id\", how=\"inner\")\n",
    "data_valid = pd.merge(data_domain_valid, data_img_valid, on=\"id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'latitude_min', 'longitude_min', 'latitude_max', 'longitude_max',\n",
       "       'sand', 'coral_algae', 'rock', 'seagrass', 'microalgal_mats', 'rubble',\n",
       "       'sand_rate', 'coral_algae_rate', 'rock_rate', 'seagrass_rate',\n",
       "       'microalgal_mats_rate', 'rubble_rate', 'seagrass_overlap', 'r_sum',\n",
       "       'r_mean', 'r_var', 'g_sum', 'g_mean', 'g_var', 'b_sum', 'b_mean',\n",
       "       'b_var', 'hog_sum', 'hog_mean', 'hog_var', 'sift_sum', 'sift_mean',\n",
       "       'sift_var'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_location = ['latitude_min', 'longitude_min', 'latitude_max', 'longitude_max']\n",
    "columns_base = ['sand', 'coral_algae', 'rock', 'seagrass', 'microalgal_mats', 'rubble']\n",
    "columns_rate = ['sand_rate', 'coral_algae_rate', 'rock_rate', 'seagrass_rate', 'microalgal_mats_rate', 'rubble_rate']\n",
    "columns_rgb = ['r_sum', 'r_mean', 'r_var', 'g_sum', 'g_mean', 'g_var', 'b_sum', 'b_mean', 'b_var', 'hog_sum']\n",
    "columns_hog = ['hog_sum', 'hog_mean', 'hog_var']\n",
    "columns_sift = ['sift_sum', 'sift_mean', 'sift_var']\n",
    "target = \"seagrass_overlap\"\n",
    "target_binary = \"target_binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target_binary'] = data[target].apply(lambda x: 0 if x == 0 else 1)\n",
    "data_valid['target_binary'] = data_valid[target].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリカル作成\n",
    "for col in ['sand', 'coral_algae', 'rock', 'seagrass', 'microalgal_mats', 'rubble']:\n",
    "    data[col + '_onehot'] = data[col].apply(lambda x: 1 if x == 1 else 0)\n",
    "for col in ['sand', 'coral_algae', 'rock', 'seagrass', 'microalgal_mats', 'rubble']:\n",
    "    data_valid[col + '_onehot'] = data_valid[col].apply(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 位置情報×ドメイン作成\n",
    "categories = ['seagrass', 'seagrass_rate', 'coral_algae', 'rock', 'microalgal_mats', 'rubble']\n",
    "for category in categories:\n",
    "    data[f'latitude×{category}'] = ((data['latitude_min'] + data['latitude_max']) / 2) * data[category]\n",
    "    data[f'longitude×{category}'] = ((data['longitude_min'] + data['longitude_max']) / 2) * data[category]\n",
    "for category in categories:\n",
    "    data_valid[f'latitude×{category}'] = ((data_valid['latitude_min'] + data_valid['latitude_max']) / 2) * data_valid[category]\n",
    "    data_valid[f'longitude×{category}'] = ((data_valid['longitude_min'] + data_valid['longitude_max']) / 2) * data_valid[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seagrass関係をexponentialize\n",
    "data['seagrass_exp'] = np.exp(data['seagrass'])\n",
    "data['seagrass_rate_exp'] = np.exp(data['seagrass_rate'])\n",
    "data_valid['seagrass_exp'] = np.exp(data_valid['seagrass'])\n",
    "data_valid['seagrass_rate_exp'] = np.exp(data_valid['seagrass_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 位置情報×画像\n",
    "features = ['r_mean', 'g_mean', 'b_mean', 'hog_mean', 'sift_mean']\n",
    "\n",
    "data['longitude_avg'] = (data['longitude_min'] + data['longitude_max']) / 2\n",
    "data['latitude_avg'] = (data['latitude_min'] + data['latitude_max']) / 2\n",
    "\n",
    "for feature in features:\n",
    "    data[f'longitude_avg×{feature}'] = data['longitude_avg'] * data[feature]\n",
    "    data[f'latitude_avg×{feature}'] = data['latitude_avg'] * data[feature]\n",
    "\n",
    "data_valid['longitude_avg'] = (data_valid['longitude_min'] + data_valid['longitude_max']) / 2\n",
    "data_valid['latitude_avg'] = (data_valid['latitude_min'] + data_valid['latitude_max']) / 2\n",
    "\n",
    "for feature in features:\n",
    "    data_valid[f'longitude_avg×{feature}'] = data_valid['longitude_avg'] * data_valid[feature]\n",
    "    data_valid[f'latitude_avg×{feature}'] = data_valid['latitude_avg'] * data_valid[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ドメイン×画像\n",
    "features = ['r_mean', 'g_mean', 'b_mean', 'hog_mean', 'sift_mean']\n",
    "categories = ['sand', 'coral_algae', 'rock', 'seagrass', 'microalgal_mats', 'rubble']\n",
    "\n",
    "for feature in features:\n",
    "    for category in categories:\n",
    "        new_column_name = f'{feature}×{category}'\n",
    "        data[new_column_name] = data[feature] * data[category]\n",
    "\n",
    "for feature in features:\n",
    "    for category in categories:\n",
    "        new_column_name = f'{feature}×{category}'\n",
    "        data_valid[new_column_name] = data_valid[feature] * data_valid[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_base = data[columns_base]\n",
    "X_data_base_valid = data_valid[columns_base]\n",
    "\n",
    "X_data_rate_img = data[columns_rate + columns_rgb + columns_hog + columns_sift]\n",
    "X_data_rate_img_valid = data_valid[columns_rate + columns_rgb + columns_hog + columns_sift]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 教師無しクラスタリング\n",
    "\n",
    "kmeans_3 = KMeans(n_clusters=3, random_state=0).fit(X_data_base)\n",
    "data['base_3'] = kmeans_3.labels_\n",
    "kmeans_3_valid = KMeans(n_clusters=3, random_state=0).fit(X_data_base_valid)\n",
    "data_valid['base_3'] = kmeans_3_valid.predict(X_data_base_valid)\n",
    "\n",
    "kmeans_5 = KMeans(n_clusters=5, random_state=0).fit(X_data_base)\n",
    "data['base_5'] = kmeans_5.labels_\n",
    "kmeans_5_valid = KMeans(n_clusters=5, random_state=0).fit(X_data_base_valid)\n",
    "data_valid['base_5'] = kmeans_5_valid.predict(X_data_base_valid)\n",
    "\n",
    "kmeans_5_ = KMeans(n_clusters=5, random_state=0).fit(X_data_rate_img)\n",
    "data['rate_img__5'] = kmeans_5_.labels_\n",
    "kmeans_5_valid_ = KMeans(n_clusters=5, random_state=0).fit(X_data_rate_img_valid)\n",
    "data_valid['rate_img_5'] = kmeans_5_valid_.predict(X_data_rate_img_valid)\n",
    "\n",
    "kmeans_7 = KMeans(n_clusters=7, random_state=0).fit(X_data_rate_img)\n",
    "data['rate_img_7'] = kmeans_7.labels_\n",
    "kmeans_7_valid = KMeans(n_clusters=7, random_state=0).fit(X_data_rate_img_valid)\n",
    "data_valid['rate_img_7'] = kmeans_7_valid.predict(X_data_rate_img_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'latitude_min', 'longitude_min', 'latitude_max', 'longitude_max',\n",
       "       'sand', 'coral_algae', 'rock', 'seagrass', 'microalgal_mats', 'rubble',\n",
       "       'sand_rate', 'coral_algae_rate', 'rock_rate', 'seagrass_rate',\n",
       "       'microalgal_mats_rate', 'rubble_rate', 'seagrass_overlap', 'r_sum',\n",
       "       'r_mean', 'r_var', 'g_sum', 'g_mean', 'g_var', 'b_sum', 'b_mean',\n",
       "       'b_var', 'hog_sum', 'hog_mean', 'hog_var', 'sift_sum', 'sift_mean',\n",
       "       'sift_var', 'target_binary', 'sand_onehot', 'coral_algae_onehot',\n",
       "       'rock_onehot', 'seagrass_onehot', 'microalgal_mats_onehot',\n",
       "       'rubble_onehot', 'latitude×seagrass', 'longitude×seagrass',\n",
       "       'latitude×seagrass_rate', 'longitude×seagrass_rate',\n",
       "       'latitude×coral_algae', 'longitude×coral_algae', 'latitude×rock',\n",
       "       'longitude×rock', 'latitude×microalgal_mats',\n",
       "       'longitude×microalgal_mats', 'latitude×rubble', 'longitude×rubble',\n",
       "       'seagrass_exp', 'seagrass_rate_exp', 'longitude_avg', 'latitude_avg',\n",
       "       'longitude_avg×r_mean', 'latitude_avg×r_mean', 'longitude_avg×g_mean',\n",
       "       'latitude_avg×g_mean', 'longitude_avg×b_mean', 'latitude_avg×b_mean',\n",
       "       'longitude_avg×hog_mean', 'latitude_avg×hog_mean',\n",
       "       'longitude_avg×sift_mean', 'latitude_avg×sift_mean', 'r_mean×sand',\n",
       "       'r_mean×coral_algae', 'r_mean×rock', 'r_mean×seagrass',\n",
       "       'r_mean×microalgal_mats', 'r_mean×rubble', 'g_mean×sand',\n",
       "       'g_mean×coral_algae', 'g_mean×rock', 'g_mean×seagrass',\n",
       "       'g_mean×microalgal_mats', 'g_mean×rubble', 'b_mean×sand',\n",
       "       'b_mean×coral_algae', 'b_mean×rock', 'b_mean×seagrass',\n",
       "       'b_mean×microalgal_mats', 'b_mean×rubble', 'hog_mean×sand',\n",
       "       'hog_mean×coral_algae', 'hog_mean×rock', 'hog_mean×seagrass',\n",
       "       'hog_mean×microalgal_mats', 'hog_mean×rubble', 'sift_mean×sand',\n",
       "       'sift_mean×coral_algae', 'sift_mean×rock', 'sift_mean×seagrass',\n",
       "       'sift_mean×microalgal_mats', 'sift_mean×rubble', 'base_3', 'base_5',\n",
       "       'rate_img_5', 'rate_img_7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_location = ['latitude_min', 'longitude_min', 'latitude_max', 'longitude_max']\n",
    "columns_base = ['sand', 'coral_algae', 'rock', 'seagrass', 'microalgal_mats', 'rubble']\n",
    "columns_rate = ['sand_rate', 'coral_algae_rate', 'rock_rate', 'seagrass_rate', 'microalgal_mats_rate', 'rubble_rate']\n",
    "columns_rgb = ['r_sum', 'r_mean', 'r_var', 'g_sum', 'g_mean', 'g_var', 'b_sum', 'b_mean', 'b_var', 'hog_sum']\n",
    "columns_hog = ['hog_sum', 'hog_mean', 'hog_var']\n",
    "columns_sift = ['sift_sum', 'sift_mean', 'sift_var']\n",
    "columns_onehot = ['sand_onehot', 'coral_algae_onehot', 'rock_onehot', 'seagrass_onehot', 'microalgal_mats_onehot', 'rubble_onehot']\n",
    "columns_loc_base = ['latitude×seagrass', 'longitude×seagrass', 'latitude×seagrass_rate', 'longitude×seagrass_rate', 'latitude×coral_algae', 'longitude×coral_algae', 'latitude×rock', 'longitude×rock', 'latitude×microalgal_mats', 'longitude×microalgal_mats', 'latitude×rubble', 'longitude×rubble']\n",
    "columns_exp = ['seagrass_exp', 'seagrass_rate_exp']\n",
    "columns_loc_img = ['longitude_avg×r_mean', 'latitude_avg×r_mean', 'longitude_avg×g_mean', 'latitude_avg×g_mean', 'longitude_avg×b_mean', 'latitude_avg×b_mean', 'longitude_avg×hog_mean', 'latitude_avg×hog_mean', 'longitude_avg×sift_mean', 'latitude_avg×sift_mean']\n",
    "columns_kmeans = ['base_3', 'base_5', 'rate_img_5', 'rate_img_7']\n",
    "target = \"seagrass_overlap\"\n",
    "target_binary = \"target_binary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics and Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    threshold: float,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    予測値と実際の値から混同行列を生成する関数。\n",
    "\n",
    "    引数:\n",
    "    - y_true: np.ndarray, テストデータセットの実際のクラスラベル。\n",
    "    - y_pred: np.ndarray, テストデータセットに対する予測確率。\n",
    "    - threshold: float, 予測確率をクラスラベルに変換するための閾値。\n",
    "\n",
    "    戻り値:\n",
    "    - np.ndarray: 生成された混同行列。\n",
    "    \"\"\"\n",
    "    y_pred_label = (y_pred >= threshold).astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred_label)\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_lightgbm_stratified_kfold(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    columns_feature: List[str],\n",
    "    target_binary: List[str],  # この実装では使用しないが、型情報を含める\n",
    "    param: Dict[str, any],\n",
    "    n_splits: int = 5,\n",
    ") -> Tuple[List[lgb.Booster], List[float]]:\n",
    "    \"\"\"\n",
    "    Stratified k-foldクロスバリデーションを使用してLightGBMモデルを訓練する関数。\n",
    "    非均衡データを考慮して、各クラスの割合を保持する。\n",
    "\n",
    "    引数:\n",
    "    - X: pandas DataFrame, 特徴量データ。\n",
    "    - y: pandas Series, 目的変数データ。\n",
    "    - columns_feature: list, 特徴量のカラム名のリスト。\n",
    "    - target_binary: list, 目的変数のカラム名のリスト（この関数では使用しないが、一貫性のために残す）。\n",
    "    - param: dict, LightGBMモデルのパラメータ。\n",
    "    - n_splits: int, クロスバリデーションの分割数。\n",
    "\n",
    "    戻り値:\n",
    "    - Tuple[List[lgb.Booster], List[float]]: 訓練済みLightGBMモデルのリストと各foldのlog lossスコアのリスト。\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    models: List[lgb.Booster] = []\n",
    "    scores: List[float] = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = (\n",
    "            X.iloc[train_index][columns_feature],\n",
    "            X.iloc[test_index][columns_feature],\n",
    "        )\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "        gbm: lgb.Booster = lgb.train(\n",
    "            param,\n",
    "            lgb_train,\n",
    "            valid_sets=[lgb_train, lgb_eval],\n",
    "        )\n",
    "\n",
    "        y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "        score: float = log_loss(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "        models.append(gbm)\n",
    "\n",
    "    return models, scores\n",
    "\n",
    "def predict_with_lightgbm(\n",
    "    models: List[lgb.Booster],\n",
    "    X_test: pd.DataFrame,\n",
    "    columns_feature: List[str]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    訓練済みLightGBMモデルのリストを使用してテストデータセットの予測を行う関数。\n",
    "\n",
    "    引数:\n",
    "    - models: List[lgb.Booster], 訓練済みLightGBMモデルのリスト。\n",
    "    - X_test: pandas DataFrame, テストデータセット。\n",
    "    - columns_feature: list, 特徴量のカラム名のリスト。\n",
    "\n",
    "    戻り値:\n",
    "    - np.ndarray: テストデータセットの予測値の平均値。\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        y_pred = model.predict(X_test[columns_feature], num_iteration=model.best_iteration)\n",
    "        predictions.append(y_pred)\n",
    "    \n",
    "    predictions_mean = np.mean(predictions, axis=0)\n",
    "    \n",
    "    return predictions_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lightgbm = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',  # 'multiclass' for multi-class classification\n",
    "    'metric': 'binary_logloss',  # 'multi_logloss' for multi-class classification\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lightgbm(trial, X, y, columns_feature, n_splits=5):\n",
    "    \"\"\"\n",
    "    Optunaの試行に対する目的関数。LightGBMのハイパーパラメータを探索する。\n",
    "\n",
    "    引数:\n",
    "    - trial: optuna.trial.Trial オブジェクト\n",
    "    - X, y: 訓練データ\n",
    "    - columns_feature: 特徴量のカラム名のリスト\n",
    "    - n_splits: クロスバリデーションの分割数\n",
    "\n",
    "    戻り値:\n",
    "    - 試行の平均log lossスコア\n",
    "    \"\"\"\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    _, scores = train_lightgbm_stratified_kfold(\n",
    "        X, y, columns_feature, [], param, n_splits\n",
    "    )\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def optimize_hyperparameters_lightgbm(\n",
    "    X, y, columns_feature, n_trials=100, n_splits=5, timeout=300\n",
    "):\n",
    "    \"\"\"\n",
    "    Optunaを使用してLightGBMモデルのハイパーパラメータを最適化する。\n",
    "\n",
    "    引数:\n",
    "    - X, y: 訓練データ\n",
    "    - columns_feature: 特徴量のカラム名のリスト\n",
    "    - n_trials: 試行回数の上限\n",
    "    - n_splits: クロスバリデーションの分割数\n",
    "    - timeout: 探索にかける時間の上限（秒）\n",
    "\n",
    "    戻り値:\n",
    "    - 最適なハイパーパラメータの辞書\n",
    "    \"\"\"\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(\n",
    "        lambda trial: objective_lightgbm(trial, X, y, columns_feature, n_splits),\n",
    "        n_trials=n_trials,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    print(f\"Best trial: {study.best_trial.value}\")\n",
    "    print(f\"Best params: {study.best_trial.params}\")\n",
    "\n",
    "    return study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 15:44:15,911] A new study created in memory with name: no-name-eb1abf46-b60a-4f5f-a0ef-03fc2fe9ec48\n",
      "/tmp/ipykernel_28044/141605296.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
      "/tmp/ipykernel_28044/141605296.py:23: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
      "[I 2024-02-24 15:44:28,750] Trial 0 finished with value: 0.16881344688513758 and parameters: {'lambda_l1': 8.070513415854402, 'lambda_l2': 3.0097415890185105e-08, 'num_leaves': 118, 'feature_fraction': 0.5601215141918066, 'bagging_fraction': 0.6856053509279036, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 0 with value: 0.16881344688513758.\n",
      "/tmp/ipykernel_28044/141605296.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
      "/tmp/ipykernel_28044/141605296.py:23: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
      "[I 2024-02-24 15:45:10,557] Trial 1 finished with value: 0.18129811798306908 and parameters: {'lambda_l1': 2.4263113783671917e-06, 'lambda_l2': 2.7002175867223345e-06, 'num_leaves': 166, 'feature_fraction': 0.4519617615092628, 'bagging_fraction': 0.6382194442358418, 'bagging_freq': 1, 'min_child_samples': 47}. Best is trial 0 with value: 0.16881344688513758.\n",
      "/tmp/ipykernel_28044/141605296.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
      "/tmp/ipykernel_28044/141605296.py:23: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
      "[I 2024-02-24 15:46:07,959] Trial 2 finished with value: 0.18742850229608066 and parameters: {'lambda_l1': 0.00024968345021464096, 'lambda_l2': 1.3722830939918498e-05, 'num_leaves': 39, 'feature_fraction': 0.8880857893791896, 'bagging_fraction': 0.9779336085187006, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 0 with value: 0.16881344688513758.\n",
      "/tmp/ipykernel_28044/141605296.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
      "/tmp/ipykernel_28044/141605296.py:23: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
      "[I 2024-02-24 15:47:23,608] Trial 3 finished with value: 0.1748044630143565 and parameters: {'lambda_l1': 0.18007844917976895, 'lambda_l2': 0.0016320984327780424, 'num_leaves': 139, 'feature_fraction': 0.5220799947394478, 'bagging_fraction': 0.6203197279893768, 'bagging_freq': 4, 'min_child_samples': 82}. Best is trial 0 with value: 0.16881344688513758.\n",
      "/tmp/ipykernel_28044/141605296.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
      "/tmp/ipykernel_28044/141605296.py:23: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
      "[I 2024-02-24 15:48:07,904] Trial 4 finished with value: 0.17429894605165744 and parameters: {'lambda_l1': 0.008152837346167839, 'lambda_l2': 3.624508066116009, 'num_leaves': 173, 'feature_fraction': 0.925140758304635, 'bagging_fraction': 0.6934715077581064, 'bagging_freq': 2, 'min_child_samples': 57}. Best is trial 0 with value: 0.16881344688513758.\n",
      "/tmp/ipykernel_28044/141605296.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
      "/tmp/ipykernel_28044/141605296.py:23: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
      "[I 2024-02-24 15:48:46,582] Trial 5 finished with value: 0.18054351167045785 and parameters: {'lambda_l1': 2.2095326127879232e-07, 'lambda_l2': 3.4494824355365634e-08, 'num_leaves': 37, 'feature_fraction': 0.9315745835930408, 'bagging_fraction': 0.5631607273825454, 'bagging_freq': 5, 'min_child_samples': 81}. Best is trial 0 with value: 0.16881344688513758.\n",
      "/tmp/ipykernel_28044/141605296.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
      "/tmp/ipykernel_28044/141605296.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
      "/tmp/ipykernel_28044/141605296.py:23: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
      "[I 2024-02-24 15:49:59,702] Trial 6 finished with value: 0.21283091639016516 and parameters: {'lambda_l1': 0.014810245913705958, 'lambda_l2': 0.010725271175675611, 'num_leaves': 252, 'feature_fraction': 0.7534559091026938, 'bagging_fraction': 0.5669532552812977, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 0 with value: 0.16881344688513758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0.16881344688513758\n",
      "Best params: {'lambda_l1': 8.070513415854402, 'lambda_l2': 3.0097415890185105e-08, 'num_leaves': 118, 'feature_fraction': 0.5601215141918066, 'bagging_fraction': 0.6856053509279036, 'bagging_freq': 4, 'min_child_samples': 24}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lambda_l1': 8.070513415854402,\n",
       " 'lambda_l2': 3.0097415890185105e-08,\n",
       " 'num_leaves': 118,\n",
       " 'feature_fraction': 0.5601215141918066,\n",
       " 'bagging_fraction': 0.6856053509279036,\n",
       " 'bagging_freq': 4,\n",
       " 'min_child_samples': 24}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_hyperparameters_lightgbm(data_valid[columns_base], data_valid[target_binary], columns_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_lightgbm, scores_lightgbm = train_lightgbm_stratified_kfold(X, y, columns_base, target_binary, params_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lightgbm = predict_with_lightgbm(models_lightgbm, X_test, columns_base)\n",
    "y_true = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_true, bins=20, alpha=0.75, edgecolor='black')\n",
    "plt.title('Predicted Probability Distribution')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_lightgbm, bins=20, alpha=0.75, edgecolor='black')\n",
    "plt.title('Predicted Probability Distribution')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1762,    3],\n",
       "       [ 137,    0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_confusion_matrix(y_true, y_pred_lightgbm, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_stratified_kfold(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    columns_feature: List[str],\n",
    "    target_binary: List[str],  # この実装では使用しないが、型情報を含める\n",
    "    param: Dict[str, any],\n",
    "    n_splits: int = 5,\n",
    ") -> Tuple[List[xgb.Booster], List[float]]:\n",
    "    \"\"\"\n",
    "    Stratified k-foldクロスバリデーションを使用してXGBoostモデルを訓練する関数。\n",
    "    非均衡データを考慮して、各クラスの割合を保持する。\n",
    "\n",
    "    引数:\n",
    "    - X: pandas DataFrame, 特徴量データ。\n",
    "    - y: pandas Series, 目的変数データ。\n",
    "    - columns_feature: list, 特徴量のカラム名のリスト。\n",
    "    - target_binary: list, 目的変数のカラム名のリスト（この関数では使用しないが、一貫性のために残す）。\n",
    "    - param: dict, XGBoostモデルのパラメータ。\n",
    "    - n_splits: int, クロスバリデーションの分割数。\n",
    "\n",
    "    戻り値:\n",
    "    - Tuple[List[xgb.Booster], List[float]]: 訓練済みXGBoostモデルのリストと各foldのlog lossスコアのリスト。\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    models: List[xgb.Booster] = []\n",
    "    scores: List[float] = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = (\n",
    "            X.iloc[train_index][columns_feature],\n",
    "            X.iloc[test_index][columns_feature],\n",
    "        )\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "        bst: xgb.Booster = xgb.train(\n",
    "            param,\n",
    "            dtrain,\n",
    "            num_boost_round=param.get(\"num_boost_round\", 100),\n",
    "            evals=[(dtrain, \"train\"), (dtest, \"eval\")],\n",
    "            # early_stopping_rounds=param.get(\"early_stopping_rounds\", 10),\n",
    "            # verbose_eval=param.get(\"verbose_eval\", 50),\n",
    "        )\n",
    "\n",
    "        y_pred = bst.predict(dtest)\n",
    "        score: float = log_loss(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "        models.append(bst)\n",
    "\n",
    "    return models, scores\n",
    "\n",
    "\n",
    "def predict_with_xgboost(models: List[xgb.Booster], X_test: pd.DataFrame, columns_feature: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    訓練済みXGBoostモデルのリストを使用してテストデータセットの予測を行う関数。\n",
    "\n",
    "    引数:\n",
    "    - models: List[xgb.Booster], 訓練済みXGBoostモデルのリスト。\n",
    "    - X_test: pandas DataFrame, テストデータセット。\n",
    "    - columns_feature: list, 特徴量のカラム名のリスト。\n",
    "\n",
    "    戻り値:\n",
    "    - np.ndarray: テストデータセットの予測値の平均値。\n",
    "    \"\"\"\n",
    "    # 各モデルからの予測値を格納するリスト\n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        dtest = xgb.DMatrix(X_test[columns_feature])\n",
    "        y_pred = model.predict(dtest)\n",
    "        predictions.append(y_pred)\n",
    "    \n",
    "    # 予測値の平均を計算\n",
    "    predictions_mean = np.mean(predictions, axis=0)\n",
    "    \n",
    "    return predictions_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgboost(trial, X, y, columns_feature, n_splits=5):\n",
    "    \"\"\"\n",
    "    Optunaの試行に対する目的関数。XGBoostのハイパーパラメータを探索する。\n",
    "\n",
    "    引数:\n",
    "    - trial: optuna.trial.Trial オブジェクト\n",
    "    - X, y: 訓練データ\n",
    "    - columns_feature: 特徴量のカラム名のリスト\n",
    "    - n_splits: クロスバリデーションの分割数\n",
    "\n",
    "    戻り値:\n",
    "    - 試行の平均log lossスコア\n",
    "    \"\"\"\n",
    "    param = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"eta\": trial.suggest_loguniform(\"eta\", 1e-3, 0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-3, 10.0),\n",
    "        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-3, 10.0),\n",
    "    }\n",
    "\n",
    "    _, scores = train_xgboost_stratified_kfold(\n",
    "        X, y, columns_feature, [], param, n_splits\n",
    "    )\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def optimize_hyperparameters_xgboost(\n",
    "    X, y, columns_feature, n_trials=100, n_splits=5, timeout=300\n",
    "):\n",
    "    \"\"\"\n",
    "    Optunaを使用してXGBoostモデルのハイパーパラメータを最適化する。\n",
    "\n",
    "    引数:\n",
    "    - X, y: 訓練データ\n",
    "    - columns_feature: 特徴量のカラム名のリスト\n",
    "    - n_trials: 試行回数の上限\n",
    "    - n_splits: クロスバリデーションの分割数\n",
    "    - timeout: 探索にかける時間の上限（秒）\n",
    "\n",
    "    戻り値:\n",
    "    - 最適なハイパーパラメータの辞書\n",
    "    \"\"\"\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(\n",
    "        lambda trial: objective_xgboost(trial, X, y, columns_feature, n_splits),\n",
    "        n_trials=n_trials,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    print(f\"Best trial: {study.best_trial.value}\")\n",
    "    print(f\"Best params: {study.best_trial.params}\")\n",
    "\n",
    "    return study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 15:59:22,628] A new study created in memory with name: no-name-ac4986c7-6d46-4f07-9ff7-a9e8a1115b70\n",
      "/tmp/ipykernel_28044/3574405256.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"eta\": trial.suggest_loguniform(\"eta\", 1e-3, 0.1),\n",
      "/tmp/ipykernel_28044/3574405256.py:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.6, 1.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.6, 1.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-3, 10.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-3, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.28929\teval-logloss:0.28931\n",
      "[1]\ttrain-logloss:0.28896\teval-logloss:0.28899\n",
      "[2]\ttrain-logloss:0.28860\teval-logloss:0.28865\n",
      "[3]\ttrain-logloss:0.28827\teval-logloss:0.28835\n",
      "[4]\ttrain-logloss:0.28792\teval-logloss:0.28803\n",
      "[5]\ttrain-logloss:0.28757\teval-logloss:0.28772\n",
      "[6]\ttrain-logloss:0.28724\teval-logloss:0.28740\n",
      "[7]\ttrain-logloss:0.28694\teval-logloss:0.28713\n",
      "[8]\ttrain-logloss:0.28661\teval-logloss:0.28682\n",
      "[9]\ttrain-logloss:0.28630\teval-logloss:0.28652\n",
      "[10]\ttrain-logloss:0.28598\teval-logloss:0.28623\n",
      "[11]\ttrain-logloss:0.28569\teval-logloss:0.28596\n",
      "[12]\ttrain-logloss:0.28538\teval-logloss:0.28568\n",
      "[13]\ttrain-logloss:0.28504\teval-logloss:0.28537\n",
      "[14]\ttrain-logloss:0.28475\teval-logloss:0.28511\n",
      "[15]\ttrain-logloss:0.28447\teval-logloss:0.28483\n",
      "[16]\ttrain-logloss:0.28419\teval-logloss:0.28458\n",
      "[17]\ttrain-logloss:0.28386\teval-logloss:0.28428\n",
      "[18]\ttrain-logloss:0.28359\teval-logloss:0.28403\n",
      "[19]\ttrain-logloss:0.28327\teval-logloss:0.28374\n",
      "[20]\ttrain-logloss:0.28300\teval-logloss:0.28350\n",
      "[21]\ttrain-logloss:0.28270\teval-logloss:0.28322\n",
      "[22]\ttrain-logloss:0.28238\teval-logloss:0.28291\n",
      "[23]\ttrain-logloss:0.28207\teval-logloss:0.28264\n",
      "[24]\ttrain-logloss:0.28176\teval-logloss:0.28236\n",
      "[25]\ttrain-logloss:0.28147\teval-logloss:0.28210\n",
      "[26]\ttrain-logloss:0.28117\teval-logloss:0.28185\n",
      "[27]\ttrain-logloss:0.28088\teval-logloss:0.28157\n",
      "[28]\ttrain-logloss:0.28058\teval-logloss:0.28130\n",
      "[29]\ttrain-logloss:0.28028\teval-logloss:0.28104\n",
      "[30]\ttrain-logloss:0.27998\teval-logloss:0.28076\n",
      "[31]\ttrain-logloss:0.27973\teval-logloss:0.28054\n",
      "[32]\ttrain-logloss:0.27943\teval-logloss:0.28028\n",
      "[33]\ttrain-logloss:0.27913\teval-logloss:0.28002\n",
      "[34]\ttrain-logloss:0.27884\teval-logloss:0.27975\n",
      "[35]\ttrain-logloss:0.27856\teval-logloss:0.27949\n",
      "[36]\ttrain-logloss:0.27827\teval-logloss:0.27923\n",
      "[37]\ttrain-logloss:0.27801\teval-logloss:0.27900\n",
      "[38]\ttrain-logloss:0.27772\teval-logloss:0.27874\n",
      "[39]\ttrain-logloss:0.27745\teval-logloss:0.27847\n",
      "[40]\ttrain-logloss:0.27717\teval-logloss:0.27822\n",
      "[41]\ttrain-logloss:0.27688\teval-logloss:0.27797\n",
      "[42]\ttrain-logloss:0.27660\teval-logloss:0.27771\n",
      "[43]\ttrain-logloss:0.27633\teval-logloss:0.27747\n",
      "[44]\ttrain-logloss:0.27606\teval-logloss:0.27722\n",
      "[45]\ttrain-logloss:0.27579\teval-logloss:0.27698\n",
      "[46]\ttrain-logloss:0.27554\teval-logloss:0.27673\n",
      "[47]\ttrain-logloss:0.27528\teval-logloss:0.27650\n",
      "[48]\ttrain-logloss:0.27502\teval-logloss:0.27627\n",
      "[49]\ttrain-logloss:0.27475\teval-logloss:0.27603\n",
      "[50]\ttrain-logloss:0.27448\teval-logloss:0.27580\n",
      "[51]\ttrain-logloss:0.27426\teval-logloss:0.27559\n",
      "[52]\ttrain-logloss:0.27401\teval-logloss:0.27538\n",
      "[53]\ttrain-logloss:0.27379\teval-logloss:0.27519\n",
      "[54]\ttrain-logloss:0.27354\teval-logloss:0.27496\n",
      "[55]\ttrain-logloss:0.27330\teval-logloss:0.27474\n",
      "[56]\ttrain-logloss:0.27305\teval-logloss:0.27453\n",
      "[57]\ttrain-logloss:0.27281\teval-logloss:0.27432\n",
      "[58]\ttrain-logloss:0.27256\teval-logloss:0.27410\n",
      "[59]\ttrain-logloss:0.27235\teval-logloss:0.27391\n",
      "[60]\ttrain-logloss:0.27212\teval-logloss:0.27370\n",
      "[61]\ttrain-logloss:0.27188\teval-logloss:0.27347\n",
      "[62]\ttrain-logloss:0.27166\teval-logloss:0.27328\n",
      "[63]\ttrain-logloss:0.27142\teval-logloss:0.27305\n",
      "[64]\ttrain-logloss:0.27118\teval-logloss:0.27284\n",
      "[65]\ttrain-logloss:0.27094\teval-logloss:0.27263\n",
      "[66]\ttrain-logloss:0.27071\teval-logloss:0.27242\n",
      "[67]\ttrain-logloss:0.27051\teval-logloss:0.27223\n",
      "[68]\ttrain-logloss:0.27031\teval-logloss:0.27205\n",
      "[69]\ttrain-logloss:0.27008\teval-logloss:0.27184\n",
      "[70]\ttrain-logloss:0.26990\teval-logloss:0.27168\n",
      "[71]\ttrain-logloss:0.26967\teval-logloss:0.27148\n",
      "[72]\ttrain-logloss:0.26944\teval-logloss:0.27129\n",
      "[73]\ttrain-logloss:0.26926\teval-logloss:0.27113\n",
      "[74]\ttrain-logloss:0.26906\teval-logloss:0.27095\n",
      "[75]\ttrain-logloss:0.26886\teval-logloss:0.27079\n",
      "[76]\ttrain-logloss:0.26863\teval-logloss:0.27059\n",
      "[77]\ttrain-logloss:0.26842\teval-logloss:0.27039\n",
      "[78]\ttrain-logloss:0.26821\teval-logloss:0.27021\n",
      "[79]\ttrain-logloss:0.26802\teval-logloss:0.27004\n",
      "[80]\ttrain-logloss:0.26781\teval-logloss:0.26985\n",
      "[81]\ttrain-logloss:0.26761\teval-logloss:0.26968\n",
      "[82]\ttrain-logloss:0.26739\teval-logloss:0.26951\n",
      "[83]\ttrain-logloss:0.26718\teval-logloss:0.26932\n",
      "[84]\ttrain-logloss:0.26696\teval-logloss:0.26912\n",
      "[85]\ttrain-logloss:0.26676\teval-logloss:0.26895\n",
      "[86]\ttrain-logloss:0.26654\teval-logloss:0.26876\n",
      "[87]\ttrain-logloss:0.26635\teval-logloss:0.26860\n",
      "[88]\ttrain-logloss:0.26616\teval-logloss:0.26843\n",
      "[89]\ttrain-logloss:0.26595\teval-logloss:0.26825\n",
      "[90]\ttrain-logloss:0.26575\teval-logloss:0.26807\n",
      "[91]\ttrain-logloss:0.26554\teval-logloss:0.26790\n",
      "[92]\ttrain-logloss:0.26535\teval-logloss:0.26773\n",
      "[93]\ttrain-logloss:0.26516\teval-logloss:0.26756\n",
      "[94]\ttrain-logloss:0.26498\teval-logloss:0.26741\n",
      "[95]\ttrain-logloss:0.26478\teval-logloss:0.26722\n",
      "[96]\ttrain-logloss:0.26458\teval-logloss:0.26706\n",
      "[97]\ttrain-logloss:0.26439\teval-logloss:0.26690\n",
      "[98]\ttrain-logloss:0.26420\teval-logloss:0.26674\n",
      "[99]\ttrain-logloss:0.26399\teval-logloss:0.26658\n",
      "[0]\ttrain-logloss:0.28927\teval-logloss:0.28929\n",
      "[1]\ttrain-logloss:0.28894\teval-logloss:0.28897\n",
      "[2]\ttrain-logloss:0.28860\teval-logloss:0.28866\n",
      "[3]\ttrain-logloss:0.28827\teval-logloss:0.28835\n",
      "[4]\ttrain-logloss:0.28794\teval-logloss:0.28803\n",
      "[5]\ttrain-logloss:0.28759\teval-logloss:0.28772\n",
      "[6]\ttrain-logloss:0.28725\teval-logloss:0.28739\n",
      "[7]\ttrain-logloss:0.28694\teval-logloss:0.28712\n",
      "[8]\ttrain-logloss:0.28661\teval-logloss:0.28681\n",
      "[9]\ttrain-logloss:0.28628\teval-logloss:0.28652\n",
      "[10]\ttrain-logloss:0.28597\teval-logloss:0.28623\n",
      "[11]\ttrain-logloss:0.28567\teval-logloss:0.28595\n",
      "[12]\ttrain-logloss:0.28536\teval-logloss:0.28568\n",
      "[13]\ttrain-logloss:0.28503\teval-logloss:0.28537\n",
      "[14]\ttrain-logloss:0.28474\teval-logloss:0.28512\n",
      "[15]\ttrain-logloss:0.28446\teval-logloss:0.28487\n",
      "[16]\ttrain-logloss:0.28417\teval-logloss:0.28462\n",
      "[17]\ttrain-logloss:0.28386\teval-logloss:0.28433\n",
      "[18]\ttrain-logloss:0.28358\teval-logloss:0.28408\n",
      "[19]\ttrain-logloss:0.28327\teval-logloss:0.28380\n",
      "[20]\ttrain-logloss:0.28299\teval-logloss:0.28355\n",
      "[21]\ttrain-logloss:0.28267\teval-logloss:0.28327\n",
      "[22]\ttrain-logloss:0.28237\teval-logloss:0.28298\n",
      "[23]\ttrain-logloss:0.28206\teval-logloss:0.28270\n",
      "[24]\ttrain-logloss:0.28176\teval-logloss:0.28242\n",
      "[25]\ttrain-logloss:0.28147\teval-logloss:0.28215\n",
      "[26]\ttrain-logloss:0.28119\teval-logloss:0.28191\n",
      "[27]\ttrain-logloss:0.28088\teval-logloss:0.28164\n",
      "[28]\ttrain-logloss:0.28058\teval-logloss:0.28137\n",
      "[29]\ttrain-logloss:0.28028\teval-logloss:0.28108\n",
      "[30]\ttrain-logloss:0.27999\teval-logloss:0.28084\n",
      "[31]\ttrain-logloss:0.27973\teval-logloss:0.28061\n",
      "[32]\ttrain-logloss:0.27944\teval-logloss:0.28035\n",
      "[33]\ttrain-logloss:0.27915\teval-logloss:0.28008\n",
      "[34]\ttrain-logloss:0.27887\teval-logloss:0.27983\n",
      "[35]\ttrain-logloss:0.27860\teval-logloss:0.27958\n",
      "[36]\ttrain-logloss:0.27832\teval-logloss:0.27932\n",
      "[37]\ttrain-logloss:0.27805\teval-logloss:0.27910\n",
      "[38]\ttrain-logloss:0.27778\teval-logloss:0.27885\n",
      "[39]\ttrain-logloss:0.27750\teval-logloss:0.27860\n",
      "[40]\ttrain-logloss:0.27723\teval-logloss:0.27835\n",
      "[41]\ttrain-logloss:0.27695\teval-logloss:0.27811\n",
      "[42]\ttrain-logloss:0.27668\teval-logloss:0.27786\n",
      "[43]\ttrain-logloss:0.27641\teval-logloss:0.27763\n",
      "[44]\ttrain-logloss:0.27615\teval-logloss:0.27740\n",
      "[45]\ttrain-logloss:0.27589\teval-logloss:0.27715\n",
      "[46]\ttrain-logloss:0.27564\teval-logloss:0.27693\n",
      "[47]\ttrain-logloss:0.27537\teval-logloss:0.27670\n",
      "[48]\ttrain-logloss:0.27512\teval-logloss:0.27646\n",
      "[49]\ttrain-logloss:0.27485\teval-logloss:0.27621\n",
      "[50]\ttrain-logloss:0.27459\teval-logloss:0.27598\n",
      "[51]\ttrain-logloss:0.27436\teval-logloss:0.27577\n",
      "[52]\ttrain-logloss:0.27411\teval-logloss:0.27556\n",
      "[53]\ttrain-logloss:0.27389\teval-logloss:0.27538\n",
      "[54]\ttrain-logloss:0.27364\teval-logloss:0.27516\n",
      "[55]\ttrain-logloss:0.27339\teval-logloss:0.27495\n",
      "[56]\ttrain-logloss:0.27315\teval-logloss:0.27474\n",
      "[57]\ttrain-logloss:0.27292\teval-logloss:0.27452\n",
      "[58]\ttrain-logloss:0.27268\teval-logloss:0.27430\n",
      "[59]\ttrain-logloss:0.27246\teval-logloss:0.27411\n",
      "[60]\ttrain-logloss:0.27223\teval-logloss:0.27390\n",
      "[61]\ttrain-logloss:0.27199\teval-logloss:0.27371\n",
      "[62]\ttrain-logloss:0.27177\teval-logloss:0.27351\n",
      "[63]\ttrain-logloss:0.27153\teval-logloss:0.27330\n",
      "[64]\ttrain-logloss:0.27130\teval-logloss:0.27310\n",
      "[65]\ttrain-logloss:0.27107\teval-logloss:0.27290\n",
      "[66]\ttrain-logloss:0.27084\teval-logloss:0.27270\n",
      "[67]\ttrain-logloss:0.27063\teval-logloss:0.27252\n",
      "[68]\ttrain-logloss:0.27044\teval-logloss:0.27234\n",
      "[69]\ttrain-logloss:0.27021\teval-logloss:0.27216\n",
      "[70]\ttrain-logloss:0.27001\teval-logloss:0.27201\n",
      "[71]\ttrain-logloss:0.26979\teval-logloss:0.27184\n",
      "[72]\ttrain-logloss:0.26956\teval-logloss:0.27163\n",
      "[73]\ttrain-logloss:0.26936\teval-logloss:0.27146\n",
      "[74]\ttrain-logloss:0.26915\teval-logloss:0.27128\n",
      "[75]\ttrain-logloss:0.26895\teval-logloss:0.27111\n",
      "[76]\ttrain-logloss:0.26874\teval-logloss:0.27094\n",
      "[77]\ttrain-logloss:0.26852\teval-logloss:0.27075\n",
      "[78]\ttrain-logloss:0.26830\teval-logloss:0.27056\n",
      "[79]\ttrain-logloss:0.26812\teval-logloss:0.27041\n",
      "[80]\ttrain-logloss:0.26791\teval-logloss:0.27025\n",
      "[81]\ttrain-logloss:0.26771\teval-logloss:0.27007\n",
      "[82]\ttrain-logloss:0.26750\teval-logloss:0.26989\n",
      "[83]\ttrain-logloss:0.26730\teval-logloss:0.26971\n",
      "[84]\ttrain-logloss:0.26709\teval-logloss:0.26952\n",
      "[85]\ttrain-logloss:0.26688\teval-logloss:0.26935\n",
      "[86]\ttrain-logloss:0.26667\teval-logloss:0.26916\n",
      "[87]\ttrain-logloss:0.26646\teval-logloss:0.26899\n",
      "[88]\ttrain-logloss:0.26626\teval-logloss:0.26882\n",
      "[89]\ttrain-logloss:0.26606\teval-logloss:0.26864\n",
      "[90]\ttrain-logloss:0.26587\teval-logloss:0.26847\n",
      "[91]\ttrain-logloss:0.26567\teval-logloss:0.26830\n",
      "[92]\ttrain-logloss:0.26546\teval-logloss:0.26812\n",
      "[93]\ttrain-logloss:0.26526\teval-logloss:0.26795\n",
      "[94]\ttrain-logloss:0.26508\teval-logloss:0.26781\n",
      "[95]\ttrain-logloss:0.26489\teval-logloss:0.26765\n",
      "[96]\ttrain-logloss:0.26469\teval-logloss:0.26745\n",
      "[97]\ttrain-logloss:0.26449\teval-logloss:0.26728\n",
      "[98]\ttrain-logloss:0.26430\teval-logloss:0.26712\n",
      "[99]\ttrain-logloss:0.26410\teval-logloss:0.26696\n",
      "[0]\ttrain-logloss:0.28927\teval-logloss:0.28929\n",
      "[1]\ttrain-logloss:0.28893\teval-logloss:0.28900\n",
      "[2]\ttrain-logloss:0.28856\teval-logloss:0.28868\n",
      "[3]\ttrain-logloss:0.28820\teval-logloss:0.28839\n",
      "[4]\ttrain-logloss:0.28786\teval-logloss:0.28808\n",
      "[5]\ttrain-logloss:0.28752\teval-logloss:0.28779\n",
      "[6]\ttrain-logloss:0.28717\teval-logloss:0.28750\n",
      "[7]\ttrain-logloss:0.28687\teval-logloss:0.28723\n",
      "[8]\ttrain-logloss:0.28653\teval-logloss:0.28694\n",
      "[9]\ttrain-logloss:0.28622\teval-logloss:0.28668\n",
      "[10]\ttrain-logloss:0.28588\teval-logloss:0.28639\n",
      "[11]\ttrain-logloss:0.28559\teval-logloss:0.28613\n",
      "[12]\ttrain-logloss:0.28526\teval-logloss:0.28586\n",
      "[13]\ttrain-logloss:0.28492\teval-logloss:0.28558\n",
      "[14]\ttrain-logloss:0.28465\teval-logloss:0.28533\n",
      "[15]\ttrain-logloss:0.28435\teval-logloss:0.28505\n",
      "[16]\ttrain-logloss:0.28407\teval-logloss:0.28479\n",
      "[17]\ttrain-logloss:0.28375\teval-logloss:0.28452\n",
      "[18]\ttrain-logloss:0.28347\teval-logloss:0.28426\n",
      "[19]\ttrain-logloss:0.28315\teval-logloss:0.28399\n",
      "[20]\ttrain-logloss:0.28286\teval-logloss:0.28375\n",
      "[21]\ttrain-logloss:0.28253\teval-logloss:0.28346\n",
      "[22]\ttrain-logloss:0.28222\teval-logloss:0.28320\n",
      "[23]\ttrain-logloss:0.28191\teval-logloss:0.28293\n",
      "[24]\ttrain-logloss:0.28159\teval-logloss:0.28268\n",
      "[25]\ttrain-logloss:0.28130\teval-logloss:0.28243\n",
      "[26]\ttrain-logloss:0.28101\teval-logloss:0.28220\n",
      "[27]\ttrain-logloss:0.28070\teval-logloss:0.28194\n",
      "[28]\ttrain-logloss:0.28040\teval-logloss:0.28170\n",
      "[29]\ttrain-logloss:0.28011\teval-logloss:0.28145\n",
      "[30]\ttrain-logloss:0.27980\teval-logloss:0.28119\n",
      "[31]\ttrain-logloss:0.27954\teval-logloss:0.28095\n",
      "[32]\ttrain-logloss:0.27924\teval-logloss:0.28071\n",
      "[33]\ttrain-logloss:0.27894\teval-logloss:0.28046\n",
      "[34]\ttrain-logloss:0.27865\teval-logloss:0.28021\n",
      "[35]\ttrain-logloss:0.27837\teval-logloss:0.27997\n",
      "[36]\ttrain-logloss:0.27808\teval-logloss:0.27974\n",
      "[37]\ttrain-logloss:0.27779\teval-logloss:0.27950\n",
      "[38]\ttrain-logloss:0.27749\teval-logloss:0.27926\n",
      "[39]\ttrain-logloss:0.27722\teval-logloss:0.27902\n",
      "[40]\ttrain-logloss:0.27693\teval-logloss:0.27880\n",
      "[41]\ttrain-logloss:0.27666\teval-logloss:0.27858\n",
      "[42]\ttrain-logloss:0.27637\teval-logloss:0.27833\n",
      "[43]\ttrain-logloss:0.27609\teval-logloss:0.27810\n",
      "[44]\ttrain-logloss:0.27582\teval-logloss:0.27788\n",
      "[45]\ttrain-logloss:0.27555\teval-logloss:0.27767\n",
      "[46]\ttrain-logloss:0.27528\teval-logloss:0.27744\n",
      "[47]\ttrain-logloss:0.27501\teval-logloss:0.27720\n",
      "[48]\ttrain-logloss:0.27475\teval-logloss:0.27699\n",
      "[49]\ttrain-logloss:0.27448\teval-logloss:0.27677\n",
      "[50]\ttrain-logloss:0.27422\teval-logloss:0.27656\n",
      "[51]\ttrain-logloss:0.27401\teval-logloss:0.27637\n",
      "[52]\ttrain-logloss:0.27376\teval-logloss:0.27616\n",
      "[53]\ttrain-logloss:0.27353\teval-logloss:0.27596\n",
      "[54]\ttrain-logloss:0.27328\teval-logloss:0.27575\n",
      "[55]\ttrain-logloss:0.27302\teval-logloss:0.27553\n",
      "[56]\ttrain-logloss:0.27277\teval-logloss:0.27533\n",
      "[57]\ttrain-logloss:0.27253\teval-logloss:0.27515\n",
      "[58]\ttrain-logloss:0.27228\teval-logloss:0.27495\n",
      "[59]\ttrain-logloss:0.27207\teval-logloss:0.27477\n",
      "[60]\ttrain-logloss:0.27183\teval-logloss:0.27458\n",
      "[61]\ttrain-logloss:0.27159\teval-logloss:0.27438\n",
      "[62]\ttrain-logloss:0.27136\teval-logloss:0.27420\n",
      "[63]\ttrain-logloss:0.27112\teval-logloss:0.27399\n",
      "[64]\ttrain-logloss:0.27088\teval-logloss:0.27379\n",
      "[65]\ttrain-logloss:0.27065\teval-logloss:0.27360\n",
      "[66]\ttrain-logloss:0.27041\teval-logloss:0.27341\n",
      "[67]\ttrain-logloss:0.27022\teval-logloss:0.27324\n",
      "[68]\ttrain-logloss:0.27002\teval-logloss:0.27307\n",
      "[69]\ttrain-logloss:0.26978\teval-logloss:0.27290\n",
      "[70]\ttrain-logloss:0.26959\teval-logloss:0.27273\n",
      "[71]\ttrain-logloss:0.26937\teval-logloss:0.27255\n",
      "[72]\ttrain-logloss:0.26914\teval-logloss:0.27237\n",
      "[73]\ttrain-logloss:0.26895\teval-logloss:0.27221\n",
      "[74]\ttrain-logloss:0.26874\teval-logloss:0.27204\n",
      "[75]\ttrain-logloss:0.26854\teval-logloss:0.27188\n",
      "[76]\ttrain-logloss:0.26830\teval-logloss:0.27169\n",
      "[77]\ttrain-logloss:0.26808\teval-logloss:0.27152\n",
      "[78]\ttrain-logloss:0.26786\teval-logloss:0.27135\n",
      "[79]\ttrain-logloss:0.26768\teval-logloss:0.27119\n",
      "[80]\ttrain-logloss:0.26746\teval-logloss:0.27103\n",
      "[81]\ttrain-logloss:0.26725\teval-logloss:0.27086\n",
      "[82]\ttrain-logloss:0.26702\teval-logloss:0.27069\n",
      "[83]\ttrain-logloss:0.26682\teval-logloss:0.27054\n",
      "[84]\ttrain-logloss:0.26661\teval-logloss:0.27038\n",
      "[85]\ttrain-logloss:0.26640\teval-logloss:0.27022\n",
      "[86]\ttrain-logloss:0.26619\teval-logloss:0.27005\n",
      "[87]\ttrain-logloss:0.26600\teval-logloss:0.26990\n",
      "[88]\ttrain-logloss:0.26580\teval-logloss:0.26974\n",
      "[89]\ttrain-logloss:0.26560\teval-logloss:0.26957\n",
      "[90]\ttrain-logloss:0.26539\teval-logloss:0.26942\n",
      "[91]\ttrain-logloss:0.26519\teval-logloss:0.26925\n",
      "[92]\ttrain-logloss:0.26498\teval-logloss:0.26909\n",
      "[93]\ttrain-logloss:0.26478\teval-logloss:0.26894\n",
      "[94]\ttrain-logloss:0.26460\teval-logloss:0.26878\n",
      "[95]\ttrain-logloss:0.26439\teval-logloss:0.26863\n",
      "[96]\ttrain-logloss:0.26418\teval-logloss:0.26846\n",
      "[97]\ttrain-logloss:0.26399\teval-logloss:0.26831\n",
      "[98]\ttrain-logloss:0.26379\teval-logloss:0.26816\n",
      "[99]\ttrain-logloss:0.26360\teval-logloss:0.26800\n",
      "[0]\ttrain-logloss:0.28927\teval-logloss:0.28929\n",
      "[1]\ttrain-logloss:0.28894\teval-logloss:0.28897\n",
      "[2]\ttrain-logloss:0.28860\teval-logloss:0.28864\n",
      "[3]\ttrain-logloss:0.28827\teval-logloss:0.28832\n",
      "[4]\ttrain-logloss:0.28792\teval-logloss:0.28801\n",
      "[5]\ttrain-logloss:0.28759\teval-logloss:0.28770\n",
      "[6]\ttrain-logloss:0.28723\teval-logloss:0.28737\n",
      "[7]\ttrain-logloss:0.28692\teval-logloss:0.28709\n",
      "[8]\ttrain-logloss:0.28658\teval-logloss:0.28677\n",
      "[9]\ttrain-logloss:0.28627\teval-logloss:0.28647\n",
      "[10]\ttrain-logloss:0.28596\teval-logloss:0.28617\n",
      "[11]\ttrain-logloss:0.28567\teval-logloss:0.28592\n",
      "[12]\ttrain-logloss:0.28537\teval-logloss:0.28562\n",
      "[13]\ttrain-logloss:0.28505\teval-logloss:0.28533\n",
      "[14]\ttrain-logloss:0.28476\teval-logloss:0.28507\n",
      "[15]\ttrain-logloss:0.28449\teval-logloss:0.28482\n",
      "[16]\ttrain-logloss:0.28421\teval-logloss:0.28457\n",
      "[17]\ttrain-logloss:0.28389\teval-logloss:0.28427\n",
      "[18]\ttrain-logloss:0.28360\teval-logloss:0.28401\n",
      "[19]\ttrain-logloss:0.28329\teval-logloss:0.28371\n",
      "[20]\ttrain-logloss:0.28301\teval-logloss:0.28346\n",
      "[21]\ttrain-logloss:0.28270\teval-logloss:0.28318\n",
      "[22]\ttrain-logloss:0.28240\teval-logloss:0.28290\n",
      "[23]\ttrain-logloss:0.28210\teval-logloss:0.28263\n",
      "[24]\ttrain-logloss:0.28180\teval-logloss:0.28236\n",
      "[25]\ttrain-logloss:0.28151\teval-logloss:0.28208\n",
      "[26]\ttrain-logloss:0.28123\teval-logloss:0.28181\n",
      "[27]\ttrain-logloss:0.28093\teval-logloss:0.28153\n",
      "[28]\ttrain-logloss:0.28063\teval-logloss:0.28126\n",
      "[29]\ttrain-logloss:0.28034\teval-logloss:0.28098\n",
      "[30]\ttrain-logloss:0.28005\teval-logloss:0.28070\n",
      "[31]\ttrain-logloss:0.27979\teval-logloss:0.28047\n",
      "[32]\ttrain-logloss:0.27949\teval-logloss:0.28020\n",
      "[33]\ttrain-logloss:0.27921\teval-logloss:0.27993\n",
      "[34]\ttrain-logloss:0.27892\teval-logloss:0.27967\n",
      "[35]\ttrain-logloss:0.27865\teval-logloss:0.27941\n",
      "[36]\ttrain-logloss:0.27836\teval-logloss:0.27915\n",
      "[37]\ttrain-logloss:0.27809\teval-logloss:0.27890\n",
      "[38]\ttrain-logloss:0.27781\teval-logloss:0.27864\n",
      "[39]\ttrain-logloss:0.27754\teval-logloss:0.27839\n",
      "[40]\ttrain-logloss:0.27726\teval-logloss:0.27815\n",
      "[41]\ttrain-logloss:0.27700\teval-logloss:0.27789\n",
      "[42]\ttrain-logloss:0.27674\teval-logloss:0.27765\n",
      "[43]\ttrain-logloss:0.27647\teval-logloss:0.27740\n",
      "[44]\ttrain-logloss:0.27620\teval-logloss:0.27715\n",
      "[45]\ttrain-logloss:0.27593\teval-logloss:0.27689\n",
      "[46]\ttrain-logloss:0.27567\teval-logloss:0.27664\n",
      "[47]\ttrain-logloss:0.27541\teval-logloss:0.27639\n",
      "[48]\ttrain-logloss:0.27514\teval-logloss:0.27615\n",
      "[49]\ttrain-logloss:0.27488\teval-logloss:0.27591\n",
      "[50]\ttrain-logloss:0.27463\teval-logloss:0.27568\n",
      "[51]\ttrain-logloss:0.27441\teval-logloss:0.27549\n",
      "[52]\ttrain-logloss:0.27417\teval-logloss:0.27527\n",
      "[53]\ttrain-logloss:0.27394\teval-logloss:0.27508\n",
      "[54]\ttrain-logloss:0.27370\teval-logloss:0.27485\n",
      "[55]\ttrain-logloss:0.27345\teval-logloss:0.27463\n",
      "[56]\ttrain-logloss:0.27320\teval-logloss:0.27439\n",
      "[57]\ttrain-logloss:0.27297\teval-logloss:0.27417\n",
      "[58]\ttrain-logloss:0.27273\teval-logloss:0.27395\n",
      "[59]\ttrain-logloss:0.27251\teval-logloss:0.27375\n",
      "[60]\ttrain-logloss:0.27228\teval-logloss:0.27352\n",
      "[61]\ttrain-logloss:0.27204\teval-logloss:0.27331\n",
      "[62]\ttrain-logloss:0.27183\teval-logloss:0.27312\n",
      "[63]\ttrain-logloss:0.27159\teval-logloss:0.27290\n",
      "[64]\ttrain-logloss:0.27136\teval-logloss:0.27268\n",
      "[65]\ttrain-logloss:0.27113\teval-logloss:0.27247\n",
      "[66]\ttrain-logloss:0.27089\teval-logloss:0.27225\n",
      "[67]\ttrain-logloss:0.27068\teval-logloss:0.27208\n",
      "[68]\ttrain-logloss:0.27047\teval-logloss:0.27191\n",
      "[69]\ttrain-logloss:0.27025\teval-logloss:0.27171\n",
      "[70]\ttrain-logloss:0.27005\teval-logloss:0.27152\n",
      "[71]\ttrain-logloss:0.26983\teval-logloss:0.27132\n",
      "[72]\ttrain-logloss:0.26961\teval-logloss:0.27112\n",
      "[73]\ttrain-logloss:0.26941\teval-logloss:0.27097\n",
      "[74]\ttrain-logloss:0.26919\teval-logloss:0.27076\n",
      "[75]\ttrain-logloss:0.26899\teval-logloss:0.27059\n",
      "[76]\ttrain-logloss:0.26878\teval-logloss:0.27039\n",
      "[77]\ttrain-logloss:0.26856\teval-logloss:0.27020\n",
      "[78]\ttrain-logloss:0.26836\teval-logloss:0.26999\n",
      "[79]\ttrain-logloss:0.26817\teval-logloss:0.26982\n",
      "[80]\ttrain-logloss:0.26796\teval-logloss:0.26963\n",
      "[81]\ttrain-logloss:0.26776\teval-logloss:0.26944\n",
      "[82]\ttrain-logloss:0.26755\teval-logloss:0.26926\n",
      "[83]\ttrain-logloss:0.26734\teval-logloss:0.26907\n",
      "[84]\ttrain-logloss:0.26713\teval-logloss:0.26888\n",
      "[85]\ttrain-logloss:0.26692\teval-logloss:0.26868\n",
      "[86]\ttrain-logloss:0.26671\teval-logloss:0.26851\n",
      "[87]\ttrain-logloss:0.26653\teval-logloss:0.26833\n",
      "[88]\ttrain-logloss:0.26633\teval-logloss:0.26814\n",
      "[89]\ttrain-logloss:0.26613\teval-logloss:0.26795\n",
      "[90]\ttrain-logloss:0.26592\teval-logloss:0.26777\n",
      "[91]\ttrain-logloss:0.26572\teval-logloss:0.26759\n",
      "[92]\ttrain-logloss:0.26553\teval-logloss:0.26743\n",
      "[93]\ttrain-logloss:0.26533\teval-logloss:0.26724\n",
      "[94]\ttrain-logloss:0.26515\teval-logloss:0.26710\n",
      "[95]\ttrain-logloss:0.26495\teval-logloss:0.26693\n",
      "[96]\ttrain-logloss:0.26476\teval-logloss:0.26677\n",
      "[97]\ttrain-logloss:0.26457\teval-logloss:0.26659\n",
      "[98]\ttrain-logloss:0.26439\teval-logloss:0.26642\n",
      "[99]\ttrain-logloss:0.26420\teval-logloss:0.26625\n",
      "[0]\ttrain-logloss:0.28926\teval-logloss:0.28937\n",
      "[1]\ttrain-logloss:0.28894\teval-logloss:0.28906\n",
      "[2]\ttrain-logloss:0.28860\teval-logloss:0.28874\n",
      "[3]\ttrain-logloss:0.28827\teval-logloss:0.28845\n",
      "[4]\ttrain-logloss:0.28793\teval-logloss:0.28814\n",
      "[5]\ttrain-logloss:0.28759\teval-logloss:0.28782\n",
      "[6]\ttrain-logloss:0.28726\teval-logloss:0.28751\n",
      "[7]\ttrain-logloss:0.28695\teval-logloss:0.28723\n",
      "[8]\ttrain-logloss:0.28661\teval-logloss:0.28690\n",
      "[9]\ttrain-logloss:0.28630\teval-logloss:0.28663\n",
      "[10]\ttrain-logloss:0.28598\teval-logloss:0.28635\n",
      "[11]\ttrain-logloss:0.28568\teval-logloss:0.28608\n",
      "[12]\ttrain-logloss:0.28537\teval-logloss:0.28580\n",
      "[13]\ttrain-logloss:0.28504\teval-logloss:0.28549\n",
      "[14]\ttrain-logloss:0.28475\teval-logloss:0.28523\n",
      "[15]\ttrain-logloss:0.28446\teval-logloss:0.28497\n",
      "[16]\ttrain-logloss:0.28417\teval-logloss:0.28471\n",
      "[17]\ttrain-logloss:0.28387\teval-logloss:0.28442\n",
      "[18]\ttrain-logloss:0.28358\teval-logloss:0.28415\n",
      "[19]\ttrain-logloss:0.28325\teval-logloss:0.28386\n",
      "[20]\ttrain-logloss:0.28296\teval-logloss:0.28361\n",
      "[21]\ttrain-logloss:0.28264\teval-logloss:0.28332\n",
      "[22]\ttrain-logloss:0.28233\teval-logloss:0.28303\n",
      "[23]\ttrain-logloss:0.28203\teval-logloss:0.28275\n",
      "[24]\ttrain-logloss:0.28174\teval-logloss:0.28246\n",
      "[25]\ttrain-logloss:0.28146\teval-logloss:0.28221\n",
      "[26]\ttrain-logloss:0.28119\teval-logloss:0.28197\n",
      "[27]\ttrain-logloss:0.28088\teval-logloss:0.28168\n",
      "[28]\ttrain-logloss:0.28057\teval-logloss:0.28141\n",
      "[29]\ttrain-logloss:0.28026\teval-logloss:0.28114\n",
      "[30]\ttrain-logloss:0.27997\teval-logloss:0.28088\n",
      "[31]\ttrain-logloss:0.27970\teval-logloss:0.28065\n",
      "[32]\ttrain-logloss:0.27940\teval-logloss:0.28039\n",
      "[33]\ttrain-logloss:0.27912\teval-logloss:0.28014\n",
      "[34]\ttrain-logloss:0.27883\teval-logloss:0.27989\n",
      "[35]\ttrain-logloss:0.27854\teval-logloss:0.27962\n",
      "[36]\ttrain-logloss:0.27826\teval-logloss:0.27937\n",
      "[37]\ttrain-logloss:0.27798\teval-logloss:0.27913\n",
      "[38]\ttrain-logloss:0.27770\teval-logloss:0.27886\n",
      "[39]\ttrain-logloss:0.27743\teval-logloss:0.27862\n",
      "[40]\ttrain-logloss:0.27716\teval-logloss:0.27836\n",
      "[41]\ttrain-logloss:0.27689\teval-logloss:0.27813\n",
      "[42]\ttrain-logloss:0.27661\teval-logloss:0.27787\n",
      "[43]\ttrain-logloss:0.27634\teval-logloss:0.27762\n",
      "[44]\ttrain-logloss:0.27607\teval-logloss:0.27739\n",
      "[45]\ttrain-logloss:0.27581\teval-logloss:0.27715\n",
      "[46]\ttrain-logloss:0.27554\teval-logloss:0.27690\n",
      "[47]\ttrain-logloss:0.27527\teval-logloss:0.27666\n",
      "[48]\ttrain-logloss:0.27500\teval-logloss:0.27640\n",
      "[49]\ttrain-logloss:0.27475\teval-logloss:0.27617\n",
      "[50]\ttrain-logloss:0.27450\teval-logloss:0.27594\n",
      "[51]\ttrain-logloss:0.27428\teval-logloss:0.27575\n",
      "[52]\ttrain-logloss:0.27404\teval-logloss:0.27553\n",
      "[53]\ttrain-logloss:0.27380\teval-logloss:0.27533\n",
      "[54]\ttrain-logloss:0.27355\teval-logloss:0.27510\n",
      "[55]\ttrain-logloss:0.27330\teval-logloss:0.27489\n",
      "[56]\ttrain-logloss:0.27306\teval-logloss:0.27467\n",
      "[57]\ttrain-logloss:0.27282\teval-logloss:0.27445\n",
      "[58]\ttrain-logloss:0.27258\teval-logloss:0.27424\n",
      "[59]\ttrain-logloss:0.27236\teval-logloss:0.27405\n",
      "[60]\ttrain-logloss:0.27213\teval-logloss:0.27386\n",
      "[61]\ttrain-logloss:0.27190\teval-logloss:0.27362\n",
      "[62]\ttrain-logloss:0.27167\teval-logloss:0.27342\n",
      "[63]\ttrain-logloss:0.27143\teval-logloss:0.27321\n",
      "[64]\ttrain-logloss:0.27119\teval-logloss:0.27301\n",
      "[65]\ttrain-logloss:0.27096\teval-logloss:0.27280\n",
      "[66]\ttrain-logloss:0.27072\teval-logloss:0.27258\n",
      "[67]\ttrain-logloss:0.27052\teval-logloss:0.27241\n",
      "[68]\ttrain-logloss:0.27032\teval-logloss:0.27225\n",
      "[69]\ttrain-logloss:0.27009\teval-logloss:0.27205\n",
      "[70]\ttrain-logloss:0.26989\teval-logloss:0.27188\n",
      "[71]\ttrain-logloss:0.26966\teval-logloss:0.27168\n",
      "[72]\ttrain-logloss:0.26943\teval-logloss:0.27149\n",
      "[73]\ttrain-logloss:0.26923\teval-logloss:0.27131\n",
      "[74]\ttrain-logloss:0.26901\teval-logloss:0.27113\n",
      "[75]\ttrain-logloss:0.26880\teval-logloss:0.27096\n",
      "[76]\ttrain-logloss:0.26857\teval-logloss:0.27076\n",
      "[77]\ttrain-logloss:0.26836\teval-logloss:0.27057\n",
      "[78]\ttrain-logloss:0.26814\teval-logloss:0.27037\n",
      "[79]\ttrain-logloss:0.26796\teval-logloss:0.27022\n",
      "[80]\ttrain-logloss:0.26775\teval-logloss:0.27004\n",
      "[81]\ttrain-logloss:0.26754\teval-logloss:0.26987\n",
      "[82]\ttrain-logloss:0.26732\teval-logloss:0.26968\n",
      "[83]\ttrain-logloss:0.26711\teval-logloss:0.26949\n",
      "[84]\ttrain-logloss:0.26691\teval-logloss:0.26931\n",
      "[85]\ttrain-logloss:0.26670\teval-logloss:0.26913\n",
      "[86]\ttrain-logloss:0.26651\teval-logloss:0.26894\n",
      "[87]\ttrain-logloss:0.26631\teval-logloss:0.26876\n",
      "[88]\ttrain-logloss:0.26610\teval-logloss:0.26858\n",
      "[89]\ttrain-logloss:0.26591\teval-logloss:0.26841\n",
      "[90]\ttrain-logloss:0.26570\teval-logloss:0.26823\n",
      "[91]\ttrain-logloss:0.26550\teval-logloss:0.26807\n",
      "[92]\ttrain-logloss:0.26529\teval-logloss:0.26788\n",
      "[93]\ttrain-logloss:0.26509\teval-logloss:0.26772\n",
      "[94]\ttrain-logloss:0.26493\teval-logloss:0.26759\n",
      "[95]\ttrain-logloss:0.26473\teval-logloss:0.26742\n",
      "[96]\ttrain-logloss:0.26453\teval-logloss:0.26723\n",
      "[97]\ttrain-logloss:0.26433\teval-logloss:0.26707\n",
      "[98]\ttrain-logloss:0.26414\teval-logloss:0.26691\n",
      "[99]\ttrain-logloss:0.26396\teval-logloss:0.26674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 16:00:02,085] Trial 0 finished with value: 0.26690499174272747 and parameters: {'eta': 0.004912759013751147, 'max_depth': 6, 'subsample': 0.7670877943835539, 'colsample_bytree': 0.848361468082169, 'min_child_weight': 7, 'lambda': 2.935710414813769, 'alpha': 0.008581182861218457}. Best is trial 0 with value: 0.26690499174272747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.28928\teval-logloss:0.28934\n",
      "[1]\ttrain-logloss:0.28895\teval-logloss:0.28906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28044/3574405256.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"eta\": trial.suggest_loguniform(\"eta\", 1e-3, 0.1),\n",
      "/tmp/ipykernel_28044/3574405256.py:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.6, 1.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.6, 1.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-3, 10.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-3, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\ttrain-logloss:0.28858\teval-logloss:0.28877\n",
      "[3]\ttrain-logloss:0.28824\teval-logloss:0.28849\n",
      "[4]\ttrain-logloss:0.28786\teval-logloss:0.28818\n",
      "[5]\ttrain-logloss:0.28751\teval-logloss:0.28791\n",
      "[6]\ttrain-logloss:0.28717\teval-logloss:0.28764\n",
      "[7]\ttrain-logloss:0.28686\teval-logloss:0.28741\n",
      "[8]\ttrain-logloss:0.28648\teval-logloss:0.28711\n",
      "[9]\ttrain-logloss:0.28616\teval-logloss:0.28684\n",
      "[10]\ttrain-logloss:0.28581\teval-logloss:0.28655\n",
      "[11]\ttrain-logloss:0.28548\teval-logloss:0.28630\n",
      "[12]\ttrain-logloss:0.28517\teval-logloss:0.28605\n",
      "[13]\ttrain-logloss:0.28482\teval-logloss:0.28576\n",
      "[14]\ttrain-logloss:0.28451\teval-logloss:0.28551\n",
      "[15]\ttrain-logloss:0.28420\teval-logloss:0.28529\n",
      "[16]\ttrain-logloss:0.28391\teval-logloss:0.28505\n",
      "[17]\ttrain-logloss:0.28355\teval-logloss:0.28476\n",
      "[18]\ttrain-logloss:0.28327\teval-logloss:0.28452\n",
      "[19]\ttrain-logloss:0.28292\teval-logloss:0.28426\n",
      "[20]\ttrain-logloss:0.28263\teval-logloss:0.28402\n",
      "[21]\ttrain-logloss:0.28228\teval-logloss:0.28377\n",
      "[22]\ttrain-logloss:0.28195\teval-logloss:0.28350\n",
      "[23]\ttrain-logloss:0.28165\teval-logloss:0.28325\n",
      "[24]\ttrain-logloss:0.28134\teval-logloss:0.28300\n",
      "[25]\ttrain-logloss:0.28105\teval-logloss:0.28277\n",
      "[26]\ttrain-logloss:0.28072\teval-logloss:0.28255\n",
      "[27]\ttrain-logloss:0.28037\teval-logloss:0.28228\n",
      "[28]\ttrain-logloss:0.28003\teval-logloss:0.28204\n",
      "[29]\ttrain-logloss:0.27970\teval-logloss:0.28181\n",
      "[30]\ttrain-logloss:0.27937\teval-logloss:0.28153\n",
      "[31]\ttrain-logloss:0.27910\teval-logloss:0.28132\n",
      "[32]\ttrain-logloss:0.27878\teval-logloss:0.28108\n",
      "[33]\ttrain-logloss:0.27845\teval-logloss:0.28083\n",
      "[34]\ttrain-logloss:0.27814\teval-logloss:0.28059\n",
      "[35]\ttrain-logloss:0.27780\teval-logloss:0.28035\n",
      "[36]\ttrain-logloss:0.27749\teval-logloss:0.28013\n",
      "[37]\ttrain-logloss:0.27720\teval-logloss:0.27994\n",
      "[38]\ttrain-logloss:0.27688\teval-logloss:0.27969\n",
      "[39]\ttrain-logloss:0.27659\teval-logloss:0.27944\n",
      "[40]\ttrain-logloss:0.27629\teval-logloss:0.27919\n",
      "[41]\ttrain-logloss:0.27599\teval-logloss:0.27894\n",
      "[42]\ttrain-logloss:0.27568\teval-logloss:0.27872\n",
      "[43]\ttrain-logloss:0.27538\teval-logloss:0.27851\n",
      "[44]\ttrain-logloss:0.27508\teval-logloss:0.27829\n",
      "[45]\ttrain-logloss:0.27477\teval-logloss:0.27808\n",
      "[46]\ttrain-logloss:0.27449\teval-logloss:0.27785\n",
      "[47]\ttrain-logloss:0.27419\teval-logloss:0.27764\n",
      "[48]\ttrain-logloss:0.27389\teval-logloss:0.27741\n",
      "[49]\ttrain-logloss:0.27358\teval-logloss:0.27718\n",
      "[50]\ttrain-logloss:0.27327\teval-logloss:0.27695\n",
      "[51]\ttrain-logloss:0.27302\teval-logloss:0.27676\n",
      "[52]\ttrain-logloss:0.27272\teval-logloss:0.27657\n",
      "[53]\ttrain-logloss:0.27247\teval-logloss:0.27638\n",
      "[54]\ttrain-logloss:0.27219\teval-logloss:0.27617\n",
      "[55]\ttrain-logloss:0.27190\teval-logloss:0.27595\n",
      "[56]\ttrain-logloss:0.27163\teval-logloss:0.27576\n",
      "[57]\ttrain-logloss:0.27139\teval-logloss:0.27557\n",
      "[58]\ttrain-logloss:0.27111\teval-logloss:0.27537\n",
      "[59]\ttrain-logloss:0.27088\teval-logloss:0.27521\n",
      "[60]\ttrain-logloss:0.27061\teval-logloss:0.27501\n",
      "[61]\ttrain-logloss:0.27034\teval-logloss:0.27483\n",
      "[62]\ttrain-logloss:0.27010\teval-logloss:0.27464\n",
      "[63]\ttrain-logloss:0.26982\teval-logloss:0.27441\n",
      "[64]\ttrain-logloss:0.26955\teval-logloss:0.27422\n",
      "[65]\ttrain-logloss:0.26929\teval-logloss:0.27403\n",
      "[66]\ttrain-logloss:0.26903\teval-logloss:0.27384\n",
      "[67]\ttrain-logloss:0.26879\teval-logloss:0.27369\n",
      "[68]\ttrain-logloss:0.26857\teval-logloss:0.27350\n",
      "[69]\ttrain-logloss:0.26833\teval-logloss:0.27331\n",
      "[70]\ttrain-logloss:0.26812\teval-logloss:0.27316\n",
      "[71]\ttrain-logloss:0.26786\teval-logloss:0.27297\n",
      "[72]\ttrain-logloss:0.26759\teval-logloss:0.27276\n",
      "[73]\ttrain-logloss:0.26739\teval-logloss:0.27261\n",
      "[74]\ttrain-logloss:0.26715\teval-logloss:0.27244\n",
      "[75]\ttrain-logloss:0.26693\teval-logloss:0.27227\n",
      "[76]\ttrain-logloss:0.26666\teval-logloss:0.27208\n",
      "[77]\ttrain-logloss:0.26641\teval-logloss:0.27189\n",
      "[78]\ttrain-logloss:0.26616\teval-logloss:0.27173\n",
      "[79]\ttrain-logloss:0.26595\teval-logloss:0.27158\n",
      "[80]\ttrain-logloss:0.26572\teval-logloss:0.27139\n",
      "[81]\ttrain-logloss:0.26551\teval-logloss:0.27121\n",
      "[82]\ttrain-logloss:0.26526\teval-logloss:0.27103\n",
      "[83]\ttrain-logloss:0.26501\teval-logloss:0.27086\n",
      "[84]\ttrain-logloss:0.26476\teval-logloss:0.27068\n",
      "[85]\ttrain-logloss:0.26452\teval-logloss:0.27051\n",
      "[86]\ttrain-logloss:0.26427\teval-logloss:0.27033\n",
      "[87]\ttrain-logloss:0.26406\teval-logloss:0.27018\n",
      "[88]\ttrain-logloss:0.26383\teval-logloss:0.27003\n",
      "[89]\ttrain-logloss:0.26357\teval-logloss:0.26984\n",
      "[90]\ttrain-logloss:0.26333\teval-logloss:0.26968\n",
      "[91]\ttrain-logloss:0.26308\teval-logloss:0.26951\n",
      "[92]\ttrain-logloss:0.26285\teval-logloss:0.26936\n",
      "[93]\ttrain-logloss:0.26262\teval-logloss:0.26919\n",
      "[94]\ttrain-logloss:0.26242\teval-logloss:0.26903\n",
      "[95]\ttrain-logloss:0.26217\teval-logloss:0.26885\n",
      "[96]\ttrain-logloss:0.26193\teval-logloss:0.26869\n",
      "[97]\ttrain-logloss:0.26172\teval-logloss:0.26851\n",
      "[98]\ttrain-logloss:0.26149\teval-logloss:0.26837\n",
      "[99]\ttrain-logloss:0.26122\teval-logloss:0.26821\n",
      "[0]\ttrain-logloss:0.28925\teval-logloss:0.28933\n",
      "[1]\ttrain-logloss:0.28892\teval-logloss:0.28904\n",
      "[2]\ttrain-logloss:0.28858\teval-logloss:0.28875\n",
      "[3]\ttrain-logloss:0.28824\teval-logloss:0.28848\n",
      "[4]\ttrain-logloss:0.28788\teval-logloss:0.28818\n",
      "[5]\ttrain-logloss:0.28751\teval-logloss:0.28792\n",
      "[6]\ttrain-logloss:0.28714\teval-logloss:0.28762\n",
      "[7]\ttrain-logloss:0.28681\teval-logloss:0.28735\n",
      "[8]\ttrain-logloss:0.28645\teval-logloss:0.28708\n",
      "[9]\ttrain-logloss:0.28614\teval-logloss:0.28683\n",
      "[10]\ttrain-logloss:0.28583\teval-logloss:0.28656\n",
      "[11]\ttrain-logloss:0.28553\teval-logloss:0.28633\n",
      "[12]\ttrain-logloss:0.28522\teval-logloss:0.28608\n",
      "[13]\ttrain-logloss:0.28487\teval-logloss:0.28581\n",
      "[14]\ttrain-logloss:0.28454\teval-logloss:0.28558\n",
      "[15]\ttrain-logloss:0.28423\teval-logloss:0.28538\n",
      "[16]\ttrain-logloss:0.28394\teval-logloss:0.28516\n",
      "[17]\ttrain-logloss:0.28361\teval-logloss:0.28490\n",
      "[18]\ttrain-logloss:0.28330\teval-logloss:0.28468\n",
      "[19]\ttrain-logloss:0.28298\teval-logloss:0.28443\n",
      "[20]\ttrain-logloss:0.28267\teval-logloss:0.28420\n",
      "[21]\ttrain-logloss:0.28232\teval-logloss:0.28396\n",
      "[22]\ttrain-logloss:0.28201\teval-logloss:0.28369\n",
      "[23]\ttrain-logloss:0.28167\teval-logloss:0.28344\n",
      "[24]\ttrain-logloss:0.28134\teval-logloss:0.28320\n",
      "[25]\ttrain-logloss:0.28102\teval-logloss:0.28297\n",
      "[26]\ttrain-logloss:0.28072\teval-logloss:0.28273\n",
      "[27]\ttrain-logloss:0.28039\teval-logloss:0.28246\n",
      "[28]\ttrain-logloss:0.28005\teval-logloss:0.28220\n",
      "[29]\ttrain-logloss:0.27972\teval-logloss:0.28195\n",
      "[30]\ttrain-logloss:0.27940\teval-logloss:0.28171\n",
      "[31]\ttrain-logloss:0.27913\teval-logloss:0.28149\n",
      "[32]\ttrain-logloss:0.27879\teval-logloss:0.28126\n",
      "[33]\ttrain-logloss:0.27847\teval-logloss:0.28102\n",
      "[34]\ttrain-logloss:0.27816\teval-logloss:0.28075\n",
      "[35]\ttrain-logloss:0.27785\teval-logloss:0.28052\n",
      "[36]\ttrain-logloss:0.27754\teval-logloss:0.28029\n",
      "[37]\ttrain-logloss:0.27724\teval-logloss:0.28010\n",
      "[38]\ttrain-logloss:0.27695\teval-logloss:0.27986\n",
      "[39]\ttrain-logloss:0.27666\teval-logloss:0.27961\n",
      "[40]\ttrain-logloss:0.27638\teval-logloss:0.27939\n",
      "[41]\ttrain-logloss:0.27607\teval-logloss:0.27917\n",
      "[42]\ttrain-logloss:0.27578\teval-logloss:0.27895\n",
      "[43]\ttrain-logloss:0.27547\teval-logloss:0.27872\n",
      "[44]\ttrain-logloss:0.27517\teval-logloss:0.27851\n",
      "[45]\ttrain-logloss:0.27488\teval-logloss:0.27828\n",
      "[46]\ttrain-logloss:0.27459\teval-logloss:0.27808\n",
      "[47]\ttrain-logloss:0.27428\teval-logloss:0.27789\n",
      "[48]\ttrain-logloss:0.27399\teval-logloss:0.27767\n",
      "[49]\ttrain-logloss:0.27372\teval-logloss:0.27745\n",
      "[50]\ttrain-logloss:0.27345\teval-logloss:0.27723\n",
      "[51]\ttrain-logloss:0.27322\teval-logloss:0.27705\n",
      "[52]\ttrain-logloss:0.27296\teval-logloss:0.27686\n",
      "[53]\ttrain-logloss:0.27271\teval-logloss:0.27667\n",
      "[54]\ttrain-logloss:0.27244\teval-logloss:0.27647\n",
      "[55]\ttrain-logloss:0.27217\teval-logloss:0.27629\n",
      "[56]\ttrain-logloss:0.27190\teval-logloss:0.27609\n",
      "[57]\ttrain-logloss:0.27166\teval-logloss:0.27589\n",
      "[58]\ttrain-logloss:0.27140\teval-logloss:0.27570\n",
      "[59]\ttrain-logloss:0.27114\teval-logloss:0.27552\n",
      "[60]\ttrain-logloss:0.27089\teval-logloss:0.27533\n",
      "[61]\ttrain-logloss:0.27062\teval-logloss:0.27513\n",
      "[62]\ttrain-logloss:0.27037\teval-logloss:0.27494\n",
      "[63]\ttrain-logloss:0.27008\teval-logloss:0.27473\n",
      "[64]\ttrain-logloss:0.26982\teval-logloss:0.27453\n",
      "[65]\ttrain-logloss:0.26956\teval-logloss:0.27434\n",
      "[66]\ttrain-logloss:0.26930\teval-logloss:0.27414\n",
      "[67]\ttrain-logloss:0.26908\teval-logloss:0.27396\n",
      "[68]\ttrain-logloss:0.26885\teval-logloss:0.27378\n",
      "[69]\ttrain-logloss:0.26860\teval-logloss:0.27360\n",
      "[70]\ttrain-logloss:0.26838\teval-logloss:0.27343\n",
      "[71]\ttrain-logloss:0.26812\teval-logloss:0.27328\n",
      "[72]\ttrain-logloss:0.26786\teval-logloss:0.27308\n",
      "[73]\ttrain-logloss:0.26761\teval-logloss:0.27291\n",
      "[74]\ttrain-logloss:0.26738\teval-logloss:0.27273\n",
      "[75]\ttrain-logloss:0.26714\teval-logloss:0.27259\n",
      "[76]\ttrain-logloss:0.26687\teval-logloss:0.27244\n",
      "[77]\ttrain-logloss:0.26662\teval-logloss:0.27223\n",
      "[78]\ttrain-logloss:0.26636\teval-logloss:0.27205\n",
      "[79]\ttrain-logloss:0.26614\teval-logloss:0.27189\n",
      "[80]\ttrain-logloss:0.26591\teval-logloss:0.27172\n",
      "[81]\ttrain-logloss:0.26567\teval-logloss:0.27155\n",
      "[82]\ttrain-logloss:0.26542\teval-logloss:0.27139\n",
      "[83]\ttrain-logloss:0.26517\teval-logloss:0.27124\n",
      "[84]\ttrain-logloss:0.26494\teval-logloss:0.27107\n",
      "[85]\ttrain-logloss:0.26471\teval-logloss:0.27087\n",
      "[86]\ttrain-logloss:0.26445\teval-logloss:0.27067\n",
      "[87]\ttrain-logloss:0.26422\teval-logloss:0.27051\n",
      "[88]\ttrain-logloss:0.26399\teval-logloss:0.27033\n",
      "[89]\ttrain-logloss:0.26376\teval-logloss:0.27016\n",
      "[90]\ttrain-logloss:0.26353\teval-logloss:0.26999\n",
      "[91]\ttrain-logloss:0.26330\teval-logloss:0.26979\n",
      "[92]\ttrain-logloss:0.26308\teval-logloss:0.26961\n",
      "[93]\ttrain-logloss:0.26286\teval-logloss:0.26943\n",
      "[94]\ttrain-logloss:0.26263\teval-logloss:0.26929\n",
      "[95]\ttrain-logloss:0.26240\teval-logloss:0.26915\n",
      "[96]\ttrain-logloss:0.26215\teval-logloss:0.26897\n",
      "[97]\ttrain-logloss:0.26192\teval-logloss:0.26879\n",
      "[98]\ttrain-logloss:0.26171\teval-logloss:0.26864\n",
      "[99]\ttrain-logloss:0.26147\teval-logloss:0.26850\n",
      "[0]\ttrain-logloss:0.28925\teval-logloss:0.28933\n",
      "[1]\ttrain-logloss:0.28891\teval-logloss:0.28907\n",
      "[2]\ttrain-logloss:0.28853\teval-logloss:0.28878\n",
      "[3]\ttrain-logloss:0.28816\teval-logloss:0.28852\n",
      "[4]\ttrain-logloss:0.28780\teval-logloss:0.28824\n",
      "[5]\ttrain-logloss:0.28743\teval-logloss:0.28797\n",
      "[6]\ttrain-logloss:0.28706\teval-logloss:0.28771\n",
      "[7]\ttrain-logloss:0.28676\teval-logloss:0.28746\n",
      "[8]\ttrain-logloss:0.28639\teval-logloss:0.28720\n",
      "[9]\ttrain-logloss:0.28607\teval-logloss:0.28698\n",
      "[10]\ttrain-logloss:0.28573\teval-logloss:0.28673\n",
      "[11]\ttrain-logloss:0.28543\teval-logloss:0.28650\n",
      "[12]\ttrain-logloss:0.28509\teval-logloss:0.28626\n",
      "[13]\ttrain-logloss:0.28474\teval-logloss:0.28598\n",
      "[14]\ttrain-logloss:0.28444\teval-logloss:0.28576\n",
      "[15]\ttrain-logloss:0.28414\teval-logloss:0.28551\n",
      "[16]\ttrain-logloss:0.28384\teval-logloss:0.28529\n",
      "[17]\ttrain-logloss:0.28350\teval-logloss:0.28502\n",
      "[18]\ttrain-logloss:0.28321\teval-logloss:0.28480\n",
      "[19]\ttrain-logloss:0.28285\teval-logloss:0.28457\n",
      "[20]\ttrain-logloss:0.28257\teval-logloss:0.28435\n",
      "[21]\ttrain-logloss:0.28221\teval-logloss:0.28411\n",
      "[22]\ttrain-logloss:0.28187\teval-logloss:0.28387\n",
      "[23]\ttrain-logloss:0.28153\teval-logloss:0.28363\n",
      "[24]\ttrain-logloss:0.28121\teval-logloss:0.28340\n",
      "[25]\ttrain-logloss:0.28092\teval-logloss:0.28316\n",
      "[26]\ttrain-logloss:0.28062\teval-logloss:0.28294\n",
      "[27]\ttrain-logloss:0.28026\teval-logloss:0.28269\n",
      "[28]\ttrain-logloss:0.27993\teval-logloss:0.28247\n",
      "[29]\ttrain-logloss:0.27960\teval-logloss:0.28227\n",
      "[30]\ttrain-logloss:0.27927\teval-logloss:0.28205\n",
      "[31]\ttrain-logloss:0.27899\teval-logloss:0.28184\n",
      "[32]\ttrain-logloss:0.27866\teval-logloss:0.28161\n",
      "[33]\ttrain-logloss:0.27835\teval-logloss:0.28139\n",
      "[34]\ttrain-logloss:0.27803\teval-logloss:0.28116\n",
      "[35]\ttrain-logloss:0.27773\teval-logloss:0.28096\n",
      "[36]\ttrain-logloss:0.27740\teval-logloss:0.28073\n",
      "[37]\ttrain-logloss:0.27710\teval-logloss:0.28054\n",
      "[38]\ttrain-logloss:0.27678\teval-logloss:0.28030\n",
      "[39]\ttrain-logloss:0.27647\teval-logloss:0.28008\n",
      "[40]\ttrain-logloss:0.27617\teval-logloss:0.27985\n",
      "[41]\ttrain-logloss:0.27586\teval-logloss:0.27963\n",
      "[42]\ttrain-logloss:0.27554\teval-logloss:0.27941\n",
      "[43]\ttrain-logloss:0.27525\teval-logloss:0.27922\n",
      "[44]\ttrain-logloss:0.27495\teval-logloss:0.27901\n",
      "[45]\ttrain-logloss:0.27466\teval-logloss:0.27880\n",
      "[46]\ttrain-logloss:0.27438\teval-logloss:0.27860\n",
      "[47]\ttrain-logloss:0.27409\teval-logloss:0.27840\n",
      "[48]\ttrain-logloss:0.27380\teval-logloss:0.27821\n",
      "[49]\ttrain-logloss:0.27351\teval-logloss:0.27800\n",
      "[50]\ttrain-logloss:0.27322\teval-logloss:0.27780\n",
      "[51]\ttrain-logloss:0.27296\teval-logloss:0.27763\n",
      "[52]\ttrain-logloss:0.27269\teval-logloss:0.27742\n",
      "[53]\ttrain-logloss:0.27243\teval-logloss:0.27722\n",
      "[54]\ttrain-logloss:0.27215\teval-logloss:0.27703\n",
      "[55]\ttrain-logloss:0.27188\teval-logloss:0.27683\n",
      "[56]\ttrain-logloss:0.27160\teval-logloss:0.27664\n",
      "[57]\ttrain-logloss:0.27132\teval-logloss:0.27647\n",
      "[58]\ttrain-logloss:0.27105\teval-logloss:0.27631\n",
      "[59]\ttrain-logloss:0.27082\teval-logloss:0.27612\n",
      "[60]\ttrain-logloss:0.27054\teval-logloss:0.27595\n",
      "[61]\ttrain-logloss:0.27026\teval-logloss:0.27575\n",
      "[62]\ttrain-logloss:0.27001\teval-logloss:0.27560\n",
      "[63]\ttrain-logloss:0.26973\teval-logloss:0.27541\n",
      "[64]\ttrain-logloss:0.26945\teval-logloss:0.27522\n",
      "[65]\ttrain-logloss:0.26919\teval-logloss:0.27506\n",
      "[66]\ttrain-logloss:0.26892\teval-logloss:0.27488\n",
      "[67]\ttrain-logloss:0.26868\teval-logloss:0.27471\n",
      "[68]\ttrain-logloss:0.26845\teval-logloss:0.27454\n",
      "[69]\ttrain-logloss:0.26817\teval-logloss:0.27439\n",
      "[70]\ttrain-logloss:0.26796\teval-logloss:0.27423\n",
      "[71]\ttrain-logloss:0.26769\teval-logloss:0.27406\n",
      "[72]\ttrain-logloss:0.26743\teval-logloss:0.27390\n",
      "[73]\ttrain-logloss:0.26724\teval-logloss:0.27375\n",
      "[74]\ttrain-logloss:0.26701\teval-logloss:0.27360\n",
      "[75]\ttrain-logloss:0.26681\teval-logloss:0.27344\n",
      "[76]\ttrain-logloss:0.26655\teval-logloss:0.27327\n",
      "[77]\ttrain-logloss:0.26629\teval-logloss:0.27307\n",
      "[78]\ttrain-logloss:0.26604\teval-logloss:0.27290\n",
      "[79]\ttrain-logloss:0.26582\teval-logloss:0.27273\n",
      "[80]\ttrain-logloss:0.26558\teval-logloss:0.27256\n",
      "[81]\ttrain-logloss:0.26535\teval-logloss:0.27241\n",
      "[82]\ttrain-logloss:0.26509\teval-logloss:0.27226\n",
      "[83]\ttrain-logloss:0.26486\teval-logloss:0.27210\n",
      "[84]\ttrain-logloss:0.26462\teval-logloss:0.27194\n",
      "[85]\ttrain-logloss:0.26438\teval-logloss:0.27179\n",
      "[86]\ttrain-logloss:0.26415\teval-logloss:0.27164\n",
      "[87]\ttrain-logloss:0.26389\teval-logloss:0.27147\n",
      "[88]\ttrain-logloss:0.26364\teval-logloss:0.27132\n",
      "[89]\ttrain-logloss:0.26341\teval-logloss:0.27118\n",
      "[90]\ttrain-logloss:0.26316\teval-logloss:0.27102\n",
      "[91]\ttrain-logloss:0.26292\teval-logloss:0.27087\n",
      "[92]\ttrain-logloss:0.26268\teval-logloss:0.27072\n",
      "[93]\ttrain-logloss:0.26245\teval-logloss:0.27060\n",
      "[94]\ttrain-logloss:0.26225\teval-logloss:0.27044\n",
      "[95]\ttrain-logloss:0.26201\teval-logloss:0.27030\n",
      "[96]\ttrain-logloss:0.26177\teval-logloss:0.27015\n",
      "[97]\ttrain-logloss:0.26154\teval-logloss:0.27002\n",
      "[98]\ttrain-logloss:0.26130\teval-logloss:0.26986\n",
      "[99]\ttrain-logloss:0.26107\teval-logloss:0.26971\n",
      "[0]\ttrain-logloss:0.28925\teval-logloss:0.28932\n",
      "[1]\ttrain-logloss:0.28891\teval-logloss:0.28906\n",
      "[2]\ttrain-logloss:0.28855\teval-logloss:0.28877\n",
      "[3]\ttrain-logloss:0.28822\teval-logloss:0.28849\n",
      "[4]\ttrain-logloss:0.28786\teval-logloss:0.28821\n",
      "[5]\ttrain-logloss:0.28751\teval-logloss:0.28793\n",
      "[6]\ttrain-logloss:0.28716\teval-logloss:0.28763\n",
      "[7]\ttrain-logloss:0.28686\teval-logloss:0.28737\n",
      "[8]\ttrain-logloss:0.28652\teval-logloss:0.28709\n",
      "[9]\ttrain-logloss:0.28621\teval-logloss:0.28683\n",
      "[10]\ttrain-logloss:0.28591\teval-logloss:0.28658\n",
      "[11]\ttrain-logloss:0.28559\teval-logloss:0.28635\n",
      "[12]\ttrain-logloss:0.28527\teval-logloss:0.28610\n",
      "[13]\ttrain-logloss:0.28493\teval-logloss:0.28584\n",
      "[14]\ttrain-logloss:0.28462\teval-logloss:0.28560\n",
      "[15]\ttrain-logloss:0.28432\teval-logloss:0.28536\n",
      "[16]\ttrain-logloss:0.28404\teval-logloss:0.28512\n",
      "[17]\ttrain-logloss:0.28370\teval-logloss:0.28485\n",
      "[18]\ttrain-logloss:0.28341\teval-logloss:0.28459\n",
      "[19]\ttrain-logloss:0.28306\teval-logloss:0.28432\n",
      "[20]\ttrain-logloss:0.28277\teval-logloss:0.28409\n",
      "[21]\ttrain-logloss:0.28243\teval-logloss:0.28383\n",
      "[22]\ttrain-logloss:0.28210\teval-logloss:0.28358\n",
      "[23]\ttrain-logloss:0.28177\teval-logloss:0.28330\n",
      "[24]\ttrain-logloss:0.28143\teval-logloss:0.28306\n",
      "[25]\ttrain-logloss:0.28113\teval-logloss:0.28281\n",
      "[26]\ttrain-logloss:0.28082\teval-logloss:0.28256\n",
      "[27]\ttrain-logloss:0.28049\teval-logloss:0.28229\n",
      "[28]\ttrain-logloss:0.28018\teval-logloss:0.28204\n",
      "[29]\ttrain-logloss:0.27985\teval-logloss:0.28178\n",
      "[30]\ttrain-logloss:0.27954\teval-logloss:0.28151\n",
      "[31]\ttrain-logloss:0.27924\teval-logloss:0.28128\n",
      "[32]\ttrain-logloss:0.27891\teval-logloss:0.28105\n",
      "[33]\ttrain-logloss:0.27861\teval-logloss:0.28079\n",
      "[34]\ttrain-logloss:0.27829\teval-logloss:0.28057\n",
      "[35]\ttrain-logloss:0.27799\teval-logloss:0.28033\n",
      "[36]\ttrain-logloss:0.27770\teval-logloss:0.28011\n",
      "[37]\ttrain-logloss:0.27740\teval-logloss:0.27988\n",
      "[38]\ttrain-logloss:0.27710\teval-logloss:0.27965\n",
      "[39]\ttrain-logloss:0.27679\teval-logloss:0.27941\n",
      "[40]\ttrain-logloss:0.27647\teval-logloss:0.27918\n",
      "[41]\ttrain-logloss:0.27620\teval-logloss:0.27895\n",
      "[42]\ttrain-logloss:0.27589\teval-logloss:0.27872\n",
      "[43]\ttrain-logloss:0.27560\teval-logloss:0.27848\n",
      "[44]\ttrain-logloss:0.27530\teval-logloss:0.27826\n",
      "[45]\ttrain-logloss:0.27501\teval-logloss:0.27804\n",
      "[46]\ttrain-logloss:0.27471\teval-logloss:0.27783\n",
      "[47]\ttrain-logloss:0.27442\teval-logloss:0.27761\n",
      "[48]\ttrain-logloss:0.27412\teval-logloss:0.27739\n",
      "[49]\ttrain-logloss:0.27383\teval-logloss:0.27716\n",
      "[50]\ttrain-logloss:0.27355\teval-logloss:0.27694\n",
      "[51]\ttrain-logloss:0.27330\teval-logloss:0.27676\n",
      "[52]\ttrain-logloss:0.27304\teval-logloss:0.27654\n",
      "[53]\ttrain-logloss:0.27281\teval-logloss:0.27634\n",
      "[54]\ttrain-logloss:0.27256\teval-logloss:0.27613\n",
      "[55]\ttrain-logloss:0.27227\teval-logloss:0.27592\n",
      "[56]\ttrain-logloss:0.27199\teval-logloss:0.27569\n",
      "[57]\ttrain-logloss:0.27172\teval-logloss:0.27549\n",
      "[58]\ttrain-logloss:0.27146\teval-logloss:0.27529\n",
      "[59]\ttrain-logloss:0.27121\teval-logloss:0.27509\n",
      "[60]\ttrain-logloss:0.27096\teval-logloss:0.27490\n",
      "[61]\ttrain-logloss:0.27069\teval-logloss:0.27470\n",
      "[62]\ttrain-logloss:0.27045\teval-logloss:0.27451\n",
      "[63]\ttrain-logloss:0.27017\teval-logloss:0.27429\n",
      "[64]\ttrain-logloss:0.26991\teval-logloss:0.27408\n",
      "[65]\ttrain-logloss:0.26965\teval-logloss:0.27386\n",
      "[66]\ttrain-logloss:0.26939\teval-logloss:0.27362\n",
      "[67]\ttrain-logloss:0.26915\teval-logloss:0.27343\n",
      "[68]\ttrain-logloss:0.26890\teval-logloss:0.27327\n",
      "[69]\ttrain-logloss:0.26864\teval-logloss:0.27307\n",
      "[70]\ttrain-logloss:0.26842\teval-logloss:0.27290\n",
      "[71]\ttrain-logloss:0.26816\teval-logloss:0.27269\n",
      "[72]\ttrain-logloss:0.26790\teval-logloss:0.27250\n",
      "[73]\ttrain-logloss:0.26767\teval-logloss:0.27234\n",
      "[74]\ttrain-logloss:0.26742\teval-logloss:0.27212\n",
      "[75]\ttrain-logloss:0.26719\teval-logloss:0.27194\n",
      "[76]\ttrain-logloss:0.26694\teval-logloss:0.27175\n",
      "[77]\ttrain-logloss:0.26669\teval-logloss:0.27155\n",
      "[78]\ttrain-logloss:0.26646\teval-logloss:0.27136\n",
      "[79]\ttrain-logloss:0.26624\teval-logloss:0.27120\n",
      "[80]\ttrain-logloss:0.26598\teval-logloss:0.27099\n",
      "[81]\ttrain-logloss:0.26574\teval-logloss:0.27079\n",
      "[82]\ttrain-logloss:0.26549\teval-logloss:0.27062\n",
      "[83]\ttrain-logloss:0.26524\teval-logloss:0.27044\n",
      "[84]\ttrain-logloss:0.26497\teval-logloss:0.27026\n",
      "[85]\ttrain-logloss:0.26473\teval-logloss:0.27004\n",
      "[86]\ttrain-logloss:0.26451\teval-logloss:0.26987\n",
      "[87]\ttrain-logloss:0.26427\teval-logloss:0.26971\n",
      "[88]\ttrain-logloss:0.26403\teval-logloss:0.26954\n",
      "[89]\ttrain-logloss:0.26377\teval-logloss:0.26936\n",
      "[90]\ttrain-logloss:0.26353\teval-logloss:0.26918\n",
      "[91]\ttrain-logloss:0.26331\teval-logloss:0.26898\n",
      "[92]\ttrain-logloss:0.26308\teval-logloss:0.26882\n",
      "[93]\ttrain-logloss:0.26282\teval-logloss:0.26862\n",
      "[94]\ttrain-logloss:0.26262\teval-logloss:0.26846\n",
      "[95]\ttrain-logloss:0.26239\teval-logloss:0.26829\n",
      "[96]\ttrain-logloss:0.26214\teval-logloss:0.26812\n",
      "[97]\ttrain-logloss:0.26190\teval-logloss:0.26795\n",
      "[98]\ttrain-logloss:0.26167\teval-logloss:0.26778\n",
      "[99]\ttrain-logloss:0.26144\teval-logloss:0.26763\n",
      "[0]\ttrain-logloss:0.28924\teval-logloss:0.28940\n",
      "[1]\ttrain-logloss:0.28892\teval-logloss:0.28914\n",
      "[2]\ttrain-logloss:0.28855\teval-logloss:0.28884\n",
      "[3]\ttrain-logloss:0.28821\teval-logloss:0.28856\n",
      "[4]\ttrain-logloss:0.28787\teval-logloss:0.28825\n",
      "[5]\ttrain-logloss:0.28752\teval-logloss:0.28794\n",
      "[6]\ttrain-logloss:0.28714\teval-logloss:0.28766\n",
      "[7]\ttrain-logloss:0.28684\teval-logloss:0.28741\n",
      "[8]\ttrain-logloss:0.28648\teval-logloss:0.28713\n",
      "[9]\ttrain-logloss:0.28617\teval-logloss:0.28687\n",
      "[10]\ttrain-logloss:0.28584\teval-logloss:0.28660\n",
      "[11]\ttrain-logloss:0.28554\teval-logloss:0.28637\n",
      "[12]\ttrain-logloss:0.28523\teval-logloss:0.28611\n",
      "[13]\ttrain-logloss:0.28488\teval-logloss:0.28583\n",
      "[14]\ttrain-logloss:0.28457\teval-logloss:0.28558\n",
      "[15]\ttrain-logloss:0.28427\teval-logloss:0.28535\n",
      "[16]\ttrain-logloss:0.28398\teval-logloss:0.28512\n",
      "[17]\ttrain-logloss:0.28364\teval-logloss:0.28487\n",
      "[18]\ttrain-logloss:0.28336\teval-logloss:0.28464\n",
      "[19]\ttrain-logloss:0.28300\teval-logloss:0.28436\n",
      "[20]\ttrain-logloss:0.28269\teval-logloss:0.28413\n",
      "[21]\ttrain-logloss:0.28237\teval-logloss:0.28384\n",
      "[22]\ttrain-logloss:0.28202\teval-logloss:0.28358\n",
      "[23]\ttrain-logloss:0.28167\teval-logloss:0.28331\n",
      "[24]\ttrain-logloss:0.28133\teval-logloss:0.28305\n",
      "[25]\ttrain-logloss:0.28106\teval-logloss:0.28281\n",
      "[26]\ttrain-logloss:0.28077\teval-logloss:0.28257\n",
      "[27]\ttrain-logloss:0.28043\teval-logloss:0.28228\n",
      "[28]\ttrain-logloss:0.28009\teval-logloss:0.28204\n",
      "[29]\ttrain-logloss:0.27975\teval-logloss:0.28178\n",
      "[30]\ttrain-logloss:0.27943\teval-logloss:0.28153\n",
      "[31]\ttrain-logloss:0.27914\teval-logloss:0.28130\n",
      "[32]\ttrain-logloss:0.27882\teval-logloss:0.28106\n",
      "[33]\ttrain-logloss:0.27851\teval-logloss:0.28081\n",
      "[34]\ttrain-logloss:0.27820\teval-logloss:0.28057\n",
      "[35]\ttrain-logloss:0.27788\teval-logloss:0.28033\n",
      "[36]\ttrain-logloss:0.27757\teval-logloss:0.28009\n",
      "[37]\ttrain-logloss:0.27729\teval-logloss:0.27985\n",
      "[38]\ttrain-logloss:0.27699\teval-logloss:0.27960\n",
      "[39]\ttrain-logloss:0.27669\teval-logloss:0.27937\n",
      "[40]\ttrain-logloss:0.27639\teval-logloss:0.27914\n",
      "[41]\ttrain-logloss:0.27610\teval-logloss:0.27891\n",
      "[42]\ttrain-logloss:0.27580\teval-logloss:0.27866\n",
      "[43]\ttrain-logloss:0.27552\teval-logloss:0.27845\n",
      "[44]\ttrain-logloss:0.27524\teval-logloss:0.27822\n",
      "[45]\ttrain-logloss:0.27494\teval-logloss:0.27799\n",
      "[46]\ttrain-logloss:0.27464\teval-logloss:0.27774\n",
      "[47]\ttrain-logloss:0.27434\teval-logloss:0.27751\n",
      "[48]\ttrain-logloss:0.27405\teval-logloss:0.27726\n",
      "[49]\ttrain-logloss:0.27378\teval-logloss:0.27704\n",
      "[50]\ttrain-logloss:0.27349\teval-logloss:0.27685\n",
      "[51]\ttrain-logloss:0.27325\teval-logloss:0.27666\n",
      "[52]\ttrain-logloss:0.27299\teval-logloss:0.27644\n",
      "[53]\ttrain-logloss:0.27274\teval-logloss:0.27627\n",
      "[54]\ttrain-logloss:0.27246\teval-logloss:0.27605\n",
      "[55]\ttrain-logloss:0.27218\teval-logloss:0.27585\n",
      "[56]\ttrain-logloss:0.27191\teval-logloss:0.27565\n",
      "[57]\ttrain-logloss:0.27164\teval-logloss:0.27545\n",
      "[58]\ttrain-logloss:0.27137\teval-logloss:0.27526\n",
      "[59]\ttrain-logloss:0.27112\teval-logloss:0.27507\n",
      "[60]\ttrain-logloss:0.27087\teval-logloss:0.27490\n",
      "[61]\ttrain-logloss:0.27060\teval-logloss:0.27466\n",
      "[62]\ttrain-logloss:0.27036\teval-logloss:0.27447\n",
      "[63]\ttrain-logloss:0.27006\teval-logloss:0.27429\n",
      "[64]\ttrain-logloss:0.26979\teval-logloss:0.27410\n",
      "[65]\ttrain-logloss:0.26955\teval-logloss:0.27390\n",
      "[66]\ttrain-logloss:0.26930\teval-logloss:0.27370\n",
      "[67]\ttrain-logloss:0.26907\teval-logloss:0.27354\n",
      "[68]\ttrain-logloss:0.26884\teval-logloss:0.27339\n",
      "[69]\ttrain-logloss:0.26859\teval-logloss:0.27320\n",
      "[70]\ttrain-logloss:0.26834\teval-logloss:0.27301\n",
      "[71]\ttrain-logloss:0.26805\teval-logloss:0.27281\n",
      "[72]\ttrain-logloss:0.26776\teval-logloss:0.27263\n",
      "[73]\ttrain-logloss:0.26751\teval-logloss:0.27248\n",
      "[74]\ttrain-logloss:0.26726\teval-logloss:0.27229\n",
      "[75]\ttrain-logloss:0.26703\teval-logloss:0.27213\n",
      "[76]\ttrain-logloss:0.26677\teval-logloss:0.27196\n",
      "[77]\ttrain-logloss:0.26653\teval-logloss:0.27179\n",
      "[78]\ttrain-logloss:0.26629\teval-logloss:0.27160\n",
      "[79]\ttrain-logloss:0.26608\teval-logloss:0.27145\n",
      "[80]\ttrain-logloss:0.26583\teval-logloss:0.27124\n",
      "[81]\ttrain-logloss:0.26556\teval-logloss:0.27106\n",
      "[82]\ttrain-logloss:0.26531\teval-logloss:0.27088\n",
      "[83]\ttrain-logloss:0.26506\teval-logloss:0.27071\n",
      "[84]\ttrain-logloss:0.26482\teval-logloss:0.27055\n",
      "[85]\ttrain-logloss:0.26459\teval-logloss:0.27037\n",
      "[86]\ttrain-logloss:0.26438\teval-logloss:0.27019\n",
      "[87]\ttrain-logloss:0.26417\teval-logloss:0.27005\n",
      "[88]\ttrain-logloss:0.26393\teval-logloss:0.26989\n",
      "[89]\ttrain-logloss:0.26370\teval-logloss:0.26972\n",
      "[90]\ttrain-logloss:0.26349\teval-logloss:0.26954\n",
      "[91]\ttrain-logloss:0.26326\teval-logloss:0.26938\n",
      "[92]\ttrain-logloss:0.26301\teval-logloss:0.26918\n",
      "[93]\ttrain-logloss:0.26276\teval-logloss:0.26899\n",
      "[94]\ttrain-logloss:0.26257\teval-logloss:0.26886\n",
      "[95]\ttrain-logloss:0.26233\teval-logloss:0.26867\n",
      "[96]\ttrain-logloss:0.26209\teval-logloss:0.26849\n",
      "[97]\ttrain-logloss:0.26185\teval-logloss:0.26833\n",
      "[98]\ttrain-logloss:0.26164\teval-logloss:0.26818\n",
      "[99]\ttrain-logloss:0.26141\teval-logloss:0.26801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 16:00:40,434] Trial 1 finished with value: 0.26841053448074903 and parameters: {'eta': 0.00429997041703104, 'max_depth': 7, 'subsample': 0.689399873834518, 'colsample_bytree': 0.9813334908807003, 'min_child_weight': 1, 'lambda': 0.4627975799031548, 'alpha': 0.5251906016617869}. Best is trial 0 with value: 0.26690499174272747.\n",
      "/tmp/ipykernel_28044/3574405256.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"eta\": trial.suggest_loguniform(\"eta\", 1e-3, 0.1),\n",
      "/tmp/ipykernel_28044/3574405256.py:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.6, 1.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.6, 1.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-3, 10.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-3, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.28951\teval-logloss:0.28950\n",
      "[1]\ttrain-logloss:0.28943\teval-logloss:0.28943\n",
      "[2]\ttrain-logloss:0.28934\teval-logloss:0.28934\n",
      "[3]\ttrain-logloss:0.28926\teval-logloss:0.28927\n",
      "[4]\ttrain-logloss:0.28917\teval-logloss:0.28919\n",
      "[5]\ttrain-logloss:0.28909\teval-logloss:0.28911\n",
      "[6]\ttrain-logloss:0.28901\teval-logloss:0.28903\n",
      "[7]\ttrain-logloss:0.28892\teval-logloss:0.28895\n",
      "[8]\ttrain-logloss:0.28883\teval-logloss:0.28887\n",
      "[9]\ttrain-logloss:0.28874\teval-logloss:0.28878\n",
      "[10]\ttrain-logloss:0.28865\teval-logloss:0.28870\n",
      "[11]\ttrain-logloss:0.28857\teval-logloss:0.28863\n",
      "[12]\ttrain-logloss:0.28849\teval-logloss:0.28855\n",
      "[13]\ttrain-logloss:0.28840\teval-logloss:0.28847\n",
      "[14]\ttrain-logloss:0.28832\teval-logloss:0.28839\n",
      "[15]\ttrain-logloss:0.28823\teval-logloss:0.28832\n",
      "[16]\ttrain-logloss:0.28815\teval-logloss:0.28824\n",
      "[17]\ttrain-logloss:0.28806\teval-logloss:0.28816\n",
      "[18]\ttrain-logloss:0.28798\teval-logloss:0.28809\n",
      "[19]\ttrain-logloss:0.28790\teval-logloss:0.28801\n",
      "[20]\ttrain-logloss:0.28782\teval-logloss:0.28794\n",
      "[21]\ttrain-logloss:0.28773\teval-logloss:0.28786\n",
      "[22]\ttrain-logloss:0.28763\teval-logloss:0.28777\n",
      "[23]\ttrain-logloss:0.28755\teval-logloss:0.28769\n",
      "[24]\ttrain-logloss:0.28746\teval-logloss:0.28760\n",
      "[25]\ttrain-logloss:0.28737\teval-logloss:0.28752\n",
      "[26]\ttrain-logloss:0.28729\teval-logloss:0.28744\n",
      "[27]\ttrain-logloss:0.28720\teval-logloss:0.28736\n",
      "[28]\ttrain-logloss:0.28710\teval-logloss:0.28728\n",
      "[29]\ttrain-logloss:0.28701\teval-logloss:0.28719\n",
      "[30]\ttrain-logloss:0.28692\teval-logloss:0.28711\n",
      "[31]\ttrain-logloss:0.28684\teval-logloss:0.28703\n",
      "[32]\ttrain-logloss:0.28675\teval-logloss:0.28695\n",
      "[33]\ttrain-logloss:0.28667\teval-logloss:0.28687\n",
      "[34]\ttrain-logloss:0.28658\teval-logloss:0.28678\n",
      "[35]\ttrain-logloss:0.28649\teval-logloss:0.28670\n",
      "[36]\ttrain-logloss:0.28640\teval-logloss:0.28662\n",
      "[37]\ttrain-logloss:0.28632\teval-logloss:0.28654\n",
      "[38]\ttrain-logloss:0.28623\teval-logloss:0.28645\n",
      "[39]\ttrain-logloss:0.28614\teval-logloss:0.28637\n",
      "[40]\ttrain-logloss:0.28605\teval-logloss:0.28629\n",
      "[41]\ttrain-logloss:0.28596\teval-logloss:0.28620\n",
      "[42]\ttrain-logloss:0.28588\teval-logloss:0.28613\n",
      "[43]\ttrain-logloss:0.28580\teval-logloss:0.28606\n",
      "[44]\ttrain-logloss:0.28572\teval-logloss:0.28598\n",
      "[45]\ttrain-logloss:0.28563\teval-logloss:0.28590\n",
      "[46]\ttrain-logloss:0.28555\teval-logloss:0.28582\n",
      "[47]\ttrain-logloss:0.28546\teval-logloss:0.28574\n",
      "[48]\ttrain-logloss:0.28538\teval-logloss:0.28567\n",
      "[49]\ttrain-logloss:0.28531\teval-logloss:0.28560\n",
      "[50]\ttrain-logloss:0.28522\teval-logloss:0.28553\n",
      "[51]\ttrain-logloss:0.28515\teval-logloss:0.28546\n",
      "[52]\ttrain-logloss:0.28507\teval-logloss:0.28539\n",
      "[53]\ttrain-logloss:0.28499\teval-logloss:0.28532\n",
      "[54]\ttrain-logloss:0.28492\teval-logloss:0.28525\n",
      "[55]\ttrain-logloss:0.28483\teval-logloss:0.28518\n",
      "[56]\ttrain-logloss:0.28474\teval-logloss:0.28510\n",
      "[57]\ttrain-logloss:0.28466\teval-logloss:0.28502\n",
      "[58]\ttrain-logloss:0.28458\teval-logloss:0.28494\n",
      "[59]\ttrain-logloss:0.28451\teval-logloss:0.28488\n",
      "[60]\ttrain-logloss:0.28443\teval-logloss:0.28480\n",
      "[61]\ttrain-logloss:0.28435\teval-logloss:0.28473\n",
      "[62]\ttrain-logloss:0.28427\teval-logloss:0.28466\n",
      "[63]\ttrain-logloss:0.28419\teval-logloss:0.28459\n",
      "[64]\ttrain-logloss:0.28412\teval-logloss:0.28452\n",
      "[65]\ttrain-logloss:0.28404\teval-logloss:0.28444\n",
      "[66]\ttrain-logloss:0.28395\teval-logloss:0.28436\n",
      "[67]\ttrain-logloss:0.28388\teval-logloss:0.28429\n",
      "[68]\ttrain-logloss:0.28381\teval-logloss:0.28422\n",
      "[69]\ttrain-logloss:0.28373\teval-logloss:0.28415\n",
      "[70]\ttrain-logloss:0.28366\teval-logloss:0.28409\n",
      "[71]\ttrain-logloss:0.28358\teval-logloss:0.28401\n",
      "[72]\ttrain-logloss:0.28349\teval-logloss:0.28393\n",
      "[73]\ttrain-logloss:0.28342\teval-logloss:0.28387\n",
      "[74]\ttrain-logloss:0.28336\teval-logloss:0.28381\n",
      "[75]\ttrain-logloss:0.28329\teval-logloss:0.28374\n",
      "[76]\ttrain-logloss:0.28321\teval-logloss:0.28367\n",
      "[77]\ttrain-logloss:0.28312\teval-logloss:0.28359\n",
      "[78]\ttrain-logloss:0.28305\teval-logloss:0.28353\n",
      "[79]\ttrain-logloss:0.28298\teval-logloss:0.28346\n",
      "[80]\ttrain-logloss:0.28290\teval-logloss:0.28339\n",
      "[81]\ttrain-logloss:0.28282\teval-logloss:0.28331\n",
      "[82]\ttrain-logloss:0.28274\teval-logloss:0.28324\n",
      "[83]\ttrain-logloss:0.28267\teval-logloss:0.28318\n",
      "[84]\ttrain-logloss:0.28259\teval-logloss:0.28310\n",
      "[85]\ttrain-logloss:0.28252\teval-logloss:0.28303\n",
      "[86]\ttrain-logloss:0.28244\teval-logloss:0.28297\n",
      "[87]\ttrain-logloss:0.28238\teval-logloss:0.28291\n",
      "[88]\ttrain-logloss:0.28230\teval-logloss:0.28284\n",
      "[89]\ttrain-logloss:0.28222\teval-logloss:0.28277\n",
      "[90]\ttrain-logloss:0.28214\teval-logloss:0.28269\n",
      "[91]\ttrain-logloss:0.28206\teval-logloss:0.28262\n",
      "[92]\ttrain-logloss:0.28198\teval-logloss:0.28254\n",
      "[93]\ttrain-logloss:0.28191\teval-logloss:0.28248\n",
      "[94]\ttrain-logloss:0.28183\teval-logloss:0.28241\n",
      "[95]\ttrain-logloss:0.28175\teval-logloss:0.28233\n",
      "[96]\ttrain-logloss:0.28167\teval-logloss:0.28226\n",
      "[97]\ttrain-logloss:0.28159\teval-logloss:0.28219\n",
      "[98]\ttrain-logloss:0.28152\teval-logloss:0.28212\n",
      "[99]\ttrain-logloss:0.28143\teval-logloss:0.28204\n",
      "[0]\ttrain-logloss:0.28951\teval-logloss:0.28950\n",
      "[1]\ttrain-logloss:0.28943\teval-logloss:0.28943\n",
      "[2]\ttrain-logloss:0.28934\teval-logloss:0.28934\n",
      "[3]\ttrain-logloss:0.28926\teval-logloss:0.28927\n",
      "[4]\ttrain-logloss:0.28917\teval-logloss:0.28919\n",
      "[5]\ttrain-logloss:0.28909\teval-logloss:0.28911\n",
      "[6]\ttrain-logloss:0.28901\teval-logloss:0.28903\n",
      "[7]\ttrain-logloss:0.28892\teval-logloss:0.28895\n",
      "[8]\ttrain-logloss:0.28883\teval-logloss:0.28887\n",
      "[9]\ttrain-logloss:0.28874\teval-logloss:0.28879\n",
      "[10]\ttrain-logloss:0.28865\teval-logloss:0.28871\n",
      "[11]\ttrain-logloss:0.28857\teval-logloss:0.28863\n",
      "[12]\ttrain-logloss:0.28849\teval-logloss:0.28855\n",
      "[13]\ttrain-logloss:0.28840\teval-logloss:0.28847\n",
      "[14]\ttrain-logloss:0.28832\teval-logloss:0.28839\n",
      "[15]\ttrain-logloss:0.28824\teval-logloss:0.28831\n",
      "[16]\ttrain-logloss:0.28816\teval-logloss:0.28824\n",
      "[17]\ttrain-logloss:0.28807\teval-logloss:0.28816\n",
      "[18]\ttrain-logloss:0.28799\teval-logloss:0.28808\n",
      "[19]\ttrain-logloss:0.28790\teval-logloss:0.28801\n",
      "[20]\ttrain-logloss:0.28782\teval-logloss:0.28794\n",
      "[21]\ttrain-logloss:0.28773\teval-logloss:0.28785\n",
      "[22]\ttrain-logloss:0.28764\teval-logloss:0.28777\n",
      "[23]\ttrain-logloss:0.28756\teval-logloss:0.28769\n",
      "[24]\ttrain-logloss:0.28747\teval-logloss:0.28760\n",
      "[25]\ttrain-logloss:0.28738\teval-logloss:0.28752\n",
      "[26]\ttrain-logloss:0.28730\teval-logloss:0.28745\n",
      "[27]\ttrain-logloss:0.28720\teval-logloss:0.28736\n",
      "[28]\ttrain-logloss:0.28711\teval-logloss:0.28728\n",
      "[29]\ttrain-logloss:0.28702\teval-logloss:0.28719\n",
      "[30]\ttrain-logloss:0.28693\teval-logloss:0.28711\n",
      "[31]\ttrain-logloss:0.28685\teval-logloss:0.28704\n",
      "[32]\ttrain-logloss:0.28676\teval-logloss:0.28696\n",
      "[33]\ttrain-logloss:0.28667\teval-logloss:0.28688\n",
      "[34]\ttrain-logloss:0.28659\teval-logloss:0.28680\n",
      "[35]\ttrain-logloss:0.28650\teval-logloss:0.28672\n",
      "[36]\ttrain-logloss:0.28641\teval-logloss:0.28664\n",
      "[37]\ttrain-logloss:0.28633\teval-logloss:0.28656\n",
      "[38]\ttrain-logloss:0.28624\teval-logloss:0.28648\n",
      "[39]\ttrain-logloss:0.28615\teval-logloss:0.28640\n",
      "[40]\ttrain-logloss:0.28606\teval-logloss:0.28631\n",
      "[41]\ttrain-logloss:0.28597\teval-logloss:0.28623\n",
      "[42]\ttrain-logloss:0.28590\teval-logloss:0.28616\n",
      "[43]\ttrain-logloss:0.28582\teval-logloss:0.28609\n",
      "[44]\ttrain-logloss:0.28573\teval-logloss:0.28601\n",
      "[45]\ttrain-logloss:0.28564\teval-logloss:0.28593\n",
      "[46]\ttrain-logloss:0.28557\teval-logloss:0.28585\n",
      "[47]\ttrain-logloss:0.28548\teval-logloss:0.28577\n",
      "[48]\ttrain-logloss:0.28540\teval-logloss:0.28571\n",
      "[49]\ttrain-logloss:0.28532\teval-logloss:0.28563\n",
      "[50]\ttrain-logloss:0.28524\teval-logloss:0.28556\n",
      "[51]\ttrain-logloss:0.28517\teval-logloss:0.28549\n",
      "[52]\ttrain-logloss:0.28508\teval-logloss:0.28542\n",
      "[53]\ttrain-logloss:0.28501\teval-logloss:0.28535\n",
      "[54]\ttrain-logloss:0.28494\teval-logloss:0.28528\n",
      "[55]\ttrain-logloss:0.28485\teval-logloss:0.28519\n",
      "[56]\ttrain-logloss:0.28476\teval-logloss:0.28512\n",
      "[57]\ttrain-logloss:0.28468\teval-logloss:0.28505\n",
      "[58]\ttrain-logloss:0.28460\teval-logloss:0.28497\n",
      "[59]\ttrain-logloss:0.28453\teval-logloss:0.28491\n",
      "[60]\ttrain-logloss:0.28445\teval-logloss:0.28483\n",
      "[61]\ttrain-logloss:0.28437\teval-logloss:0.28476\n",
      "[62]\ttrain-logloss:0.28429\teval-logloss:0.28469\n",
      "[63]\ttrain-logloss:0.28421\teval-logloss:0.28462\n",
      "[64]\ttrain-logloss:0.28414\teval-logloss:0.28455\n",
      "[65]\ttrain-logloss:0.28405\teval-logloss:0.28447\n",
      "[66]\ttrain-logloss:0.28397\teval-logloss:0.28440\n",
      "[67]\ttrain-logloss:0.28389\teval-logloss:0.28433\n",
      "[68]\ttrain-logloss:0.28382\teval-logloss:0.28426\n",
      "[69]\ttrain-logloss:0.28374\teval-logloss:0.28419\n",
      "[70]\ttrain-logloss:0.28367\teval-logloss:0.28413\n",
      "[71]\ttrain-logloss:0.28359\teval-logloss:0.28405\n",
      "[72]\ttrain-logloss:0.28350\teval-logloss:0.28398\n",
      "[73]\ttrain-logloss:0.28343\teval-logloss:0.28391\n",
      "[74]\ttrain-logloss:0.28336\teval-logloss:0.28385\n",
      "[75]\ttrain-logloss:0.28329\teval-logloss:0.28378\n",
      "[76]\ttrain-logloss:0.28321\teval-logloss:0.28371\n",
      "[77]\ttrain-logloss:0.28313\teval-logloss:0.28363\n",
      "[78]\ttrain-logloss:0.28306\teval-logloss:0.28357\n",
      "[79]\ttrain-logloss:0.28299\teval-logloss:0.28350\n",
      "[80]\ttrain-logloss:0.28291\teval-logloss:0.28343\n",
      "[81]\ttrain-logloss:0.28282\teval-logloss:0.28336\n",
      "[82]\ttrain-logloss:0.28274\teval-logloss:0.28329\n",
      "[83]\ttrain-logloss:0.28267\teval-logloss:0.28322\n",
      "[84]\ttrain-logloss:0.28259\teval-logloss:0.28315\n",
      "[85]\ttrain-logloss:0.28252\teval-logloss:0.28309\n",
      "[86]\ttrain-logloss:0.28245\teval-logloss:0.28302\n",
      "[87]\ttrain-logloss:0.28238\teval-logloss:0.28295\n",
      "[88]\ttrain-logloss:0.28230\teval-logloss:0.28288\n",
      "[89]\ttrain-logloss:0.28223\teval-logloss:0.28282\n",
      "[90]\ttrain-logloss:0.28215\teval-logloss:0.28274\n",
      "[91]\ttrain-logloss:0.28207\teval-logloss:0.28267\n",
      "[92]\ttrain-logloss:0.28199\teval-logloss:0.28259\n",
      "[93]\ttrain-logloss:0.28192\teval-logloss:0.28253\n",
      "[94]\ttrain-logloss:0.28184\teval-logloss:0.28246\n",
      "[95]\ttrain-logloss:0.28176\teval-logloss:0.28239\n",
      "[96]\ttrain-logloss:0.28168\teval-logloss:0.28232\n",
      "[97]\ttrain-logloss:0.28160\teval-logloss:0.28225\n",
      "[98]\ttrain-logloss:0.28153\teval-logloss:0.28219\n",
      "[99]\ttrain-logloss:0.28145\teval-logloss:0.28212\n",
      "[0]\ttrain-logloss:0.28951\teval-logloss:0.28950\n",
      "[1]\ttrain-logloss:0.28943\teval-logloss:0.28943\n",
      "[2]\ttrain-logloss:0.28933\teval-logloss:0.28935\n",
      "[3]\ttrain-logloss:0.28925\teval-logloss:0.28927\n",
      "[4]\ttrain-logloss:0.28916\teval-logloss:0.28920\n",
      "[5]\ttrain-logloss:0.28907\teval-logloss:0.28912\n",
      "[6]\ttrain-logloss:0.28899\teval-logloss:0.28904\n",
      "[7]\ttrain-logloss:0.28890\teval-logloss:0.28897\n",
      "[8]\ttrain-logloss:0.28881\teval-logloss:0.28889\n",
      "[9]\ttrain-logloss:0.28872\teval-logloss:0.28881\n",
      "[10]\ttrain-logloss:0.28863\teval-logloss:0.28873\n",
      "[11]\ttrain-logloss:0.28855\teval-logloss:0.28865\n",
      "[12]\ttrain-logloss:0.28847\teval-logloss:0.28858\n",
      "[13]\ttrain-logloss:0.28837\teval-logloss:0.28850\n",
      "[14]\ttrain-logloss:0.28830\teval-logloss:0.28842\n",
      "[15]\ttrain-logloss:0.28821\teval-logloss:0.28834\n",
      "[16]\ttrain-logloss:0.28813\teval-logloss:0.28827\n",
      "[17]\ttrain-logloss:0.28804\teval-logloss:0.28818\n",
      "[18]\ttrain-logloss:0.28796\teval-logloss:0.28811\n",
      "[19]\ttrain-logloss:0.28787\teval-logloss:0.28804\n",
      "[20]\ttrain-logloss:0.28779\teval-logloss:0.28796\n",
      "[21]\ttrain-logloss:0.28769\teval-logloss:0.28788\n",
      "[22]\ttrain-logloss:0.28760\teval-logloss:0.28780\n",
      "[23]\ttrain-logloss:0.28752\teval-logloss:0.28772\n",
      "[24]\ttrain-logloss:0.28742\teval-logloss:0.28765\n",
      "[25]\ttrain-logloss:0.28734\teval-logloss:0.28757\n",
      "[26]\ttrain-logloss:0.28725\teval-logloss:0.28749\n",
      "[27]\ttrain-logloss:0.28715\teval-logloss:0.28741\n",
      "[28]\ttrain-logloss:0.28706\teval-logloss:0.28733\n",
      "[29]\ttrain-logloss:0.28697\teval-logloss:0.28726\n",
      "[30]\ttrain-logloss:0.28688\teval-logloss:0.28718\n",
      "[31]\ttrain-logloss:0.28680\teval-logloss:0.28710\n",
      "[32]\ttrain-logloss:0.28670\teval-logloss:0.28702\n",
      "[33]\ttrain-logloss:0.28662\teval-logloss:0.28694\n",
      "[34]\ttrain-logloss:0.28652\teval-logloss:0.28686\n",
      "[35]\ttrain-logloss:0.28643\teval-logloss:0.28679\n",
      "[36]\ttrain-logloss:0.28634\teval-logloss:0.28671\n",
      "[37]\ttrain-logloss:0.28626\teval-logloss:0.28664\n",
      "[38]\ttrain-logloss:0.28616\teval-logloss:0.28656\n",
      "[39]\ttrain-logloss:0.28607\teval-logloss:0.28648\n",
      "[40]\ttrain-logloss:0.28598\teval-logloss:0.28640\n",
      "[41]\ttrain-logloss:0.28589\teval-logloss:0.28632\n",
      "[42]\ttrain-logloss:0.28582\teval-logloss:0.28626\n",
      "[43]\ttrain-logloss:0.28574\teval-logloss:0.28618\n",
      "[44]\ttrain-logloss:0.28565\teval-logloss:0.28611\n",
      "[45]\ttrain-logloss:0.28557\teval-logloss:0.28603\n",
      "[46]\ttrain-logloss:0.28548\teval-logloss:0.28596\n",
      "[47]\ttrain-logloss:0.28539\teval-logloss:0.28589\n",
      "[48]\ttrain-logloss:0.28531\teval-logloss:0.28581\n",
      "[49]\ttrain-logloss:0.28523\teval-logloss:0.28574\n",
      "[50]\ttrain-logloss:0.28515\teval-logloss:0.28566\n",
      "[51]\ttrain-logloss:0.28508\teval-logloss:0.28560\n",
      "[52]\ttrain-logloss:0.28500\teval-logloss:0.28553\n",
      "[53]\ttrain-logloss:0.28492\teval-logloss:0.28546\n",
      "[54]\ttrain-logloss:0.28484\teval-logloss:0.28539\n",
      "[55]\ttrain-logloss:0.28475\teval-logloss:0.28531\n",
      "[56]\ttrain-logloss:0.28466\teval-logloss:0.28524\n",
      "[57]\ttrain-logloss:0.28458\teval-logloss:0.28517\n",
      "[58]\ttrain-logloss:0.28450\teval-logloss:0.28510\n",
      "[59]\ttrain-logloss:0.28443\teval-logloss:0.28503\n",
      "[60]\ttrain-logloss:0.28434\teval-logloss:0.28496\n",
      "[61]\ttrain-logloss:0.28427\teval-logloss:0.28489\n",
      "[62]\ttrain-logloss:0.28418\teval-logloss:0.28482\n",
      "[63]\ttrain-logloss:0.28410\teval-logloss:0.28475\n",
      "[64]\ttrain-logloss:0.28403\teval-logloss:0.28468\n",
      "[65]\ttrain-logloss:0.28394\teval-logloss:0.28461\n",
      "[66]\ttrain-logloss:0.28385\teval-logloss:0.28454\n",
      "[67]\ttrain-logloss:0.28378\teval-logloss:0.28447\n",
      "[68]\ttrain-logloss:0.28371\teval-logloss:0.28440\n",
      "[69]\ttrain-logloss:0.28363\teval-logloss:0.28433\n",
      "[70]\ttrain-logloss:0.28356\teval-logloss:0.28427\n",
      "[71]\ttrain-logloss:0.28347\teval-logloss:0.28420\n",
      "[72]\ttrain-logloss:0.28338\teval-logloss:0.28413\n",
      "[73]\ttrain-logloss:0.28331\teval-logloss:0.28406\n",
      "[74]\ttrain-logloss:0.28324\teval-logloss:0.28400\n",
      "[75]\ttrain-logloss:0.28318\teval-logloss:0.28394\n",
      "[76]\ttrain-logloss:0.28309\teval-logloss:0.28387\n",
      "[77]\ttrain-logloss:0.28301\teval-logloss:0.28379\n",
      "[78]\ttrain-logloss:0.28293\teval-logloss:0.28373\n",
      "[79]\ttrain-logloss:0.28286\teval-logloss:0.28366\n",
      "[80]\ttrain-logloss:0.28277\teval-logloss:0.28359\n",
      "[81]\ttrain-logloss:0.28269\teval-logloss:0.28353\n",
      "[82]\ttrain-logloss:0.28261\teval-logloss:0.28346\n",
      "[83]\ttrain-logloss:0.28254\teval-logloss:0.28340\n",
      "[84]\ttrain-logloss:0.28246\teval-logloss:0.28333\n",
      "[85]\ttrain-logloss:0.28239\teval-logloss:0.28326\n",
      "[86]\ttrain-logloss:0.28232\teval-logloss:0.28319\n",
      "[87]\ttrain-logloss:0.28225\teval-logloss:0.28313\n",
      "[88]\ttrain-logloss:0.28217\teval-logloss:0.28306\n",
      "[89]\ttrain-logloss:0.28209\teval-logloss:0.28299\n",
      "[90]\ttrain-logloss:0.28201\teval-logloss:0.28293\n",
      "[91]\ttrain-logloss:0.28193\teval-logloss:0.28285\n",
      "[92]\ttrain-logloss:0.28185\teval-logloss:0.28279\n",
      "[93]\ttrain-logloss:0.28178\teval-logloss:0.28272\n",
      "[94]\ttrain-logloss:0.28170\teval-logloss:0.28266\n",
      "[95]\ttrain-logloss:0.28162\teval-logloss:0.28259\n",
      "[96]\ttrain-logloss:0.28153\teval-logloss:0.28252\n",
      "[97]\ttrain-logloss:0.28145\teval-logloss:0.28245\n",
      "[98]\ttrain-logloss:0.28138\teval-logloss:0.28238\n",
      "[99]\ttrain-logloss:0.28130\teval-logloss:0.28231\n",
      "[0]\ttrain-logloss:0.28950\teval-logloss:0.28950\n",
      "[1]\ttrain-logloss:0.28942\teval-logloss:0.28942\n",
      "[2]\ttrain-logloss:0.28933\teval-logloss:0.28934\n",
      "[3]\ttrain-logloss:0.28925\teval-logloss:0.28926\n",
      "[4]\ttrain-logloss:0.28917\teval-logloss:0.28918\n",
      "[5]\ttrain-logloss:0.28909\teval-logloss:0.28910\n",
      "[6]\ttrain-logloss:0.28900\teval-logloss:0.28902\n",
      "[7]\ttrain-logloss:0.28891\teval-logloss:0.28894\n",
      "[8]\ttrain-logloss:0.28882\teval-logloss:0.28886\n",
      "[9]\ttrain-logloss:0.28873\teval-logloss:0.28877\n",
      "[10]\ttrain-logloss:0.28865\teval-logloss:0.28869\n",
      "[11]\ttrain-logloss:0.28857\teval-logloss:0.28861\n",
      "[12]\ttrain-logloss:0.28849\teval-logloss:0.28854\n",
      "[13]\ttrain-logloss:0.28840\teval-logloss:0.28845\n",
      "[14]\ttrain-logloss:0.28832\teval-logloss:0.28837\n",
      "[15]\ttrain-logloss:0.28824\teval-logloss:0.28830\n",
      "[16]\ttrain-logloss:0.28816\teval-logloss:0.28822\n",
      "[17]\ttrain-logloss:0.28807\teval-logloss:0.28814\n",
      "[18]\ttrain-logloss:0.28799\teval-logloss:0.28806\n",
      "[19]\ttrain-logloss:0.28790\teval-logloss:0.28798\n",
      "[20]\ttrain-logloss:0.28782\teval-logloss:0.28791\n",
      "[21]\ttrain-logloss:0.28773\teval-logloss:0.28782\n",
      "[22]\ttrain-logloss:0.28764\teval-logloss:0.28773\n",
      "[23]\ttrain-logloss:0.28756\teval-logloss:0.28766\n",
      "[24]\ttrain-logloss:0.28747\teval-logloss:0.28757\n",
      "[25]\ttrain-logloss:0.28739\teval-logloss:0.28749\n",
      "[26]\ttrain-logloss:0.28730\teval-logloss:0.28741\n",
      "[27]\ttrain-logloss:0.28721\teval-logloss:0.28733\n",
      "[28]\ttrain-logloss:0.28712\teval-logloss:0.28724\n",
      "[29]\ttrain-logloss:0.28703\teval-logloss:0.28715\n",
      "[30]\ttrain-logloss:0.28694\teval-logloss:0.28707\n",
      "[31]\ttrain-logloss:0.28686\teval-logloss:0.28699\n",
      "[32]\ttrain-logloss:0.28677\teval-logloss:0.28691\n",
      "[33]\ttrain-logloss:0.28669\teval-logloss:0.28683\n",
      "[34]\ttrain-logloss:0.28660\teval-logloss:0.28675\n",
      "[35]\ttrain-logloss:0.28651\teval-logloss:0.28666\n",
      "[36]\ttrain-logloss:0.28642\teval-logloss:0.28658\n",
      "[37]\ttrain-logloss:0.28634\teval-logloss:0.28650\n",
      "[38]\ttrain-logloss:0.28625\teval-logloss:0.28641\n",
      "[39]\ttrain-logloss:0.28616\teval-logloss:0.28633\n",
      "[40]\ttrain-logloss:0.28608\teval-logloss:0.28624\n",
      "[41]\ttrain-logloss:0.28599\teval-logloss:0.28616\n",
      "[42]\ttrain-logloss:0.28591\teval-logloss:0.28608\n",
      "[43]\ttrain-logloss:0.28583\teval-logloss:0.28601\n",
      "[44]\ttrain-logloss:0.28574\teval-logloss:0.28593\n",
      "[45]\ttrain-logloss:0.28566\teval-logloss:0.28585\n",
      "[46]\ttrain-logloss:0.28558\teval-logloss:0.28577\n",
      "[47]\ttrain-logloss:0.28549\teval-logloss:0.28569\n",
      "[48]\ttrain-logloss:0.28541\teval-logloss:0.28562\n",
      "[49]\ttrain-logloss:0.28534\teval-logloss:0.28555\n",
      "[50]\ttrain-logloss:0.28526\teval-logloss:0.28548\n",
      "[51]\ttrain-logloss:0.28519\teval-logloss:0.28541\n",
      "[52]\ttrain-logloss:0.28511\teval-logloss:0.28533\n",
      "[53]\ttrain-logloss:0.28503\teval-logloss:0.28526\n",
      "[54]\ttrain-logloss:0.28496\teval-logloss:0.28519\n",
      "[55]\ttrain-logloss:0.28487\teval-logloss:0.28511\n",
      "[56]\ttrain-logloss:0.28478\teval-logloss:0.28502\n",
      "[57]\ttrain-logloss:0.28470\teval-logloss:0.28494\n",
      "[58]\ttrain-logloss:0.28462\teval-logloss:0.28487\n",
      "[59]\ttrain-logloss:0.28454\teval-logloss:0.28480\n",
      "[60]\ttrain-logloss:0.28446\teval-logloss:0.28472\n",
      "[61]\ttrain-logloss:0.28438\teval-logloss:0.28465\n",
      "[62]\ttrain-logloss:0.28430\teval-logloss:0.28458\n",
      "[63]\ttrain-logloss:0.28423\teval-logloss:0.28451\n",
      "[64]\ttrain-logloss:0.28415\teval-logloss:0.28444\n",
      "[65]\ttrain-logloss:0.28407\teval-logloss:0.28436\n",
      "[66]\ttrain-logloss:0.28398\teval-logloss:0.28428\n",
      "[67]\ttrain-logloss:0.28391\teval-logloss:0.28421\n",
      "[68]\ttrain-logloss:0.28384\teval-logloss:0.28414\n",
      "[69]\ttrain-logloss:0.28376\teval-logloss:0.28407\n",
      "[70]\ttrain-logloss:0.28369\teval-logloss:0.28400\n",
      "[71]\ttrain-logloss:0.28360\teval-logloss:0.28392\n",
      "[72]\ttrain-logloss:0.28352\teval-logloss:0.28385\n",
      "[73]\ttrain-logloss:0.28345\teval-logloss:0.28378\n",
      "[74]\ttrain-logloss:0.28338\teval-logloss:0.28372\n",
      "[75]\ttrain-logloss:0.28331\teval-logloss:0.28365\n",
      "[76]\ttrain-logloss:0.28323\teval-logloss:0.28358\n",
      "[77]\ttrain-logloss:0.28315\teval-logloss:0.28350\n",
      "[78]\ttrain-logloss:0.28308\teval-logloss:0.28343\n",
      "[79]\ttrain-logloss:0.28301\teval-logloss:0.28337\n",
      "[80]\ttrain-logloss:0.28293\teval-logloss:0.28329\n",
      "[81]\ttrain-logloss:0.28285\teval-logloss:0.28321\n",
      "[82]\ttrain-logloss:0.28277\teval-logloss:0.28314\n",
      "[83]\ttrain-logloss:0.28270\teval-logloss:0.28307\n",
      "[84]\ttrain-logloss:0.28261\teval-logloss:0.28300\n",
      "[85]\ttrain-logloss:0.28254\teval-logloss:0.28293\n",
      "[86]\ttrain-logloss:0.28247\teval-logloss:0.28287\n",
      "[87]\ttrain-logloss:0.28240\teval-logloss:0.28281\n",
      "[88]\ttrain-logloss:0.28232\teval-logloss:0.28273\n",
      "[89]\ttrain-logloss:0.28225\teval-logloss:0.28266\n",
      "[90]\ttrain-logloss:0.28217\teval-logloss:0.28259\n",
      "[91]\ttrain-logloss:0.28209\teval-logloss:0.28251\n",
      "[92]\ttrain-logloss:0.28201\teval-logloss:0.28244\n",
      "[93]\ttrain-logloss:0.28194\teval-logloss:0.28237\n",
      "[94]\ttrain-logloss:0.28187\teval-logloss:0.28231\n",
      "[95]\ttrain-logloss:0.28178\teval-logloss:0.28223\n",
      "[96]\ttrain-logloss:0.28171\teval-logloss:0.28216\n",
      "[97]\ttrain-logloss:0.28163\teval-logloss:0.28209\n",
      "[98]\ttrain-logloss:0.28155\teval-logloss:0.28202\n",
      "[99]\ttrain-logloss:0.28148\teval-logloss:0.28195\n",
      "[0]\ttrain-logloss:0.28949\teval-logloss:0.28956\n",
      "[1]\ttrain-logloss:0.28941\teval-logloss:0.28949\n",
      "[2]\ttrain-logloss:0.28932\teval-logloss:0.28940\n",
      "[3]\ttrain-logloss:0.28924\teval-logloss:0.28933\n",
      "[4]\ttrain-logloss:0.28916\teval-logloss:0.28925\n",
      "[5]\ttrain-logloss:0.28907\teval-logloss:0.28917\n",
      "[6]\ttrain-logloss:0.28899\teval-logloss:0.28908\n",
      "[7]\ttrain-logloss:0.28890\teval-logloss:0.28901\n",
      "[8]\ttrain-logloss:0.28881\teval-logloss:0.28892\n",
      "[9]\ttrain-logloss:0.28872\teval-logloss:0.28884\n",
      "[10]\ttrain-logloss:0.28864\teval-logloss:0.28876\n",
      "[11]\ttrain-logloss:0.28855\teval-logloss:0.28868\n",
      "[12]\ttrain-logloss:0.28847\teval-logloss:0.28861\n",
      "[13]\ttrain-logloss:0.28838\teval-logloss:0.28852\n",
      "[14]\ttrain-logloss:0.28830\teval-logloss:0.28844\n",
      "[15]\ttrain-logloss:0.28821\teval-logloss:0.28836\n",
      "[16]\ttrain-logloss:0.28813\teval-logloss:0.28828\n",
      "[17]\ttrain-logloss:0.28804\teval-logloss:0.28820\n",
      "[18]\ttrain-logloss:0.28796\teval-logloss:0.28813\n",
      "[19]\ttrain-logloss:0.28788\teval-logloss:0.28805\n",
      "[20]\ttrain-logloss:0.28780\teval-logloss:0.28798\n",
      "[21]\ttrain-logloss:0.28771\teval-logloss:0.28789\n",
      "[22]\ttrain-logloss:0.28761\teval-logloss:0.28781\n",
      "[23]\ttrain-logloss:0.28753\teval-logloss:0.28774\n",
      "[24]\ttrain-logloss:0.28744\teval-logloss:0.28765\n",
      "[25]\ttrain-logloss:0.28735\teval-logloss:0.28757\n",
      "[26]\ttrain-logloss:0.28727\teval-logloss:0.28749\n",
      "[27]\ttrain-logloss:0.28718\teval-logloss:0.28740\n",
      "[28]\ttrain-logloss:0.28709\teval-logloss:0.28732\n",
      "[29]\ttrain-logloss:0.28699\teval-logloss:0.28723\n",
      "[30]\ttrain-logloss:0.28691\teval-logloss:0.28715\n",
      "[31]\ttrain-logloss:0.28683\teval-logloss:0.28707\n",
      "[32]\ttrain-logloss:0.28673\teval-logloss:0.28699\n",
      "[33]\ttrain-logloss:0.28665\teval-logloss:0.28692\n",
      "[34]\ttrain-logloss:0.28656\teval-logloss:0.28683\n",
      "[35]\ttrain-logloss:0.28647\teval-logloss:0.28675\n",
      "[36]\ttrain-logloss:0.28638\teval-logloss:0.28667\n",
      "[37]\ttrain-logloss:0.28630\teval-logloss:0.28659\n",
      "[38]\ttrain-logloss:0.28621\teval-logloss:0.28650\n",
      "[39]\ttrain-logloss:0.28612\teval-logloss:0.28642\n",
      "[40]\ttrain-logloss:0.28603\teval-logloss:0.28634\n",
      "[41]\ttrain-logloss:0.28594\teval-logloss:0.28626\n",
      "[42]\ttrain-logloss:0.28586\teval-logloss:0.28619\n",
      "[43]\ttrain-logloss:0.28579\teval-logloss:0.28612\n",
      "[44]\ttrain-logloss:0.28570\teval-logloss:0.28604\n",
      "[45]\ttrain-logloss:0.28561\teval-logloss:0.28596\n",
      "[46]\ttrain-logloss:0.28553\teval-logloss:0.28588\n",
      "[47]\ttrain-logloss:0.28544\teval-logloss:0.28580\n",
      "[48]\ttrain-logloss:0.28537\teval-logloss:0.28572\n",
      "[49]\ttrain-logloss:0.28529\teval-logloss:0.28565\n",
      "[50]\ttrain-logloss:0.28521\teval-logloss:0.28558\n",
      "[51]\ttrain-logloss:0.28514\teval-logloss:0.28551\n",
      "[52]\ttrain-logloss:0.28506\teval-logloss:0.28543\n",
      "[53]\ttrain-logloss:0.28498\teval-logloss:0.28536\n",
      "[54]\ttrain-logloss:0.28490\teval-logloss:0.28529\n",
      "[55]\ttrain-logloss:0.28482\teval-logloss:0.28521\n",
      "[56]\ttrain-logloss:0.28473\teval-logloss:0.28513\n",
      "[57]\ttrain-logloss:0.28465\teval-logloss:0.28506\n",
      "[58]\ttrain-logloss:0.28457\teval-logloss:0.28499\n",
      "[59]\ttrain-logloss:0.28450\teval-logloss:0.28492\n",
      "[60]\ttrain-logloss:0.28442\teval-logloss:0.28485\n",
      "[61]\ttrain-logloss:0.28434\teval-logloss:0.28478\n",
      "[62]\ttrain-logloss:0.28426\teval-logloss:0.28470\n",
      "[63]\ttrain-logloss:0.28418\teval-logloss:0.28463\n",
      "[64]\ttrain-logloss:0.28411\teval-logloss:0.28456\n",
      "[65]\ttrain-logloss:0.28403\teval-logloss:0.28448\n",
      "[66]\ttrain-logloss:0.28394\teval-logloss:0.28440\n",
      "[67]\ttrain-logloss:0.28387\teval-logloss:0.28433\n",
      "[68]\ttrain-logloss:0.28380\teval-logloss:0.28427\n",
      "[69]\ttrain-logloss:0.28372\teval-logloss:0.28420\n",
      "[70]\ttrain-logloss:0.28365\teval-logloss:0.28414\n",
      "[71]\ttrain-logloss:0.28357\teval-logloss:0.28406\n",
      "[72]\ttrain-logloss:0.28348\teval-logloss:0.28398\n",
      "[73]\ttrain-logloss:0.28340\teval-logloss:0.28391\n",
      "[74]\ttrain-logloss:0.28333\teval-logloss:0.28385\n",
      "[75]\ttrain-logloss:0.28326\teval-logloss:0.28379\n",
      "[76]\ttrain-logloss:0.28318\teval-logloss:0.28371\n",
      "[77]\ttrain-logloss:0.28310\teval-logloss:0.28364\n",
      "[78]\ttrain-logloss:0.28303\teval-logloss:0.28357\n",
      "[79]\ttrain-logloss:0.28295\teval-logloss:0.28350\n",
      "[80]\ttrain-logloss:0.28288\teval-logloss:0.28343\n",
      "[81]\ttrain-logloss:0.28280\teval-logloss:0.28335\n",
      "[82]\ttrain-logloss:0.28272\teval-logloss:0.28328\n",
      "[83]\ttrain-logloss:0.28264\teval-logloss:0.28322\n",
      "[84]\ttrain-logloss:0.28256\teval-logloss:0.28314\n",
      "[85]\ttrain-logloss:0.28249\teval-logloss:0.28307\n",
      "[86]\ttrain-logloss:0.28242\teval-logloss:0.28300\n",
      "[87]\ttrain-logloss:0.28235\teval-logloss:0.28294\n",
      "[88]\ttrain-logloss:0.28227\teval-logloss:0.28287\n",
      "[89]\ttrain-logloss:0.28219\teval-logloss:0.28280\n",
      "[90]\ttrain-logloss:0.28211\teval-logloss:0.28272\n",
      "[91]\ttrain-logloss:0.28204\teval-logloss:0.28265\n",
      "[92]\ttrain-logloss:0.28196\teval-logloss:0.28258\n",
      "[93]\ttrain-logloss:0.28189\teval-logloss:0.28252\n",
      "[94]\ttrain-logloss:0.28181\teval-logloss:0.28245\n",
      "[95]\ttrain-logloss:0.28173\teval-logloss:0.28238\n",
      "[96]\ttrain-logloss:0.28165\teval-logloss:0.28230\n",
      "[97]\ttrain-logloss:0.28157\teval-logloss:0.28222\n",
      "[98]\ttrain-logloss:0.28150\teval-logloss:0.28216\n",
      "[99]\ttrain-logloss:0.28142\teval-logloss:0.28209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 16:01:41,872] Trial 2 finished with value: 0.28210079802632054 and parameters: {'eta': 0.0013615247289670218, 'max_depth': 9, 'subsample': 0.7571618711387393, 'colsample_bytree': 0.7680948172828955, 'min_child_weight': 2, 'lambda': 9.751702880888226, 'alpha': 0.004468968613911363}. Best is trial 0 with value: 0.26690499174272747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.28953\teval-logloss:0.28951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28044/3574405256.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"eta\": trial.suggest_loguniform(\"eta\", 1e-3, 0.1),\n",
      "/tmp/ipykernel_28044/3574405256.py:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.6, 1.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.6, 1.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-3, 10.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-3, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-logloss:0.28946\teval-logloss:0.28945\n",
      "[2]\ttrain-logloss:0.28938\teval-logloss:0.28938\n",
      "[3]\ttrain-logloss:0.28932\teval-logloss:0.28933\n",
      "[4]\ttrain-logloss:0.28924\teval-logloss:0.28926\n",
      "[5]\ttrain-logloss:0.28918\teval-logloss:0.28920\n",
      "[6]\ttrain-logloss:0.28911\teval-logloss:0.28914\n",
      "[7]\ttrain-logloss:0.28903\teval-logloss:0.28907\n",
      "[8]\ttrain-logloss:0.28895\teval-logloss:0.28900\n",
      "[9]\ttrain-logloss:0.28888\teval-logloss:0.28893\n",
      "[10]\ttrain-logloss:0.28881\teval-logloss:0.28886\n",
      "[11]\ttrain-logloss:0.28874\teval-logloss:0.28880\n",
      "[12]\ttrain-logloss:0.28866\teval-logloss:0.28873\n",
      "[13]\ttrain-logloss:0.28859\teval-logloss:0.28866\n",
      "[14]\ttrain-logloss:0.28852\teval-logloss:0.28860\n",
      "[15]\ttrain-logloss:0.28845\teval-logloss:0.28854\n",
      "[16]\ttrain-logloss:0.28839\teval-logloss:0.28847\n",
      "[17]\ttrain-logloss:0.28831\teval-logloss:0.28840\n",
      "[18]\ttrain-logloss:0.28824\teval-logloss:0.28835\n",
      "[19]\ttrain-logloss:0.28817\teval-logloss:0.28828\n",
      "[20]\ttrain-logloss:0.28811\teval-logloss:0.28822\n",
      "[21]\ttrain-logloss:0.28803\teval-logloss:0.28815\n",
      "[22]\ttrain-logloss:0.28795\teval-logloss:0.28808\n",
      "[23]\ttrain-logloss:0.28789\teval-logloss:0.28802\n",
      "[24]\ttrain-logloss:0.28781\teval-logloss:0.28794\n",
      "[25]\ttrain-logloss:0.28773\teval-logloss:0.28787\n",
      "[26]\ttrain-logloss:0.28766\teval-logloss:0.28781\n",
      "[27]\ttrain-logloss:0.28758\teval-logloss:0.28773\n",
      "[28]\ttrain-logloss:0.28750\teval-logloss:0.28767\n",
      "[29]\ttrain-logloss:0.28742\teval-logloss:0.28760\n",
      "[30]\ttrain-logloss:0.28735\teval-logloss:0.28753\n",
      "[31]\ttrain-logloss:0.28728\teval-logloss:0.28747\n",
      "[32]\ttrain-logloss:0.28720\teval-logloss:0.28740\n",
      "[33]\ttrain-logloss:0.28713\teval-logloss:0.28733\n",
      "[34]\ttrain-logloss:0.28706\teval-logloss:0.28726\n",
      "[35]\ttrain-logloss:0.28698\teval-logloss:0.28719\n",
      "[36]\ttrain-logloss:0.28691\teval-logloss:0.28712\n",
      "[37]\ttrain-logloss:0.28684\teval-logloss:0.28706\n",
      "[38]\ttrain-logloss:0.28677\teval-logloss:0.28699\n",
      "[39]\ttrain-logloss:0.28669\teval-logloss:0.28692\n",
      "[40]\ttrain-logloss:0.28662\teval-logloss:0.28685\n",
      "[41]\ttrain-logloss:0.28654\teval-logloss:0.28678\n",
      "[42]\ttrain-logloss:0.28647\teval-logloss:0.28672\n",
      "[43]\ttrain-logloss:0.28641\teval-logloss:0.28666\n",
      "[44]\ttrain-logloss:0.28634\teval-logloss:0.28659\n",
      "[45]\ttrain-logloss:0.28626\teval-logloss:0.28652\n",
      "[46]\ttrain-logloss:0.28620\teval-logloss:0.28646\n",
      "[47]\ttrain-logloss:0.28612\teval-logloss:0.28639\n",
      "[48]\ttrain-logloss:0.28606\teval-logloss:0.28633\n",
      "[49]\ttrain-logloss:0.28599\teval-logloss:0.28627\n",
      "[50]\ttrain-logloss:0.28592\teval-logloss:0.28621\n",
      "[51]\ttrain-logloss:0.28586\teval-logloss:0.28615\n",
      "[52]\ttrain-logloss:0.28579\teval-logloss:0.28609\n",
      "[53]\ttrain-logloss:0.28572\teval-logloss:0.28604\n",
      "[54]\ttrain-logloss:0.28566\teval-logloss:0.28598\n",
      "[55]\ttrain-logloss:0.28558\teval-logloss:0.28591\n",
      "[56]\ttrain-logloss:0.28551\teval-logloss:0.28585\n",
      "[57]\ttrain-logloss:0.28544\teval-logloss:0.28579\n",
      "[58]\ttrain-logloss:0.28537\teval-logloss:0.28572\n",
      "[59]\ttrain-logloss:0.28531\teval-logloss:0.28567\n",
      "[60]\ttrain-logloss:0.28524\teval-logloss:0.28560\n",
      "[61]\ttrain-logloss:0.28518\teval-logloss:0.28554\n",
      "[62]\ttrain-logloss:0.28511\teval-logloss:0.28548\n",
      "[63]\ttrain-logloss:0.28504\teval-logloss:0.28542\n",
      "[64]\ttrain-logloss:0.28498\teval-logloss:0.28536\n",
      "[65]\ttrain-logloss:0.28490\teval-logloss:0.28530\n",
      "[66]\ttrain-logloss:0.28483\teval-logloss:0.28523\n",
      "[67]\ttrain-logloss:0.28477\teval-logloss:0.28517\n",
      "[68]\ttrain-logloss:0.28471\teval-logloss:0.28511\n",
      "[69]\ttrain-logloss:0.28464\teval-logloss:0.28505\n",
      "[70]\ttrain-logloss:0.28459\teval-logloss:0.28500\n",
      "[71]\ttrain-logloss:0.28452\teval-logloss:0.28494\n",
      "[72]\ttrain-logloss:0.28444\teval-logloss:0.28487\n",
      "[73]\ttrain-logloss:0.28438\teval-logloss:0.28481\n",
      "[74]\ttrain-logloss:0.28433\teval-logloss:0.28476\n",
      "[75]\ttrain-logloss:0.28427\teval-logloss:0.28470\n",
      "[76]\ttrain-logloss:0.28420\teval-logloss:0.28464\n",
      "[77]\ttrain-logloss:0.28413\teval-logloss:0.28458\n",
      "[78]\ttrain-logloss:0.28407\teval-logloss:0.28452\n",
      "[79]\ttrain-logloss:0.28401\teval-logloss:0.28447\n",
      "[80]\ttrain-logloss:0.28393\teval-logloss:0.28440\n",
      "[81]\ttrain-logloss:0.28387\teval-logloss:0.28434\n",
      "[82]\ttrain-logloss:0.28380\teval-logloss:0.28427\n",
      "[83]\ttrain-logloss:0.28374\teval-logloss:0.28422\n",
      "[84]\ttrain-logloss:0.28367\teval-logloss:0.28416\n",
      "[85]\ttrain-logloss:0.28361\teval-logloss:0.28410\n",
      "[86]\ttrain-logloss:0.28355\teval-logloss:0.28405\n",
      "[87]\ttrain-logloss:0.28349\teval-logloss:0.28400\n",
      "[88]\ttrain-logloss:0.28343\teval-logloss:0.28394\n",
      "[89]\ttrain-logloss:0.28336\teval-logloss:0.28388\n",
      "[90]\ttrain-logloss:0.28329\teval-logloss:0.28382\n",
      "[91]\ttrain-logloss:0.28322\teval-logloss:0.28375\n",
      "[92]\ttrain-logloss:0.28316\teval-logloss:0.28369\n",
      "[93]\ttrain-logloss:0.28310\teval-logloss:0.28364\n",
      "[94]\ttrain-logloss:0.28303\teval-logloss:0.28358\n",
      "[95]\ttrain-logloss:0.28297\teval-logloss:0.28351\n",
      "[96]\ttrain-logloss:0.28289\teval-logloss:0.28345\n",
      "[97]\ttrain-logloss:0.28283\teval-logloss:0.28340\n",
      "[98]\ttrain-logloss:0.28277\teval-logloss:0.28334\n",
      "[99]\ttrain-logloss:0.28270\teval-logloss:0.28328\n",
      "[0]\ttrain-logloss:0.28952\teval-logloss:0.28951\n",
      "[1]\ttrain-logloss:0.28946\teval-logloss:0.28945\n",
      "[2]\ttrain-logloss:0.28938\teval-logloss:0.28938\n",
      "[3]\ttrain-logloss:0.28931\teval-logloss:0.28932\n",
      "[4]\ttrain-logloss:0.28925\teval-logloss:0.28925\n",
      "[5]\ttrain-logloss:0.28917\teval-logloss:0.28919\n",
      "[6]\ttrain-logloss:0.28910\teval-logloss:0.28913\n",
      "[7]\ttrain-logloss:0.28903\teval-logloss:0.28906\n",
      "[8]\ttrain-logloss:0.28896\teval-logloss:0.28900\n",
      "[9]\ttrain-logloss:0.28888\teval-logloss:0.28892\n",
      "[10]\ttrain-logloss:0.28881\teval-logloss:0.28886\n",
      "[11]\ttrain-logloss:0.28874\teval-logloss:0.28879\n",
      "[12]\ttrain-logloss:0.28867\teval-logloss:0.28873\n",
      "[13]\ttrain-logloss:0.28859\teval-logloss:0.28866\n",
      "[14]\ttrain-logloss:0.28853\teval-logloss:0.28860\n",
      "[15]\ttrain-logloss:0.28846\teval-logloss:0.28854\n",
      "[16]\ttrain-logloss:0.28839\teval-logloss:0.28848\n",
      "[17]\ttrain-logloss:0.28832\teval-logloss:0.28841\n",
      "[18]\ttrain-logloss:0.28825\teval-logloss:0.28835\n",
      "[19]\ttrain-logloss:0.28818\teval-logloss:0.28828\n",
      "[20]\ttrain-logloss:0.28811\teval-logloss:0.28822\n",
      "[21]\ttrain-logloss:0.28804\teval-logloss:0.28815\n",
      "[22]\ttrain-logloss:0.28796\teval-logloss:0.28808\n",
      "[23]\ttrain-logloss:0.28789\teval-logloss:0.28801\n",
      "[24]\ttrain-logloss:0.28781\teval-logloss:0.28794\n",
      "[25]\ttrain-logloss:0.28774\teval-logloss:0.28788\n",
      "[26]\ttrain-logloss:0.28767\teval-logloss:0.28781\n",
      "[27]\ttrain-logloss:0.28759\teval-logloss:0.28774\n",
      "[28]\ttrain-logloss:0.28751\teval-logloss:0.28767\n",
      "[29]\ttrain-logloss:0.28743\teval-logloss:0.28760\n",
      "[30]\ttrain-logloss:0.28736\teval-logloss:0.28753\n",
      "[31]\ttrain-logloss:0.28729\teval-logloss:0.28747\n",
      "[32]\ttrain-logloss:0.28722\teval-logloss:0.28740\n",
      "[33]\ttrain-logloss:0.28715\teval-logloss:0.28733\n",
      "[34]\ttrain-logloss:0.28707\teval-logloss:0.28726\n",
      "[35]\ttrain-logloss:0.28699\teval-logloss:0.28719\n",
      "[36]\ttrain-logloss:0.28691\teval-logloss:0.28712\n",
      "[37]\ttrain-logloss:0.28685\teval-logloss:0.28706\n",
      "[38]\ttrain-logloss:0.28677\teval-logloss:0.28699\n",
      "[39]\ttrain-logloss:0.28670\teval-logloss:0.28692\n",
      "[40]\ttrain-logloss:0.28663\teval-logloss:0.28685\n",
      "[41]\ttrain-logloss:0.28655\teval-logloss:0.28679\n",
      "[42]\ttrain-logloss:0.28649\teval-logloss:0.28673\n",
      "[43]\ttrain-logloss:0.28642\teval-logloss:0.28667\n",
      "[44]\ttrain-logloss:0.28635\teval-logloss:0.28660\n",
      "[45]\ttrain-logloss:0.28628\teval-logloss:0.28653\n",
      "[46]\ttrain-logloss:0.28621\teval-logloss:0.28647\n",
      "[47]\ttrain-logloss:0.28613\teval-logloss:0.28641\n",
      "[48]\ttrain-logloss:0.28607\teval-logloss:0.28635\n",
      "[49]\ttrain-logloss:0.28600\teval-logloss:0.28629\n",
      "[50]\ttrain-logloss:0.28593\teval-logloss:0.28623\n",
      "[51]\ttrain-logloss:0.28587\teval-logloss:0.28617\n",
      "[52]\ttrain-logloss:0.28581\teval-logloss:0.28611\n",
      "[53]\ttrain-logloss:0.28574\teval-logloss:0.28605\n",
      "[54]\ttrain-logloss:0.28568\teval-logloss:0.28600\n",
      "[55]\ttrain-logloss:0.28561\teval-logloss:0.28593\n",
      "[56]\ttrain-logloss:0.28554\teval-logloss:0.28587\n",
      "[57]\ttrain-logloss:0.28547\teval-logloss:0.28580\n",
      "[58]\ttrain-logloss:0.28540\teval-logloss:0.28574\n",
      "[59]\ttrain-logloss:0.28535\teval-logloss:0.28569\n",
      "[60]\ttrain-logloss:0.28528\teval-logloss:0.28563\n",
      "[61]\ttrain-logloss:0.28521\teval-logloss:0.28557\n",
      "[62]\ttrain-logloss:0.28514\teval-logloss:0.28551\n",
      "[63]\ttrain-logloss:0.28507\teval-logloss:0.28544\n",
      "[64]\ttrain-logloss:0.28501\teval-logloss:0.28538\n",
      "[65]\ttrain-logloss:0.28494\teval-logloss:0.28532\n",
      "[66]\ttrain-logloss:0.28487\teval-logloss:0.28525\n",
      "[67]\ttrain-logloss:0.28480\teval-logloss:0.28519\n",
      "[68]\ttrain-logloss:0.28474\teval-logloss:0.28514\n",
      "[69]\ttrain-logloss:0.28468\teval-logloss:0.28508\n",
      "[70]\ttrain-logloss:0.28462\teval-logloss:0.28502\n",
      "[71]\ttrain-logloss:0.28455\teval-logloss:0.28496\n",
      "[72]\ttrain-logloss:0.28447\teval-logloss:0.28490\n",
      "[73]\ttrain-logloss:0.28441\teval-logloss:0.28484\n",
      "[74]\ttrain-logloss:0.28435\teval-logloss:0.28479\n",
      "[75]\ttrain-logloss:0.28429\teval-logloss:0.28474\n",
      "[76]\ttrain-logloss:0.28422\teval-logloss:0.28468\n",
      "[77]\ttrain-logloss:0.28416\teval-logloss:0.28461\n",
      "[78]\ttrain-logloss:0.28409\teval-logloss:0.28456\n",
      "[79]\ttrain-logloss:0.28403\teval-logloss:0.28450\n",
      "[80]\ttrain-logloss:0.28397\teval-logloss:0.28444\n",
      "[81]\ttrain-logloss:0.28390\teval-logloss:0.28438\n",
      "[82]\ttrain-logloss:0.28383\teval-logloss:0.28432\n",
      "[83]\ttrain-logloss:0.28377\teval-logloss:0.28427\n",
      "[84]\ttrain-logloss:0.28370\teval-logloss:0.28421\n",
      "[85]\ttrain-logloss:0.28364\teval-logloss:0.28415\n",
      "[86]\ttrain-logloss:0.28358\teval-logloss:0.28410\n",
      "[87]\ttrain-logloss:0.28352\teval-logloss:0.28405\n",
      "[88]\ttrain-logloss:0.28346\teval-logloss:0.28398\n",
      "[89]\ttrain-logloss:0.28339\teval-logloss:0.28393\n",
      "[90]\ttrain-logloss:0.28333\teval-logloss:0.28387\n",
      "[91]\ttrain-logloss:0.28326\teval-logloss:0.28380\n",
      "[92]\ttrain-logloss:0.28319\teval-logloss:0.28374\n",
      "[93]\ttrain-logloss:0.28313\teval-logloss:0.28368\n",
      "[94]\ttrain-logloss:0.28306\teval-logloss:0.28363\n",
      "[95]\ttrain-logloss:0.28300\teval-logloss:0.28357\n",
      "[96]\ttrain-logloss:0.28293\teval-logloss:0.28350\n",
      "[97]\ttrain-logloss:0.28286\teval-logloss:0.28344\n",
      "[98]\ttrain-logloss:0.28280\teval-logloss:0.28339\n",
      "[99]\ttrain-logloss:0.28273\teval-logloss:0.28333\n",
      "[0]\ttrain-logloss:0.28952\teval-logloss:0.28952\n",
      "[1]\ttrain-logloss:0.28946\teval-logloss:0.28946\n",
      "[2]\ttrain-logloss:0.28937\teval-logloss:0.28939\n",
      "[3]\ttrain-logloss:0.28931\teval-logloss:0.28933\n",
      "[4]\ttrain-logloss:0.28923\teval-logloss:0.28927\n",
      "[5]\ttrain-logloss:0.28916\teval-logloss:0.28920\n",
      "[6]\ttrain-logloss:0.28909\teval-logloss:0.28914\n",
      "[7]\ttrain-logloss:0.28902\teval-logloss:0.28908\n",
      "[8]\ttrain-logloss:0.28894\teval-logloss:0.28901\n",
      "[9]\ttrain-logloss:0.28886\teval-logloss:0.28895\n",
      "[10]\ttrain-logloss:0.28879\teval-logloss:0.28888\n",
      "[11]\ttrain-logloss:0.28872\teval-logloss:0.28882\n",
      "[12]\ttrain-logloss:0.28865\teval-logloss:0.28876\n",
      "[13]\ttrain-logloss:0.28857\teval-logloss:0.28868\n",
      "[14]\ttrain-logloss:0.28850\teval-logloss:0.28863\n",
      "[15]\ttrain-logloss:0.28843\teval-logloss:0.28856\n",
      "[16]\ttrain-logloss:0.28836\teval-logloss:0.28850\n",
      "[17]\ttrain-logloss:0.28828\teval-logloss:0.28843\n",
      "[18]\ttrain-logloss:0.28822\teval-logloss:0.28837\n",
      "[19]\ttrain-logloss:0.28814\teval-logloss:0.28831\n",
      "[20]\ttrain-logloss:0.28808\teval-logloss:0.28825\n",
      "[21]\ttrain-logloss:0.28799\teval-logloss:0.28818\n",
      "[22]\ttrain-logloss:0.28792\teval-logloss:0.28811\n",
      "[23]\ttrain-logloss:0.28785\teval-logloss:0.28805\n",
      "[24]\ttrain-logloss:0.28777\teval-logloss:0.28799\n",
      "[25]\ttrain-logloss:0.28770\teval-logloss:0.28792\n",
      "[26]\ttrain-logloss:0.28762\teval-logloss:0.28786\n",
      "[27]\ttrain-logloss:0.28754\teval-logloss:0.28779\n",
      "[28]\ttrain-logloss:0.28747\teval-logloss:0.28772\n",
      "[29]\ttrain-logloss:0.28739\teval-logloss:0.28766\n",
      "[30]\ttrain-logloss:0.28731\teval-logloss:0.28759\n",
      "[31]\ttrain-logloss:0.28725\teval-logloss:0.28753\n",
      "[32]\ttrain-logloss:0.28717\teval-logloss:0.28747\n",
      "[33]\ttrain-logloss:0.28710\teval-logloss:0.28740\n",
      "[34]\ttrain-logloss:0.28702\teval-logloss:0.28733\n",
      "[35]\ttrain-logloss:0.28694\teval-logloss:0.28727\n",
      "[36]\ttrain-logloss:0.28687\teval-logloss:0.28721\n",
      "[37]\ttrain-logloss:0.28680\teval-logloss:0.28715\n",
      "[38]\ttrain-logloss:0.28672\teval-logloss:0.28709\n",
      "[39]\ttrain-logloss:0.28664\teval-logloss:0.28702\n",
      "[40]\ttrain-logloss:0.28657\teval-logloss:0.28695\n",
      "[41]\ttrain-logloss:0.28649\teval-logloss:0.28689\n",
      "[42]\ttrain-logloss:0.28643\teval-logloss:0.28683\n",
      "[43]\ttrain-logloss:0.28636\teval-logloss:0.28678\n",
      "[44]\ttrain-logloss:0.28629\teval-logloss:0.28671\n",
      "[45]\ttrain-logloss:0.28621\teval-logloss:0.28665\n",
      "[46]\ttrain-logloss:0.28614\teval-logloss:0.28659\n",
      "[47]\ttrain-logloss:0.28606\teval-logloss:0.28652\n",
      "[48]\ttrain-logloss:0.28600\teval-logloss:0.28646\n",
      "[49]\ttrain-logloss:0.28593\teval-logloss:0.28640\n",
      "[50]\ttrain-logloss:0.28586\teval-logloss:0.28634\n",
      "[51]\ttrain-logloss:0.28580\teval-logloss:0.28629\n",
      "[52]\ttrain-logloss:0.28573\teval-logloss:0.28622\n",
      "[53]\ttrain-logloss:0.28566\teval-logloss:0.28616\n",
      "[54]\ttrain-logloss:0.28560\teval-logloss:0.28611\n",
      "[55]\ttrain-logloss:0.28552\teval-logloss:0.28604\n",
      "[56]\ttrain-logloss:0.28545\teval-logloss:0.28597\n",
      "[57]\ttrain-logloss:0.28538\teval-logloss:0.28592\n",
      "[58]\ttrain-logloss:0.28530\teval-logloss:0.28586\n",
      "[59]\ttrain-logloss:0.28524\teval-logloss:0.28581\n",
      "[60]\ttrain-logloss:0.28517\teval-logloss:0.28575\n",
      "[61]\ttrain-logloss:0.28511\teval-logloss:0.28569\n",
      "[62]\ttrain-logloss:0.28504\teval-logloss:0.28563\n",
      "[63]\ttrain-logloss:0.28497\teval-logloss:0.28557\n",
      "[64]\ttrain-logloss:0.28491\teval-logloss:0.28551\n",
      "[65]\ttrain-logloss:0.28484\teval-logloss:0.28545\n",
      "[66]\ttrain-logloss:0.28476\teval-logloss:0.28539\n",
      "[67]\ttrain-logloss:0.28470\teval-logloss:0.28533\n",
      "[68]\ttrain-logloss:0.28464\teval-logloss:0.28527\n",
      "[69]\ttrain-logloss:0.28457\teval-logloss:0.28522\n",
      "[70]\ttrain-logloss:0.28451\teval-logloss:0.28516\n",
      "[71]\ttrain-logloss:0.28443\teval-logloss:0.28510\n",
      "[72]\ttrain-logloss:0.28436\teval-logloss:0.28504\n",
      "[73]\ttrain-logloss:0.28430\teval-logloss:0.28498\n",
      "[74]\ttrain-logloss:0.28424\teval-logloss:0.28493\n",
      "[75]\ttrain-logloss:0.28418\teval-logloss:0.28488\n",
      "[76]\ttrain-logloss:0.28411\teval-logloss:0.28482\n",
      "[77]\ttrain-logloss:0.28403\teval-logloss:0.28476\n",
      "[78]\ttrain-logloss:0.28397\teval-logloss:0.28469\n",
      "[79]\ttrain-logloss:0.28391\teval-logloss:0.28464\n",
      "[80]\ttrain-logloss:0.28384\teval-logloss:0.28457\n",
      "[81]\ttrain-logloss:0.28377\teval-logloss:0.28452\n",
      "[82]\ttrain-logloss:0.28370\teval-logloss:0.28446\n",
      "[83]\ttrain-logloss:0.28364\teval-logloss:0.28441\n",
      "[84]\ttrain-logloss:0.28357\teval-logloss:0.28435\n",
      "[85]\ttrain-logloss:0.28350\teval-logloss:0.28429\n",
      "[86]\ttrain-logloss:0.28345\teval-logloss:0.28424\n",
      "[87]\ttrain-logloss:0.28339\teval-logloss:0.28419\n",
      "[88]\ttrain-logloss:0.28332\teval-logloss:0.28413\n",
      "[89]\ttrain-logloss:0.28326\teval-logloss:0.28407\n",
      "[90]\ttrain-logloss:0.28319\teval-logloss:0.28401\n",
      "[91]\ttrain-logloss:0.28312\teval-logloss:0.28396\n",
      "[92]\ttrain-logloss:0.28305\teval-logloss:0.28390\n",
      "[93]\ttrain-logloss:0.28299\teval-logloss:0.28385\n",
      "[94]\ttrain-logloss:0.28293\teval-logloss:0.28379\n",
      "[95]\ttrain-logloss:0.28286\teval-logloss:0.28374\n",
      "[96]\ttrain-logloss:0.28279\teval-logloss:0.28368\n",
      "[97]\ttrain-logloss:0.28272\teval-logloss:0.28362\n",
      "[98]\ttrain-logloss:0.28266\teval-logloss:0.28357\n",
      "[99]\ttrain-logloss:0.28259\teval-logloss:0.28351\n",
      "[0]\ttrain-logloss:0.28952\teval-logloss:0.28951\n",
      "[1]\ttrain-logloss:0.28946\teval-logloss:0.28945\n",
      "[2]\ttrain-logloss:0.28938\teval-logloss:0.28938\n",
      "[3]\ttrain-logloss:0.28932\teval-logloss:0.28932\n",
      "[4]\ttrain-logloss:0.28925\teval-logloss:0.28925\n",
      "[5]\ttrain-logloss:0.28918\teval-logloss:0.28918\n",
      "[6]\ttrain-logloss:0.28910\teval-logloss:0.28912\n",
      "[7]\ttrain-logloss:0.28903\teval-logloss:0.28905\n",
      "[8]\ttrain-logloss:0.28896\teval-logloss:0.28898\n",
      "[9]\ttrain-logloss:0.28889\teval-logloss:0.28891\n",
      "[10]\ttrain-logloss:0.28882\teval-logloss:0.28885\n",
      "[11]\ttrain-logloss:0.28875\teval-logloss:0.28879\n",
      "[12]\ttrain-logloss:0.28869\teval-logloss:0.28872\n",
      "[13]\ttrain-logloss:0.28861\teval-logloss:0.28865\n",
      "[14]\ttrain-logloss:0.28855\teval-logloss:0.28859\n",
      "[15]\ttrain-logloss:0.28848\teval-logloss:0.28853\n",
      "[16]\ttrain-logloss:0.28841\teval-logloss:0.28847\n",
      "[17]\ttrain-logloss:0.28834\teval-logloss:0.28839\n",
      "[18]\ttrain-logloss:0.28827\teval-logloss:0.28833\n",
      "[19]\ttrain-logloss:0.28820\teval-logloss:0.28826\n",
      "[20]\ttrain-logloss:0.28813\teval-logloss:0.28820\n",
      "[21]\ttrain-logloss:0.28806\teval-logloss:0.28813\n",
      "[22]\ttrain-logloss:0.28798\teval-logloss:0.28806\n",
      "[23]\ttrain-logloss:0.28792\teval-logloss:0.28799\n",
      "[24]\ttrain-logloss:0.28784\teval-logloss:0.28792\n",
      "[25]\ttrain-logloss:0.28777\teval-logloss:0.28785\n",
      "[26]\ttrain-logloss:0.28770\teval-logloss:0.28779\n",
      "[27]\ttrain-logloss:0.28762\teval-logloss:0.28771\n",
      "[28]\ttrain-logloss:0.28755\teval-logloss:0.28764\n",
      "[29]\ttrain-logloss:0.28747\teval-logloss:0.28758\n",
      "[30]\ttrain-logloss:0.28740\teval-logloss:0.28750\n",
      "[31]\ttrain-logloss:0.28734\teval-logloss:0.28745\n",
      "[32]\ttrain-logloss:0.28726\teval-logloss:0.28737\n",
      "[33]\ttrain-logloss:0.28718\teval-logloss:0.28730\n",
      "[34]\ttrain-logloss:0.28711\teval-logloss:0.28723\n",
      "[35]\ttrain-logloss:0.28704\teval-logloss:0.28716\n",
      "[36]\ttrain-logloss:0.28696\teval-logloss:0.28709\n",
      "[37]\ttrain-logloss:0.28689\teval-logloss:0.28703\n",
      "[38]\ttrain-logloss:0.28682\teval-logloss:0.28696\n",
      "[39]\ttrain-logloss:0.28675\teval-logloss:0.28689\n",
      "[40]\ttrain-logloss:0.28667\teval-logloss:0.28682\n",
      "[41]\ttrain-logloss:0.28660\teval-logloss:0.28675\n",
      "[42]\ttrain-logloss:0.28654\teval-logloss:0.28669\n",
      "[43]\ttrain-logloss:0.28647\teval-logloss:0.28663\n",
      "[44]\ttrain-logloss:0.28640\teval-logloss:0.28657\n",
      "[45]\ttrain-logloss:0.28632\teval-logloss:0.28650\n",
      "[46]\ttrain-logloss:0.28626\teval-logloss:0.28643\n",
      "[47]\ttrain-logloss:0.28619\teval-logloss:0.28637\n",
      "[48]\ttrain-logloss:0.28612\teval-logloss:0.28631\n",
      "[49]\ttrain-logloss:0.28606\teval-logloss:0.28624\n",
      "[50]\ttrain-logloss:0.28599\teval-logloss:0.28619\n",
      "[51]\ttrain-logloss:0.28593\teval-logloss:0.28613\n",
      "[52]\ttrain-logloss:0.28587\teval-logloss:0.28606\n",
      "[53]\ttrain-logloss:0.28580\teval-logloss:0.28600\n",
      "[54]\ttrain-logloss:0.28574\teval-logloss:0.28595\n",
      "[55]\ttrain-logloss:0.28567\teval-logloss:0.28588\n",
      "[56]\ttrain-logloss:0.28559\teval-logloss:0.28581\n",
      "[57]\ttrain-logloss:0.28552\teval-logloss:0.28574\n",
      "[58]\ttrain-logloss:0.28545\teval-logloss:0.28567\n",
      "[59]\ttrain-logloss:0.28539\teval-logloss:0.28562\n",
      "[60]\ttrain-logloss:0.28532\teval-logloss:0.28555\n",
      "[61]\ttrain-logloss:0.28525\teval-logloss:0.28550\n",
      "[62]\ttrain-logloss:0.28519\teval-logloss:0.28543\n",
      "[63]\ttrain-logloss:0.28512\teval-logloss:0.28537\n",
      "[64]\ttrain-logloss:0.28506\teval-logloss:0.28532\n",
      "[65]\ttrain-logloss:0.28499\teval-logloss:0.28525\n",
      "[66]\ttrain-logloss:0.28491\teval-logloss:0.28518\n",
      "[67]\ttrain-logloss:0.28485\teval-logloss:0.28512\n",
      "[68]\ttrain-logloss:0.28479\teval-logloss:0.28506\n",
      "[69]\ttrain-logloss:0.28472\teval-logloss:0.28500\n",
      "[70]\ttrain-logloss:0.28466\teval-logloss:0.28494\n",
      "[71]\ttrain-logloss:0.28459\teval-logloss:0.28488\n",
      "[72]\ttrain-logloss:0.28452\teval-logloss:0.28481\n",
      "[73]\ttrain-logloss:0.28446\teval-logloss:0.28475\n",
      "[74]\ttrain-logloss:0.28440\teval-logloss:0.28470\n",
      "[75]\ttrain-logloss:0.28434\teval-logloss:0.28464\n",
      "[76]\ttrain-logloss:0.28427\teval-logloss:0.28458\n",
      "[77]\ttrain-logloss:0.28420\teval-logloss:0.28451\n",
      "[78]\ttrain-logloss:0.28414\teval-logloss:0.28445\n",
      "[79]\ttrain-logloss:0.28408\teval-logloss:0.28440\n",
      "[80]\ttrain-logloss:0.28401\teval-logloss:0.28433\n",
      "[81]\ttrain-logloss:0.28394\teval-logloss:0.28427\n",
      "[82]\ttrain-logloss:0.28388\teval-logloss:0.28421\n",
      "[83]\ttrain-logloss:0.28382\teval-logloss:0.28415\n",
      "[84]\ttrain-logloss:0.28374\teval-logloss:0.28409\n",
      "[85]\ttrain-logloss:0.28368\teval-logloss:0.28403\n",
      "[86]\ttrain-logloss:0.28362\teval-logloss:0.28397\n",
      "[87]\ttrain-logloss:0.28356\teval-logloss:0.28392\n",
      "[88]\ttrain-logloss:0.28349\teval-logloss:0.28386\n",
      "[89]\ttrain-logloss:0.28343\teval-logloss:0.28380\n",
      "[90]\ttrain-logloss:0.28336\teval-logloss:0.28373\n",
      "[91]\ttrain-logloss:0.28330\teval-logloss:0.28367\n",
      "[92]\ttrain-logloss:0.28323\teval-logloss:0.28361\n",
      "[93]\ttrain-logloss:0.28317\teval-logloss:0.28355\n",
      "[94]\ttrain-logloss:0.28310\teval-logloss:0.28349\n",
      "[95]\ttrain-logloss:0.28303\teval-logloss:0.28343\n",
      "[96]\ttrain-logloss:0.28296\teval-logloss:0.28336\n",
      "[97]\ttrain-logloss:0.28289\teval-logloss:0.28330\n",
      "[98]\ttrain-logloss:0.28283\teval-logloss:0.28325\n",
      "[99]\ttrain-logloss:0.28276\teval-logloss:0.28318\n",
      "[0]\ttrain-logloss:0.28951\teval-logloss:0.28958\n",
      "[1]\ttrain-logloss:0.28944\teval-logloss:0.28952\n",
      "[2]\ttrain-logloss:0.28937\teval-logloss:0.28945\n",
      "[3]\ttrain-logloss:0.28930\teval-logloss:0.28939\n",
      "[4]\ttrain-logloss:0.28923\teval-logloss:0.28932\n",
      "[5]\ttrain-logloss:0.28916\teval-logloss:0.28926\n",
      "[6]\ttrain-logloss:0.28909\teval-logloss:0.28919\n",
      "[7]\ttrain-logloss:0.28902\teval-logloss:0.28913\n",
      "[8]\ttrain-logloss:0.28894\teval-logloss:0.28905\n",
      "[9]\ttrain-logloss:0.28886\teval-logloss:0.28899\n",
      "[10]\ttrain-logloss:0.28879\teval-logloss:0.28892\n",
      "[11]\ttrain-logloss:0.28872\teval-logloss:0.28886\n",
      "[12]\ttrain-logloss:0.28866\teval-logloss:0.28879\n",
      "[13]\ttrain-logloss:0.28858\teval-logloss:0.28872\n",
      "[14]\ttrain-logloss:0.28851\teval-logloss:0.28865\n",
      "[15]\ttrain-logloss:0.28844\teval-logloss:0.28859\n",
      "[16]\ttrain-logloss:0.28837\teval-logloss:0.28852\n",
      "[17]\ttrain-logloss:0.28830\teval-logloss:0.28845\n",
      "[18]\ttrain-logloss:0.28823\teval-logloss:0.28839\n",
      "[19]\ttrain-logloss:0.28816\teval-logloss:0.28833\n",
      "[20]\ttrain-logloss:0.28809\teval-logloss:0.28827\n",
      "[21]\ttrain-logloss:0.28801\teval-logloss:0.28820\n",
      "[22]\ttrain-logloss:0.28793\teval-logloss:0.28813\n",
      "[23]\ttrain-logloss:0.28787\teval-logloss:0.28807\n",
      "[24]\ttrain-logloss:0.28779\teval-logloss:0.28799\n",
      "[25]\ttrain-logloss:0.28772\teval-logloss:0.28792\n",
      "[26]\ttrain-logloss:0.28765\teval-logloss:0.28786\n",
      "[27]\ttrain-logloss:0.28757\teval-logloss:0.28778\n",
      "[28]\ttrain-logloss:0.28749\teval-logloss:0.28771\n",
      "[29]\ttrain-logloss:0.28741\teval-logloss:0.28764\n",
      "[30]\ttrain-logloss:0.28734\teval-logloss:0.28757\n",
      "[31]\ttrain-logloss:0.28727\teval-logloss:0.28751\n",
      "[32]\ttrain-logloss:0.28719\teval-logloss:0.28744\n",
      "[33]\ttrain-logloss:0.28712\teval-logloss:0.28738\n",
      "[34]\ttrain-logloss:0.28705\teval-logloss:0.28732\n",
      "[35]\ttrain-logloss:0.28697\teval-logloss:0.28725\n",
      "[36]\ttrain-logloss:0.28690\teval-logloss:0.28717\n",
      "[37]\ttrain-logloss:0.28683\teval-logloss:0.28711\n",
      "[38]\ttrain-logloss:0.28675\teval-logloss:0.28704\n",
      "[39]\ttrain-logloss:0.28668\teval-logloss:0.28697\n",
      "[40]\ttrain-logloss:0.28660\teval-logloss:0.28690\n",
      "[41]\ttrain-logloss:0.28653\teval-logloss:0.28684\n",
      "[42]\ttrain-logloss:0.28646\teval-logloss:0.28678\n",
      "[43]\ttrain-logloss:0.28640\teval-logloss:0.28672\n",
      "[44]\ttrain-logloss:0.28633\teval-logloss:0.28666\n",
      "[45]\ttrain-logloss:0.28626\teval-logloss:0.28659\n",
      "[46]\ttrain-logloss:0.28619\teval-logloss:0.28652\n",
      "[47]\ttrain-logloss:0.28611\teval-logloss:0.28646\n",
      "[48]\ttrain-logloss:0.28604\teval-logloss:0.28639\n",
      "[49]\ttrain-logloss:0.28598\teval-logloss:0.28633\n",
      "[50]\ttrain-logloss:0.28591\teval-logloss:0.28627\n",
      "[51]\ttrain-logloss:0.28585\teval-logloss:0.28622\n",
      "[52]\ttrain-logloss:0.28578\teval-logloss:0.28616\n",
      "[53]\ttrain-logloss:0.28572\teval-logloss:0.28610\n",
      "[54]\ttrain-logloss:0.28565\teval-logloss:0.28604\n",
      "[55]\ttrain-logloss:0.28558\teval-logloss:0.28598\n",
      "[56]\ttrain-logloss:0.28550\teval-logloss:0.28591\n",
      "[57]\ttrain-logloss:0.28543\teval-logloss:0.28585\n",
      "[58]\ttrain-logloss:0.28537\teval-logloss:0.28579\n",
      "[59]\ttrain-logloss:0.28531\teval-logloss:0.28574\n",
      "[60]\ttrain-logloss:0.28524\teval-logloss:0.28567\n",
      "[61]\ttrain-logloss:0.28517\teval-logloss:0.28561\n",
      "[62]\ttrain-logloss:0.28510\teval-logloss:0.28555\n",
      "[63]\ttrain-logloss:0.28504\teval-logloss:0.28549\n",
      "[64]\ttrain-logloss:0.28497\teval-logloss:0.28544\n",
      "[65]\ttrain-logloss:0.28490\teval-logloss:0.28537\n",
      "[66]\ttrain-logloss:0.28483\teval-logloss:0.28531\n",
      "[67]\ttrain-logloss:0.28477\teval-logloss:0.28524\n",
      "[68]\ttrain-logloss:0.28471\teval-logloss:0.28519\n",
      "[69]\ttrain-logloss:0.28464\teval-logloss:0.28513\n",
      "[70]\ttrain-logloss:0.28458\teval-logloss:0.28508\n",
      "[71]\ttrain-logloss:0.28451\teval-logloss:0.28502\n",
      "[72]\ttrain-logloss:0.28444\teval-logloss:0.28495\n",
      "[73]\ttrain-logloss:0.28437\teval-logloss:0.28490\n",
      "[74]\ttrain-logloss:0.28431\teval-logloss:0.28485\n",
      "[75]\ttrain-logloss:0.28425\teval-logloss:0.28479\n",
      "[76]\ttrain-logloss:0.28418\teval-logloss:0.28473\n",
      "[77]\ttrain-logloss:0.28411\teval-logloss:0.28466\n",
      "[78]\ttrain-logloss:0.28405\teval-logloss:0.28461\n",
      "[79]\ttrain-logloss:0.28399\teval-logloss:0.28456\n",
      "[80]\ttrain-logloss:0.28392\teval-logloss:0.28449\n",
      "[81]\ttrain-logloss:0.28385\teval-logloss:0.28443\n",
      "[82]\ttrain-logloss:0.28378\teval-logloss:0.28437\n",
      "[83]\ttrain-logloss:0.28372\teval-logloss:0.28432\n",
      "[84]\ttrain-logloss:0.28365\teval-logloss:0.28425\n",
      "[85]\ttrain-logloss:0.28359\teval-logloss:0.28420\n",
      "[86]\ttrain-logloss:0.28353\teval-logloss:0.28414\n",
      "[87]\ttrain-logloss:0.28347\teval-logloss:0.28410\n",
      "[88]\ttrain-logloss:0.28341\teval-logloss:0.28403\n",
      "[89]\ttrain-logloss:0.28334\teval-logloss:0.28398\n",
      "[90]\ttrain-logloss:0.28328\teval-logloss:0.28391\n",
      "[91]\ttrain-logloss:0.28321\teval-logloss:0.28385\n",
      "[92]\ttrain-logloss:0.28314\teval-logloss:0.28378\n",
      "[93]\ttrain-logloss:0.28308\teval-logloss:0.28373\n",
      "[94]\ttrain-logloss:0.28302\teval-logloss:0.28368\n",
      "[95]\ttrain-logloss:0.28295\teval-logloss:0.28361\n",
      "[96]\ttrain-logloss:0.28288\teval-logloss:0.28355\n",
      "[97]\ttrain-logloss:0.28281\teval-logloss:0.28349\n",
      "[98]\ttrain-logloss:0.28275\teval-logloss:0.28344\n",
      "[99]\ttrain-logloss:0.28268\teval-logloss:0.28337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 16:02:59,435] Trial 3 finished with value: 0.28333415692799724 and parameters: {'eta': 0.001107873125080376, 'max_depth': 8, 'subsample': 0.6106798125610987, 'colsample_bytree': 0.8150837380415081, 'min_child_weight': 2, 'lambda': 5.422500111444353, 'alpha': 0.16410884856707386}. Best is trial 0 with value: 0.26690499174272747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.28825\teval-logloss:0.28841\n",
      "[1]\ttrain-logloss:0.28699\teval-logloss:0.28722\n",
      "[2]\ttrain-logloss:0.28547\teval-logloss:0.28585\n",
      "[3]\ttrain-logloss:0.28431\teval-logloss:0.28476\n",
      "[4]\ttrain-logloss:0.28296\teval-logloss:0.28362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28044/3574405256.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"eta\": trial.suggest_loguniform(\"eta\", 1e-3, 0.1),\n",
      "/tmp/ipykernel_28044/3574405256.py:21: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"subsample\": trial.suggest_uniform(\"subsample\", 0.6, 1.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.6, 1.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-3, 10.0),\n",
      "/tmp/ipykernel_28044/3574405256.py:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-3, 10.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-logloss:0.28175\teval-logloss:0.28251\n",
      "[6]\ttrain-logloss:0.28060\teval-logloss:0.28148\n",
      "[7]\ttrain-logloss:0.27942\teval-logloss:0.28035\n",
      "[8]\ttrain-logloss:0.27808\teval-logloss:0.27915\n",
      "[9]\ttrain-logloss:0.27697\teval-logloss:0.27811\n",
      "[10]\ttrain-logloss:0.27587\teval-logloss:0.27718\n",
      "[11]\ttrain-logloss:0.27478\teval-logloss:0.27607\n",
      "[12]\ttrain-logloss:0.27378\teval-logloss:0.27526\n",
      "[13]\ttrain-logloss:0.27264\teval-logloss:0.27436\n",
      "[14]\ttrain-logloss:0.27166\teval-logloss:0.27343\n",
      "[15]\ttrain-logloss:0.27075\teval-logloss:0.27262\n",
      "[16]\ttrain-logloss:0.26982\teval-logloss:0.27194\n",
      "[17]\ttrain-logloss:0.26875\teval-logloss:0.27101\n",
      "[18]\ttrain-logloss:0.26798\teval-logloss:0.27034\n",
      "[19]\ttrain-logloss:0.26706\teval-logloss:0.26960\n",
      "[20]\ttrain-logloss:0.26627\teval-logloss:0.26885\n",
      "[21]\ttrain-logloss:0.26536\teval-logloss:0.26806\n",
      "[22]\ttrain-logloss:0.26444\teval-logloss:0.26730\n",
      "[23]\ttrain-logloss:0.26372\teval-logloss:0.26666\n",
      "[24]\ttrain-logloss:0.26283\teval-logloss:0.26592\n",
      "[25]\ttrain-logloss:0.26204\teval-logloss:0.26524\n",
      "[26]\ttrain-logloss:0.26126\teval-logloss:0.26469\n",
      "[27]\ttrain-logloss:0.26046\teval-logloss:0.26402\n",
      "[28]\ttrain-logloss:0.25962\teval-logloss:0.26341\n",
      "[29]\ttrain-logloss:0.25886\teval-logloss:0.26280\n",
      "[30]\ttrain-logloss:0.25814\teval-logloss:0.26228\n",
      "[31]\ttrain-logloss:0.25752\teval-logloss:0.26184\n",
      "[32]\ttrain-logloss:0.25685\teval-logloss:0.26124\n",
      "[33]\ttrain-logloss:0.25622\teval-logloss:0.26058\n",
      "[34]\ttrain-logloss:0.25555\teval-logloss:0.26003\n",
      "[35]\ttrain-logloss:0.25487\teval-logloss:0.25955\n",
      "[36]\ttrain-logloss:0.25426\teval-logloss:0.25911\n",
      "[37]\ttrain-logloss:0.25372\teval-logloss:0.25875\n",
      "[38]\ttrain-logloss:0.25309\teval-logloss:0.25830\n",
      "[39]\ttrain-logloss:0.25253\teval-logloss:0.25788\n",
      "[40]\ttrain-logloss:0.25199\teval-logloss:0.25746\n",
      "[41]\ttrain-logloss:0.25142\teval-logloss:0.25701\n",
      "[42]\ttrain-logloss:0.25100\teval-logloss:0.25672\n",
      "[43]\ttrain-logloss:0.25051\teval-logloss:0.25640\n",
      "[44]\ttrain-logloss:0.25001\teval-logloss:0.25601\n",
      "[45]\ttrain-logloss:0.24944\teval-logloss:0.25553\n",
      "[46]\ttrain-logloss:0.24901\teval-logloss:0.25520\n",
      "[47]\ttrain-logloss:0.24854\teval-logloss:0.25490\n",
      "[48]\ttrain-logloss:0.24816\teval-logloss:0.25461\n",
      "[49]\ttrain-logloss:0.24778\teval-logloss:0.25432\n",
      "[50]\ttrain-logloss:0.24738\teval-logloss:0.25405\n",
      "[51]\ttrain-logloss:0.24702\teval-logloss:0.25374\n",
      "[52]\ttrain-logloss:0.24663\teval-logloss:0.25345\n",
      "[53]\ttrain-logloss:0.24627\teval-logloss:0.25331\n",
      "[54]\ttrain-logloss:0.24597\teval-logloss:0.25311\n",
      "[55]\ttrain-logloss:0.24556\teval-logloss:0.25292\n",
      "[56]\ttrain-logloss:0.24522\teval-logloss:0.25271\n",
      "[57]\ttrain-logloss:0.24483\teval-logloss:0.25249\n",
      "[58]\ttrain-logloss:0.24445\teval-logloss:0.25223\n",
      "[59]\ttrain-logloss:0.24418\teval-logloss:0.25205\n",
      "[60]\ttrain-logloss:0.24384\teval-logloss:0.25185\n",
      "[61]\ttrain-logloss:0.24352\teval-logloss:0.25165\n",
      "[62]\ttrain-logloss:0.24319\teval-logloss:0.25143\n",
      "[63]\ttrain-logloss:0.24289\teval-logloss:0.25128\n",
      "[64]\ttrain-logloss:0.24260\teval-logloss:0.25095\n",
      "[65]\ttrain-logloss:0.24231\teval-logloss:0.25076\n",
      "[66]\ttrain-logloss:0.24199\teval-logloss:0.25060\n",
      "[67]\ttrain-logloss:0.24169\teval-logloss:0.25040\n",
      "[68]\ttrain-logloss:0.24146\teval-logloss:0.25035\n",
      "[69]\ttrain-logloss:0.24114\teval-logloss:0.25027\n",
      "[70]\ttrain-logloss:0.24095\teval-logloss:0.25015\n",
      "[71]\ttrain-logloss:0.24064\teval-logloss:0.25001\n",
      "[72]\ttrain-logloss:0.24037\teval-logloss:0.24991\n",
      "[73]\ttrain-logloss:0.24019\teval-logloss:0.24984\n",
      "[74]\ttrain-logloss:0.24000\teval-logloss:0.24965\n",
      "[75]\ttrain-logloss:0.23980\teval-logloss:0.24952\n",
      "[76]\ttrain-logloss:0.23958\teval-logloss:0.24938\n",
      "[77]\ttrain-logloss:0.23931\teval-logloss:0.24926\n",
      "[78]\ttrain-logloss:0.23916\teval-logloss:0.24918\n",
      "[79]\ttrain-logloss:0.23896\teval-logloss:0.24909\n",
      "[80]\ttrain-logloss:0.23877\teval-logloss:0.24901\n",
      "[81]\ttrain-logloss:0.23854\teval-logloss:0.24891\n",
      "[82]\ttrain-logloss:0.23829\teval-logloss:0.24874\n",
      "[83]\ttrain-logloss:0.23815\teval-logloss:0.24864\n",
      "[84]\ttrain-logloss:0.23789\teval-logloss:0.24853\n",
      "[85]\ttrain-logloss:0.23772\teval-logloss:0.24846\n",
      "[86]\ttrain-logloss:0.23754\teval-logloss:0.24843\n",
      "[87]\ttrain-logloss:0.23740\teval-logloss:0.24835\n",
      "[88]\ttrain-logloss:0.23715\teval-logloss:0.24836\n",
      "[89]\ttrain-logloss:0.23697\teval-logloss:0.24828\n",
      "[90]\ttrain-logloss:0.23676\teval-logloss:0.24819\n",
      "[91]\ttrain-logloss:0.23657\teval-logloss:0.24813\n",
      "[92]\ttrain-logloss:0.23637\teval-logloss:0.24809\n",
      "[93]\ttrain-logloss:0.23625\teval-logloss:0.24807\n",
      "[94]\ttrain-logloss:0.23607\teval-logloss:0.24797\n",
      "[95]\ttrain-logloss:0.23586\teval-logloss:0.24780\n",
      "[96]\ttrain-logloss:0.23565\teval-logloss:0.24769\n",
      "[97]\ttrain-logloss:0.23549\teval-logloss:0.24763\n",
      "[98]\ttrain-logloss:0.23532\teval-logloss:0.24755\n",
      "[99]\ttrain-logloss:0.23506\teval-logloss:0.24752\n",
      "[0]\ttrain-logloss:0.28812\teval-logloss:0.28835\n",
      "[1]\ttrain-logloss:0.28684\teval-logloss:0.28724\n",
      "[2]\ttrain-logloss:0.28539\teval-logloss:0.28594\n",
      "[3]\ttrain-logloss:0.28409\teval-logloss:0.28488\n",
      "[4]\ttrain-logloss:0.28280\teval-logloss:0.28380\n",
      "[5]\ttrain-logloss:0.28153\teval-logloss:0.28264\n",
      "[6]\ttrain-logloss:0.28030\teval-logloss:0.28155\n",
      "[7]\ttrain-logloss:0.27910\teval-logloss:0.28057\n",
      "[8]\ttrain-logloss:0.27786\teval-logloss:0.27934\n",
      "[9]\ttrain-logloss:0.27667\teval-logloss:0.27832\n",
      "[10]\ttrain-logloss:0.27553\teval-logloss:0.27728\n",
      "[11]\ttrain-logloss:0.27447\teval-logloss:0.27636\n",
      "[12]\ttrain-logloss:0.27347\teval-logloss:0.27554\n",
      "[13]\ttrain-logloss:0.27236\teval-logloss:0.27451\n",
      "[14]\ttrain-logloss:0.27139\teval-logloss:0.27372\n",
      "[15]\ttrain-logloss:0.27048\teval-logloss:0.27298\n",
      "[16]\ttrain-logloss:0.26956\teval-logloss:0.27219\n",
      "[17]\ttrain-logloss:0.26857\teval-logloss:0.27124\n",
      "[18]\ttrain-logloss:0.26773\teval-logloss:0.27058\n",
      "[19]\ttrain-logloss:0.26685\teval-logloss:0.26979\n",
      "[20]\ttrain-logloss:0.26596\teval-logloss:0.26921\n",
      "[21]\ttrain-logloss:0.26503\teval-logloss:0.26835\n",
      "[22]\ttrain-logloss:0.26414\teval-logloss:0.26757\n",
      "[23]\ttrain-logloss:0.26342\teval-logloss:0.26691\n",
      "[24]\ttrain-logloss:0.26261\teval-logloss:0.26612\n",
      "[25]\ttrain-logloss:0.26181\teval-logloss:0.26539\n",
      "[26]\ttrain-logloss:0.26103\teval-logloss:0.26476\n",
      "[27]\ttrain-logloss:0.26024\teval-logloss:0.26411\n",
      "[28]\ttrain-logloss:0.25948\teval-logloss:0.26343\n",
      "[29]\ttrain-logloss:0.25870\teval-logloss:0.26278\n",
      "[30]\ttrain-logloss:0.25801\teval-logloss:0.26220\n",
      "[31]\ttrain-logloss:0.25744\teval-logloss:0.26173\n",
      "[32]\ttrain-logloss:0.25677\teval-logloss:0.26121\n",
      "[33]\ttrain-logloss:0.25608\teval-logloss:0.26067\n",
      "[34]\ttrain-logloss:0.25547\teval-logloss:0.26016\n",
      "[35]\ttrain-logloss:0.25485\teval-logloss:0.25964\n",
      "[36]\ttrain-logloss:0.25421\teval-logloss:0.25910\n",
      "[37]\ttrain-logloss:0.25368\teval-logloss:0.25867\n",
      "[38]\ttrain-logloss:0.25307\teval-logloss:0.25821\n",
      "[39]\ttrain-logloss:0.25247\teval-logloss:0.25771\n",
      "[40]\ttrain-logloss:0.25189\teval-logloss:0.25715\n",
      "[41]\ttrain-logloss:0.25132\teval-logloss:0.25674\n",
      "[42]\ttrain-logloss:0.25090\teval-logloss:0.25645\n",
      "[43]\ttrain-logloss:0.25043\teval-logloss:0.25613\n",
      "[44]\ttrain-logloss:0.24996\teval-logloss:0.25578\n",
      "[45]\ttrain-logloss:0.24945\teval-logloss:0.25533\n",
      "[46]\ttrain-logloss:0.24905\teval-logloss:0.25509\n",
      "[47]\ttrain-logloss:0.24855\teval-logloss:0.25473\n",
      "[48]\ttrain-logloss:0.24816\teval-logloss:0.25449\n",
      "[49]\ttrain-logloss:0.24774\teval-logloss:0.25420\n",
      "[50]\ttrain-logloss:0.24737\teval-logloss:0.25388\n",
      "[51]\ttrain-logloss:0.24699\teval-logloss:0.25362\n",
      "[52]\ttrain-logloss:0.24658\teval-logloss:0.25325\n",
      "[53]\ttrain-logloss:0.24625\teval-logloss:0.25307\n",
      "[54]\ttrain-logloss:0.24596\teval-logloss:0.25290\n",
      "[55]\ttrain-logloss:0.24556\teval-logloss:0.25271\n",
      "[56]\ttrain-logloss:0.24516\teval-logloss:0.25247\n",
      "[57]\ttrain-logloss:0.24480\teval-logloss:0.25216\n",
      "[58]\ttrain-logloss:0.24445\teval-logloss:0.25190\n",
      "[59]\ttrain-logloss:0.24415\teval-logloss:0.25178\n",
      "[60]\ttrain-logloss:0.24382\teval-logloss:0.25154\n",
      "[61]\ttrain-logloss:0.24356\teval-logloss:0.25135\n",
      "[62]\ttrain-logloss:0.24320\teval-logloss:0.25119\n",
      "[63]\ttrain-logloss:0.24290\teval-logloss:0.25099\n",
      "[64]\ttrain-logloss:0.24265\teval-logloss:0.25083\n",
      "[65]\ttrain-logloss:0.24236\teval-logloss:0.25064\n",
      "[66]\ttrain-logloss:0.24207\teval-logloss:0.25039\n",
      "[67]\ttrain-logloss:0.24183\teval-logloss:0.25023\n",
      "[68]\ttrain-logloss:0.24158\teval-logloss:0.25008\n",
      "[69]\ttrain-logloss:0.24130\teval-logloss:0.24989\n",
      "[70]\ttrain-logloss:0.24106\teval-logloss:0.24981\n",
      "[71]\ttrain-logloss:0.24070\teval-logloss:0.24963\n",
      "[72]\ttrain-logloss:0.24038\teval-logloss:0.24945\n",
      "[73]\ttrain-logloss:0.24017\teval-logloss:0.24935\n",
      "[74]\ttrain-logloss:0.23992\teval-logloss:0.24931\n",
      "[75]\ttrain-logloss:0.23970\teval-logloss:0.24922\n",
      "[76]\ttrain-logloss:0.23946\teval-logloss:0.24909\n",
      "[77]\ttrain-logloss:0.23923\teval-logloss:0.24893\n",
      "[78]\ttrain-logloss:0.23903\teval-logloss:0.24880\n",
      "[79]\ttrain-logloss:0.23886\teval-logloss:0.24869\n",
      "[80]\ttrain-logloss:0.23865\teval-logloss:0.24856\n",
      "[81]\ttrain-logloss:0.23834\teval-logloss:0.24845\n",
      "[82]\ttrain-logloss:0.23812\teval-logloss:0.24839\n",
      "[83]\ttrain-logloss:0.23789\teval-logloss:0.24836\n",
      "[84]\ttrain-logloss:0.23767\teval-logloss:0.24821\n",
      "[85]\ttrain-logloss:0.23748\teval-logloss:0.24817\n",
      "[86]\ttrain-logloss:0.23733\teval-logloss:0.24805\n",
      "[87]\ttrain-logloss:0.23714\teval-logloss:0.24805\n",
      "[88]\ttrain-logloss:0.23693\teval-logloss:0.24793\n",
      "[89]\ttrain-logloss:0.23674\teval-logloss:0.24786\n",
      "[90]\ttrain-logloss:0.23653\teval-logloss:0.24772\n",
      "[91]\ttrain-logloss:0.23635\teval-logloss:0.24764\n",
      "[92]\ttrain-logloss:0.23613\teval-logloss:0.24754\n",
      "[93]\ttrain-logloss:0.23598\teval-logloss:0.24760\n",
      "[94]\ttrain-logloss:0.23575\teval-logloss:0.24758\n",
      "[95]\ttrain-logloss:0.23556\teval-logloss:0.24753\n",
      "[96]\ttrain-logloss:0.23533\teval-logloss:0.24741\n",
      "[97]\ttrain-logloss:0.23518\teval-logloss:0.24735\n",
      "[98]\ttrain-logloss:0.23502\teval-logloss:0.24737\n",
      "[99]\ttrain-logloss:0.23485\teval-logloss:0.24732\n",
      "[0]\ttrain-logloss:0.28814\teval-logloss:0.28831\n",
      "[1]\ttrain-logloss:0.28685\teval-logloss:0.28720\n",
      "[2]\ttrain-logloss:0.28528\teval-logloss:0.28592\n",
      "[3]\ttrain-logloss:0.28405\teval-logloss:0.28484\n",
      "[4]\ttrain-logloss:0.28275\teval-logloss:0.28377\n",
      "[5]\ttrain-logloss:0.28148\teval-logloss:0.28275\n",
      "[6]\ttrain-logloss:0.28026\teval-logloss:0.28171\n",
      "[7]\ttrain-logloss:0.27909\teval-logloss:0.28070\n",
      "[8]\ttrain-logloss:0.27776\teval-logloss:0.27970\n",
      "[9]\ttrain-logloss:0.27661\teval-logloss:0.27881\n",
      "[10]\ttrain-logloss:0.27547\teval-logloss:0.27786\n",
      "[11]\ttrain-logloss:0.27444\teval-logloss:0.27693\n",
      "[12]\ttrain-logloss:0.27340\teval-logloss:0.27609\n",
      "[13]\ttrain-logloss:0.27221\teval-logloss:0.27520\n",
      "[14]\ttrain-logloss:0.27128\teval-logloss:0.27439\n",
      "[15]\ttrain-logloss:0.27032\teval-logloss:0.27350\n",
      "[16]\ttrain-logloss:0.26941\teval-logloss:0.27274\n",
      "[17]\ttrain-logloss:0.26837\teval-logloss:0.27199\n",
      "[18]\ttrain-logloss:0.26753\teval-logloss:0.27123\n",
      "[19]\ttrain-logloss:0.26658\teval-logloss:0.27055\n",
      "[20]\ttrain-logloss:0.26579\teval-logloss:0.26988\n",
      "[21]\ttrain-logloss:0.26478\teval-logloss:0.26919\n",
      "[22]\ttrain-logloss:0.26388\teval-logloss:0.26856\n",
      "[23]\ttrain-logloss:0.26313\teval-logloss:0.26793\n",
      "[24]\ttrain-logloss:0.26225\teval-logloss:0.26738\n",
      "[25]\ttrain-logloss:0.26149\teval-logloss:0.26679\n",
      "[26]\ttrain-logloss:0.26074\teval-logloss:0.26625\n",
      "[27]\ttrain-logloss:0.25991\teval-logloss:0.26572\n",
      "[28]\ttrain-logloss:0.25910\teval-logloss:0.26522\n",
      "[29]\ttrain-logloss:0.25833\teval-logloss:0.26473\n",
      "[30]\ttrain-logloss:0.25759\teval-logloss:0.26430\n",
      "[31]\ttrain-logloss:0.25699\teval-logloss:0.26381\n",
      "[32]\ttrain-logloss:0.25627\teval-logloss:0.26336\n",
      "[33]\ttrain-logloss:0.25557\teval-logloss:0.26288\n",
      "[34]\ttrain-logloss:0.25490\teval-logloss:0.26241\n",
      "[35]\ttrain-logloss:0.25426\teval-logloss:0.26205\n",
      "[36]\ttrain-logloss:0.25362\teval-logloss:0.26164\n",
      "[37]\ttrain-logloss:0.25300\teval-logloss:0.26123\n",
      "[38]\ttrain-logloss:0.25241\teval-logloss:0.26089\n",
      "[39]\ttrain-logloss:0.25184\teval-logloss:0.26048\n",
      "[40]\ttrain-logloss:0.25122\teval-logloss:0.26012\n",
      "[41]\ttrain-logloss:0.25071\teval-logloss:0.25982\n",
      "[42]\ttrain-logloss:0.25024\teval-logloss:0.25944\n",
      "[43]\ttrain-logloss:0.24981\teval-logloss:0.25909\n",
      "[44]\ttrain-logloss:0.24933\teval-logloss:0.25881\n",
      "[45]\ttrain-logloss:0.24880\teval-logloss:0.25846\n",
      "[46]\ttrain-logloss:0.24835\teval-logloss:0.25816\n",
      "[47]\ttrain-logloss:0.24781\teval-logloss:0.25789\n",
      "[48]\ttrain-logloss:0.24742\teval-logloss:0.25757\n",
      "[49]\ttrain-logloss:0.24703\teval-logloss:0.25730\n",
      "[50]\ttrain-logloss:0.24663\teval-logloss:0.25699\n",
      "[51]\ttrain-logloss:0.24630\teval-logloss:0.25671\n",
      "[52]\ttrain-logloss:0.24589\teval-logloss:0.25648\n",
      "[53]\ttrain-logloss:0.24553\teval-logloss:0.25624\n",
      "[54]\ttrain-logloss:0.24519\teval-logloss:0.25607\n",
      "[55]\ttrain-logloss:0.24482\teval-logloss:0.25582\n",
      "[56]\ttrain-logloss:0.24445\teval-logloss:0.25563\n",
      "[57]\ttrain-logloss:0.24406\teval-logloss:0.25543\n",
      "[58]\ttrain-logloss:0.24369\teval-logloss:0.25533\n",
      "[59]\ttrain-logloss:0.24344\teval-logloss:0.25519\n",
      "[60]\ttrain-logloss:0.24306\teval-logloss:0.25500\n",
      "[61]\ttrain-logloss:0.24279\teval-logloss:0.25486\n",
      "[62]\ttrain-logloss:0.24242\teval-logloss:0.25472\n",
      "[63]\ttrain-logloss:0.24214\teval-logloss:0.25462\n",
      "[64]\ttrain-logloss:0.24187\teval-logloss:0.25447\n",
      "[65]\ttrain-logloss:0.24154\teval-logloss:0.25436\n",
      "[66]\ttrain-logloss:0.24118\teval-logloss:0.25423\n",
      "[67]\ttrain-logloss:0.24092\teval-logloss:0.25406\n",
      "[68]\ttrain-logloss:0.24061\teval-logloss:0.25391\n",
      "[69]\ttrain-logloss:0.24030\teval-logloss:0.25380\n",
      "[70]\ttrain-logloss:0.24013\teval-logloss:0.25369\n",
      "[71]\ttrain-logloss:0.23985\teval-logloss:0.25362\n",
      "[72]\ttrain-logloss:0.23955\teval-logloss:0.25354\n",
      "[73]\ttrain-logloss:0.23929\teval-logloss:0.25341\n",
      "[74]\ttrain-logloss:0.23911\teval-logloss:0.25328\n",
      "[75]\ttrain-logloss:0.23889\teval-logloss:0.25319\n",
      "[76]\ttrain-logloss:0.23859\teval-logloss:0.25310\n",
      "[77]\ttrain-logloss:0.23830\teval-logloss:0.25297\n",
      "[78]\ttrain-logloss:0.23810\teval-logloss:0.25287\n",
      "[79]\ttrain-logloss:0.23792\teval-logloss:0.25282\n",
      "[80]\ttrain-logloss:0.23766\teval-logloss:0.25267\n",
      "[81]\ttrain-logloss:0.23732\teval-logloss:0.25263\n",
      "[82]\ttrain-logloss:0.23706\teval-logloss:0.25255\n",
      "[83]\ttrain-logloss:0.23688\teval-logloss:0.25243\n",
      "[84]\ttrain-logloss:0.23668\teval-logloss:0.25245\n",
      "[85]\ttrain-logloss:0.23653\teval-logloss:0.25232\n",
      "[86]\ttrain-logloss:0.23639\teval-logloss:0.25227\n",
      "[87]\ttrain-logloss:0.23622\teval-logloss:0.25216\n",
      "[88]\ttrain-logloss:0.23603\teval-logloss:0.25212\n",
      "[89]\ttrain-logloss:0.23592\teval-logloss:0.25206\n",
      "[90]\ttrain-logloss:0.23572\teval-logloss:0.25194\n",
      "[91]\ttrain-logloss:0.23548\teval-logloss:0.25194\n",
      "[92]\ttrain-logloss:0.23531\teval-logloss:0.25192\n",
      "[93]\ttrain-logloss:0.23512\teval-logloss:0.25183\n",
      "[94]\ttrain-logloss:0.23497\teval-logloss:0.25177\n",
      "[95]\ttrain-logloss:0.23476\teval-logloss:0.25169\n",
      "[96]\ttrain-logloss:0.23454\teval-logloss:0.25168\n",
      "[97]\ttrain-logloss:0.23438\teval-logloss:0.25163\n",
      "[98]\ttrain-logloss:0.23421\teval-logloss:0.25158\n",
      "[99]\ttrain-logloss:0.23403\teval-logloss:0.25152\n",
      "[0]\ttrain-logloss:0.28811\teval-logloss:0.28833\n",
      "[1]\ttrain-logloss:0.28681\teval-logloss:0.28720\n",
      "[2]\ttrain-logloss:0.28529\teval-logloss:0.28586\n",
      "[3]\ttrain-logloss:0.28411\teval-logloss:0.28481\n",
      "[4]\ttrain-logloss:0.28287\teval-logloss:0.28352\n",
      "[5]\ttrain-logloss:0.28160\teval-logloss:0.28244\n",
      "[6]\ttrain-logloss:0.28031\teval-logloss:0.28124\n",
      "[7]\ttrain-logloss:0.27914\teval-logloss:0.28020\n",
      "[8]\ttrain-logloss:0.27793\teval-logloss:0.27904\n",
      "[9]\ttrain-logloss:0.27679\teval-logloss:0.27797\n",
      "[10]\ttrain-logloss:0.27572\teval-logloss:0.27699\n",
      "[11]\ttrain-logloss:0.27467\teval-logloss:0.27608\n",
      "[12]\ttrain-logloss:0.27368\teval-logloss:0.27518\n",
      "[13]\ttrain-logloss:0.27251\teval-logloss:0.27421\n",
      "[14]\ttrain-logloss:0.27154\teval-logloss:0.27335\n",
      "[15]\ttrain-logloss:0.27062\teval-logloss:0.27267\n",
      "[16]\ttrain-logloss:0.26968\teval-logloss:0.27195\n",
      "[17]\ttrain-logloss:0.26865\teval-logloss:0.27110\n",
      "[18]\ttrain-logloss:0.26778\teval-logloss:0.27040\n",
      "[19]\ttrain-logloss:0.26690\teval-logloss:0.26967\n",
      "[20]\ttrain-logloss:0.26614\teval-logloss:0.26895\n",
      "[21]\ttrain-logloss:0.26517\teval-logloss:0.26810\n",
      "[22]\ttrain-logloss:0.26429\teval-logloss:0.26737\n",
      "[23]\ttrain-logloss:0.26357\teval-logloss:0.26677\n",
      "[24]\ttrain-logloss:0.26266\teval-logloss:0.26607\n",
      "[25]\ttrain-logloss:0.26188\teval-logloss:0.26534\n",
      "[26]\ttrain-logloss:0.26116\teval-logloss:0.26465\n",
      "[27]\ttrain-logloss:0.26034\teval-logloss:0.26391\n",
      "[28]\ttrain-logloss:0.25959\teval-logloss:0.26324\n",
      "[29]\ttrain-logloss:0.25883\teval-logloss:0.26259\n",
      "[30]\ttrain-logloss:0.25814\teval-logloss:0.26198\n",
      "[31]\ttrain-logloss:0.25752\teval-logloss:0.26147\n",
      "[32]\ttrain-logloss:0.25681\teval-logloss:0.26089\n",
      "[33]\ttrain-logloss:0.25623\teval-logloss:0.26035\n",
      "[34]\ttrain-logloss:0.25554\teval-logloss:0.25984\n",
      "[35]\ttrain-logloss:0.25494\teval-logloss:0.25936\n",
      "[36]\ttrain-logloss:0.25430\teval-logloss:0.25885\n",
      "[37]\ttrain-logloss:0.25375\teval-logloss:0.25841\n",
      "[38]\ttrain-logloss:0.25317\teval-logloss:0.25792\n",
      "[39]\ttrain-logloss:0.25259\teval-logloss:0.25748\n",
      "[40]\ttrain-logloss:0.25204\teval-logloss:0.25706\n",
      "[41]\ttrain-logloss:0.25156\teval-logloss:0.25665\n",
      "[42]\ttrain-logloss:0.25109\teval-logloss:0.25635\n",
      "[43]\ttrain-logloss:0.25063\teval-logloss:0.25604\n",
      "[44]\ttrain-logloss:0.25013\teval-logloss:0.25562\n",
      "[45]\ttrain-logloss:0.24961\teval-logloss:0.25524\n",
      "[46]\ttrain-logloss:0.24920\teval-logloss:0.25490\n",
      "[47]\ttrain-logloss:0.24870\teval-logloss:0.25460\n",
      "[48]\ttrain-logloss:0.24832\teval-logloss:0.25433\n",
      "[49]\ttrain-logloss:0.24795\teval-logloss:0.25410\n",
      "[50]\ttrain-logloss:0.24758\teval-logloss:0.25380\n",
      "[51]\ttrain-logloss:0.24721\teval-logloss:0.25360\n",
      "[52]\ttrain-logloss:0.24680\teval-logloss:0.25328\n",
      "[53]\ttrain-logloss:0.24645\teval-logloss:0.25300\n",
      "[54]\ttrain-logloss:0.24612\teval-logloss:0.25275\n",
      "[55]\ttrain-logloss:0.24569\teval-logloss:0.25250\n",
      "[56]\ttrain-logloss:0.24527\teval-logloss:0.25225\n",
      "[57]\ttrain-logloss:0.24490\teval-logloss:0.25209\n",
      "[58]\ttrain-logloss:0.24458\teval-logloss:0.25188\n",
      "[59]\ttrain-logloss:0.24428\teval-logloss:0.25168\n",
      "[60]\ttrain-logloss:0.24390\teval-logloss:0.25148\n",
      "[61]\ttrain-logloss:0.24361\teval-logloss:0.25130\n",
      "[62]\ttrain-logloss:0.24327\teval-logloss:0.25113\n",
      "[63]\ttrain-logloss:0.24294\teval-logloss:0.25104\n",
      "[64]\ttrain-logloss:0.24270\teval-logloss:0.25090\n",
      "[65]\ttrain-logloss:0.24239\teval-logloss:0.25071\n",
      "[66]\ttrain-logloss:0.24205\teval-logloss:0.25045\n",
      "[67]\ttrain-logloss:0.24180\teval-logloss:0.25029\n",
      "[68]\ttrain-logloss:0.24148\teval-logloss:0.25014\n",
      "[69]\ttrain-logloss:0.24121\teval-logloss:0.24997\n",
      "[70]\ttrain-logloss:0.24097\teval-logloss:0.24994\n",
      "[71]\ttrain-logloss:0.24065\teval-logloss:0.24976\n",
      "[72]\ttrain-logloss:0.24036\teval-logloss:0.24956\n",
      "[73]\ttrain-logloss:0.24019\teval-logloss:0.24944\n",
      "[74]\ttrain-logloss:0.23995\teval-logloss:0.24935\n",
      "[75]\ttrain-logloss:0.23974\teval-logloss:0.24929\n",
      "[76]\ttrain-logloss:0.23952\teval-logloss:0.24911\n",
      "[77]\ttrain-logloss:0.23931\teval-logloss:0.24902\n",
      "[78]\ttrain-logloss:0.23914\teval-logloss:0.24891\n",
      "[79]\ttrain-logloss:0.23897\teval-logloss:0.24884\n",
      "[80]\ttrain-logloss:0.23871\teval-logloss:0.24864\n",
      "[81]\ttrain-logloss:0.23851\teval-logloss:0.24856\n",
      "[82]\ttrain-logloss:0.23828\teval-logloss:0.24849\n",
      "[83]\ttrain-logloss:0.23812\teval-logloss:0.24843\n",
      "[84]\ttrain-logloss:0.23793\teval-logloss:0.24830\n",
      "[85]\ttrain-logloss:0.23772\teval-logloss:0.24817\n",
      "[86]\ttrain-logloss:0.23756\teval-logloss:0.24811\n",
      "[87]\ttrain-logloss:0.23739\teval-logloss:0.24805\n",
      "[88]\ttrain-logloss:0.23720\teval-logloss:0.24798\n",
      "[89]\ttrain-logloss:0.23697\teval-logloss:0.24792\n",
      "[90]\ttrain-logloss:0.23676\teval-logloss:0.24787\n",
      "[91]\ttrain-logloss:0.23659\teval-logloss:0.24774\n",
      "[92]\ttrain-logloss:0.23641\teval-logloss:0.24772\n",
      "[93]\ttrain-logloss:0.23627\teval-logloss:0.24766\n",
      "[94]\ttrain-logloss:0.23610\teval-logloss:0.24767\n",
      "[95]\ttrain-logloss:0.23590\teval-logloss:0.24766\n",
      "[96]\ttrain-logloss:0.23571\teval-logloss:0.24762\n",
      "[97]\ttrain-logloss:0.23552\teval-logloss:0.24754\n",
      "[98]\ttrain-logloss:0.23537\teval-logloss:0.24751\n",
      "[99]\ttrain-logloss:0.23519\teval-logloss:0.24738\n",
      "[0]\ttrain-logloss:0.28816\teval-logloss:0.28845\n",
      "[1]\ttrain-logloss:0.28693\teval-logloss:0.28730\n",
      "[2]\ttrain-logloss:0.28550\teval-logloss:0.28589\n",
      "[3]\ttrain-logloss:0.28434\teval-logloss:0.28481\n",
      "[4]\ttrain-logloss:0.28305\teval-logloss:0.28361\n",
      "[5]\ttrain-logloss:0.28178\teval-logloss:0.28247\n",
      "[6]\ttrain-logloss:0.28055\teval-logloss:0.28148\n",
      "[7]\ttrain-logloss:0.27935\teval-logloss:0.28043\n",
      "[8]\ttrain-logloss:0.27804\teval-logloss:0.27924\n",
      "[9]\ttrain-logloss:0.27697\teval-logloss:0.27823\n",
      "[10]\ttrain-logloss:0.27584\teval-logloss:0.27727\n",
      "[11]\ttrain-logloss:0.27479\teval-logloss:0.27635\n",
      "[12]\ttrain-logloss:0.27374\teval-logloss:0.27547\n",
      "[13]\ttrain-logloss:0.27265\teval-logloss:0.27442\n",
      "[14]\ttrain-logloss:0.27165\teval-logloss:0.27358\n",
      "[15]\ttrain-logloss:0.27067\teval-logloss:0.27284\n",
      "[16]\ttrain-logloss:0.26973\teval-logloss:0.27204\n",
      "[17]\ttrain-logloss:0.26877\teval-logloss:0.27115\n",
      "[18]\ttrain-logloss:0.26790\teval-logloss:0.27048\n",
      "[19]\ttrain-logloss:0.26692\teval-logloss:0.26970\n",
      "[20]\ttrain-logloss:0.26614\teval-logloss:0.26902\n",
      "[21]\ttrain-logloss:0.26516\teval-logloss:0.26822\n",
      "[22]\ttrain-logloss:0.26420\teval-logloss:0.26742\n",
      "[23]\ttrain-logloss:0.26349\teval-logloss:0.26688\n",
      "[24]\ttrain-logloss:0.26261\teval-logloss:0.26615\n",
      "[25]\ttrain-logloss:0.26190\teval-logloss:0.26550\n",
      "[26]\ttrain-logloss:0.26121\teval-logloss:0.26492\n",
      "[27]\ttrain-logloss:0.26037\teval-logloss:0.26417\n",
      "[28]\ttrain-logloss:0.25956\teval-logloss:0.26349\n",
      "[29]\ttrain-logloss:0.25872\teval-logloss:0.26288\n",
      "[30]\ttrain-logloss:0.25801\teval-logloss:0.26233\n",
      "[31]\ttrain-logloss:0.25734\teval-logloss:0.26181\n",
      "[32]\ttrain-logloss:0.25661\teval-logloss:0.26128\n",
      "[33]\ttrain-logloss:0.25601\teval-logloss:0.26079\n",
      "[34]\ttrain-logloss:0.25533\teval-logloss:0.26021\n",
      "[35]\ttrain-logloss:0.25468\teval-logloss:0.25969\n",
      "[36]\ttrain-logloss:0.25409\teval-logloss:0.25925\n",
      "[37]\ttrain-logloss:0.25352\teval-logloss:0.25879\n",
      "[38]\ttrain-logloss:0.25291\teval-logloss:0.25832\n",
      "[39]\ttrain-logloss:0.25236\teval-logloss:0.25789\n",
      "[40]\ttrain-logloss:0.25183\teval-logloss:0.25746\n",
      "[41]\ttrain-logloss:0.25129\teval-logloss:0.25706\n",
      "[42]\ttrain-logloss:0.25077\teval-logloss:0.25671\n",
      "[43]\ttrain-logloss:0.25035\teval-logloss:0.25637\n",
      "[44]\ttrain-logloss:0.24986\teval-logloss:0.25601\n",
      "[45]\ttrain-logloss:0.24935\teval-logloss:0.25562\n",
      "[46]\ttrain-logloss:0.24893\teval-logloss:0.25533\n",
      "[47]\ttrain-logloss:0.24845\teval-logloss:0.25494\n",
      "[48]\ttrain-logloss:0.24800\teval-logloss:0.25465\n",
      "[49]\ttrain-logloss:0.24764\teval-logloss:0.25443\n",
      "[50]\ttrain-logloss:0.24723\teval-logloss:0.25410\n",
      "[51]\ttrain-logloss:0.24689\teval-logloss:0.25389\n",
      "[52]\ttrain-logloss:0.24655\teval-logloss:0.25361\n",
      "[53]\ttrain-logloss:0.24623\teval-logloss:0.25343\n",
      "[54]\ttrain-logloss:0.24590\teval-logloss:0.25319\n",
      "[55]\ttrain-logloss:0.24550\teval-logloss:0.25295\n",
      "[56]\ttrain-logloss:0.24514\teval-logloss:0.25265\n",
      "[57]\ttrain-logloss:0.24471\teval-logloss:0.25253\n",
      "[58]\ttrain-logloss:0.24437\teval-logloss:0.25233\n",
      "[59]\ttrain-logloss:0.24409\teval-logloss:0.25216\n",
      "[60]\ttrain-logloss:0.24376\teval-logloss:0.25191\n",
      "[61]\ttrain-logloss:0.24344\teval-logloss:0.25179\n",
      "[62]\ttrain-logloss:0.24307\teval-logloss:0.25155\n",
      "[63]\ttrain-logloss:0.24276\teval-logloss:0.25138\n",
      "[64]\ttrain-logloss:0.24250\teval-logloss:0.25123\n",
      "[65]\ttrain-logloss:0.24223\teval-logloss:0.25097\n",
      "[66]\ttrain-logloss:0.24187\teval-logloss:0.25078\n",
      "[67]\ttrain-logloss:0.24161\teval-logloss:0.25072\n",
      "[68]\ttrain-logloss:0.24134\teval-logloss:0.25059\n",
      "[69]\ttrain-logloss:0.24106\teval-logloss:0.25053\n",
      "[70]\ttrain-logloss:0.24080\teval-logloss:0.25036\n",
      "[71]\ttrain-logloss:0.24053\teval-logloss:0.25016\n",
      "[72]\ttrain-logloss:0.24019\teval-logloss:0.25004\n",
      "[73]\ttrain-logloss:0.23999\teval-logloss:0.24990\n",
      "[74]\ttrain-logloss:0.23977\teval-logloss:0.24983\n",
      "[75]\ttrain-logloss:0.23952\teval-logloss:0.24966\n",
      "[76]\ttrain-logloss:0.23918\teval-logloss:0.24952\n",
      "[77]\ttrain-logloss:0.23898\teval-logloss:0.24935\n",
      "[78]\ttrain-logloss:0.23875\teval-logloss:0.24918\n",
      "[79]\ttrain-logloss:0.23856\teval-logloss:0.24908\n",
      "[80]\ttrain-logloss:0.23833\teval-logloss:0.24895\n",
      "[81]\ttrain-logloss:0.23805\teval-logloss:0.24889\n",
      "[82]\ttrain-logloss:0.23780\teval-logloss:0.24884\n",
      "[83]\ttrain-logloss:0.23763\teval-logloss:0.24875\n",
      "[84]\ttrain-logloss:0.23740\teval-logloss:0.24864\n",
      "[85]\ttrain-logloss:0.23722\teval-logloss:0.24858\n",
      "[86]\ttrain-logloss:0.23701\teval-logloss:0.24851\n",
      "[87]\ttrain-logloss:0.23687\teval-logloss:0.24842\n",
      "[88]\ttrain-logloss:0.23666\teval-logloss:0.24835\n",
      "[89]\ttrain-logloss:0.23646\teval-logloss:0.24824\n",
      "[90]\ttrain-logloss:0.23626\teval-logloss:0.24813\n",
      "[91]\ttrain-logloss:0.23606\teval-logloss:0.24801\n",
      "[92]\ttrain-logloss:0.23586\teval-logloss:0.24789\n",
      "[93]\ttrain-logloss:0.23570\teval-logloss:0.24788\n",
      "[94]\ttrain-logloss:0.23556\teval-logloss:0.24783\n",
      "[95]\ttrain-logloss:0.23536\teval-logloss:0.24776\n",
      "[96]\ttrain-logloss:0.23516\teval-logloss:0.24773\n",
      "[97]\ttrain-logloss:0.23499\teval-logloss:0.24767\n",
      "[98]\ttrain-logloss:0.23481\teval-logloss:0.24765\n",
      "[99]\ttrain-logloss:0.23461\teval-logloss:0.24753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 16:05:35,062] Trial 4 finished with value: 0.24825329034903967 and parameters: {'eta': 0.020731849490478793, 'max_depth': 5, 'subsample': 0.7745570964456191, 'colsample_bytree': 0.6902371409050212, 'min_child_weight': 4, 'lambda': 0.0865690416659273, 'alpha': 0.0016686161100794377}. Best is trial 4 with value: 0.24825329034903967.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0.24825329034903967\n",
      "Best params: {'eta': 0.020731849490478793, 'max_depth': 5, 'subsample': 0.7745570964456191, 'colsample_bytree': 0.6902371409050212, 'min_child_weight': 4, 'lambda': 0.0865690416659273, 'alpha': 0.0016686161100794377}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eta': 0.020731849490478793,\n",
       " 'max_depth': 5,\n",
       " 'subsample': 0.7745570964456191,\n",
       " 'colsample_bytree': 0.6902371409050212,\n",
       " 'min_child_weight': 4,\n",
       " 'lambda': 0.0865690416659273,\n",
       " 'alpha': 0.0016686161100794377}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_hyperparameters_xgboost(data[columns_base], data[target_binary], columns_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost_stratified_kfold(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    columns_feature: List[str],\n",
    "    target_binary: List[str],  # この実装では使用しないが、型情報を含める\n",
    "    param: Dict[str, any],\n",
    "    n_splits: int = 5,\n",
    ") -> Tuple[List[CatBoostClassifier], List[float]]:\n",
    "    \"\"\"\n",
    "    Stratified k-foldクロスバリデーションを使用してCatBoostモデルを訓練する関数。\n",
    "    非均衡データを考慮して、各クラスの割合を保持する。\n",
    "\n",
    "    引数:\n",
    "    - X: pandas DataFrame, 特徴量データ。\n",
    "    - y: pandas Series, 目的変数データ。\n",
    "    - columns_feature: list, 特徴量のカラム名のリスト。\n",
    "    - target_binary: list, 目的変数のカラム名のリスト（この関数では使用しないが、一貫性のために残す）。\n",
    "    - param: dict, CatBoostモデルのパラメータ。\n",
    "    - n_splits: int, クロスバリデーションの分割数。\n",
    "\n",
    "    戻り値:\n",
    "    - Tuple[List[CatBoostClassifier], List[float]]: 訓練済みCatBoostモデルのリストと各foldのlog lossスコアのリスト。\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    models: List[CatBoostClassifier] = []\n",
    "    scores: List[float] = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = (\n",
    "            X.iloc[train_index][columns_feature],\n",
    "            X.iloc[test_index][columns_feature],\n",
    "        )\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        train_pool = Pool(X_train, y_train)\n",
    "        test_pool = Pool(X_test, y_test)\n",
    "\n",
    "        model = CatBoostClassifier(**param)\n",
    "        model.fit(\n",
    "            train_pool,\n",
    "            eval_set=test_pool,\n",
    "            # verbose=50,\n",
    "            # early_stopping_rounds=100,\n",
    "            use_best_model=True,\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict_proba(X_test)[:, 1]\n",
    "        score = log_loss(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "        models.append(model)\n",
    "\n",
    "    return models, scores\n",
    "\n",
    "\n",
    "def predict_with_catboost(\n",
    "    models: List[CatBoostClassifier], X_test: pd.DataFrame, columns_feature: List[str]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    訓練済みCatBoostモデルのリストを使用してテストデータセットの予測を行う関数。\n",
    "\n",
    "    引数:\n",
    "    - models: List[CatBoostClassifier], 訓練済みCatBoostモデルのリスト。\n",
    "    - X_test: pandas DataFrame, テストデータセット。\n",
    "    - columns_feature: list, 特徴量のカラム名のリスト。\n",
    "\n",
    "    戻り値:\n",
    "    - np.ndarray: テストデータセットの予測値の平均値。\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    for model in models:\n",
    "        y_pred = model.predict_proba(X_test[columns_feature])[:, 1]\n",
    "        predictions.append(y_pred)\n",
    "\n",
    "    predictions_mean = np.mean(predictions, axis=0)\n",
    "\n",
    "    return predictions_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_catboost(trial, X, y, columns_feature, n_splits=5):\n",
    "    \"\"\"\n",
    "    Optunaの試行に対する目的関数。CatBoostのハイパーパラメータを探索する。\n",
    "\n",
    "    引数:\n",
    "    - trial: optuna.trial.Trial オブジェクト\n",
    "    - X, y: 訓練データ\n",
    "    - columns_feature: 特徴量のカラム名のリスト\n",
    "    - n_splits: クロスバリデーションの分割数\n",
    "\n",
    "    戻り値:\n",
    "    - 試行の平均log lossスコア\n",
    "    \"\"\"\n",
    "    param = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"random_strength\": trial.suggest_int(\"random_strength\", 1, 20),\n",
    "        \"bagging_temperature\": trial.suggest_loguniform(\n",
    "            \"bagging_temperature\", 0.01, 1.0\n",
    "        ),\n",
    "        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 1, 255),\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"Logloss\",\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    _, scores = train_catboost_stratified_kfold(\n",
    "        X, y, columns_feature, [], param, n_splits\n",
    "    )\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def optimize_hyperparameters_catboost(\n",
    "    X, y, columns_feature, n_trials=100, n_splits=5, timeout=300\n",
    "):\n",
    "    \"\"\"\n",
    "    Optunaを使用してCatBoostモデルのハイパーパラメータを最適化する。\n",
    "\n",
    "    引数:\n",
    "    - X, y: 訓練データ\n",
    "    - columns_feature: 特徴量のカラム名のリスト\n",
    "    - n_trials: 試行回数の上限\n",
    "    - n_splits: クロスバリデーションの分割数\n",
    "    - timeout: 探索にかける時間の上限（秒）\n",
    "\n",
    "    戻り値:\n",
    "    - 最適なハイパーパラメータの辞書\n",
    "    \"\"\"\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(\n",
    "        lambda trial: objective_catboost(trial, X, y, columns_feature, n_splits),\n",
    "        n_trials=n_trials,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    print(f\"Best trial: {study.best_trial.value}\")\n",
    "    print(f\"Best params: {study.best_trial.params}\")\n",
    "\n",
    "    return study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 16:06:04,153] A new study created in memory with name: no-name-08574b2c-f97f-4485-8205-3b615d23d841\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:06:38,500] Trial 0 finished with value: 0.2532592351052029 and parameters: {'iterations': 974, 'depth': 8, 'learning_rate': 0.18520070048284315, 'random_strength': 13, 'bagging_temperature': 0.6081734530303052, 'l2_leaf_reg': 1.4083800996367003e-06, 'border_count': 195}. Best is trial 0 with value: 0.2532592351052029.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:06:55,648] Trial 1 finished with value: 0.2468854681791318 and parameters: {'iterations': 608, 'depth': 6, 'learning_rate': 0.03260059320191419, 'random_strength': 2, 'bagging_temperature': 0.24279569753878447, 'l2_leaf_reg': 6.842089866364824e-08, 'border_count': 195}. Best is trial 1 with value: 0.2468854681791318.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:07:09,151] Trial 2 finished with value: 0.24583362926961425 and parameters: {'iterations': 539, 'depth': 6, 'learning_rate': 0.028162690589138138, 'random_strength': 11, 'bagging_temperature': 0.050025827342240495, 'l2_leaf_reg': 0.0003508655871432115, 'border_count': 47}. Best is trial 2 with value: 0.24583362926961425.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:07:24,155] Trial 3 finished with value: 0.24653614634441565 and parameters: {'iterations': 700, 'depth': 5, 'learning_rate': 0.12404307177575259, 'random_strength': 17, 'bagging_temperature': 0.5879255249988135, 'l2_leaf_reg': 2.267342859759751e-06, 'border_count': 4}. Best is trial 2 with value: 0.24583362926961425.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:07:32,615] Trial 4 finished with value: 0.2451537002403 and parameters: {'iterations': 349, 'depth': 5, 'learning_rate': 0.22962044805035975, 'random_strength': 14, 'bagging_temperature': 0.07036616022408072, 'l2_leaf_reg': 1.6773142840760373, 'border_count': 52}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:07:34,867] Trial 5 finished with value: 0.24560135707648817 and parameters: {'iterations': 148, 'depth': 5, 'learning_rate': 0.06333350726575558, 'random_strength': 16, 'bagging_temperature': 0.07321263504123025, 'l2_leaf_reg': 1.170211152205496, 'border_count': 39}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:07:39,335] Trial 6 finished with value: 0.2549103130967245 and parameters: {'iterations': 141, 'depth': 9, 'learning_rate': 0.017889843246714457, 'random_strength': 3, 'bagging_temperature': 0.01081238885953006, 'l2_leaf_reg': 1.0419633408857867e-05, 'border_count': 116}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:08:03,273] Trial 7 finished with value: 0.24779172801682464 and parameters: {'iterations': 990, 'depth': 6, 'learning_rate': 0.17639561531426187, 'random_strength': 11, 'bagging_temperature': 0.666527085570594, 'l2_leaf_reg': 0.0008861053284055702, 'border_count': 32}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:08:28,714] Trial 8 finished with value: 0.2482384794553969 and parameters: {'iterations': 942, 'depth': 8, 'learning_rate': 0.015461989838096258, 'random_strength': 9, 'bagging_temperature': 0.09375964915582227, 'l2_leaf_reg': 0.00024984207533820487, 'border_count': 14}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:08:52,925] Trial 9 finished with value: 0.24569463180532672 and parameters: {'iterations': 964, 'depth': 5, 'learning_rate': 0.15854277930041993, 'random_strength': 16, 'bagging_temperature': 0.013202612599117558, 'l2_leaf_reg': 0.0777735020485849, 'border_count': 97}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:09:01,771] Trial 10 finished with value: 0.2458469014213683 and parameters: {'iterations': 348, 'depth': 4, 'learning_rate': 0.29823007953264513, 'random_strength': 6, 'bagging_temperature': 0.03513032849518904, 'l2_leaf_reg': 6.307252399798793, 'border_count': 239}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:09:03,495] Trial 11 finished with value: 0.24701786595167713 and parameters: {'iterations': 109, 'depth': 4, 'learning_rate': 0.06490063394803433, 'random_strength': 20, 'bagging_temperature': 0.1527124656313141, 'l2_leaf_reg': 7.864659780828624, 'border_count': 74}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:09:09,809] Trial 12 finished with value: 0.24538329469047734 and parameters: {'iterations': 248, 'depth': 5, 'learning_rate': 0.07780973587657165, 'random_strength': 15, 'bagging_temperature': 0.0541624022424742, 'l2_leaf_reg': 0.08682553619568949, 'border_count': 61}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:09:20,597] Trial 13 finished with value: 0.24555606470357144 and parameters: {'iterations': 343, 'depth': 7, 'learning_rate': 0.0937723243409972, 'random_strength': 14, 'bagging_temperature': 0.029132056914939745, 'l2_leaf_reg': 0.054102396443806364, 'border_count': 147}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:09:35,467] Trial 14 finished with value: 0.2494578777615602 and parameters: {'iterations': 320, 'depth': 10, 'learning_rate': 0.2916396109971572, 'random_strength': 19, 'bagging_temperature': 0.22496280587410653, 'l2_leaf_reg': 0.06259729388557943, 'border_count': 71}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:09:45,555] Trial 15 finished with value: 0.2453358097169227 and parameters: {'iterations': 448, 'depth': 4, 'learning_rate': 0.03659294082512659, 'random_strength': 8, 'bagging_temperature': 0.02222224194223223, 'l2_leaf_reg': 0.004535171059116651, 'border_count': 143}. Best is trial 4 with value: 0.2451537002403.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:09:56,524] Trial 16 finished with value: 0.24501772249425371 and parameters: {'iterations': 477, 'depth': 4, 'learning_rate': 0.03865988030236425, 'random_strength': 7, 'bagging_temperature': 0.021047069450234896, 'l2_leaf_reg': 0.002765756526827921, 'border_count': 152}. Best is trial 16 with value: 0.24501772249425371.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:10:14,097] Trial 17 finished with value: 0.2458281357983696 and parameters: {'iterations': 738, 'depth': 4, 'learning_rate': 0.046097325610316146, 'random_strength': 5, 'bagging_temperature': 0.017914297066968326, 'l2_leaf_reg': 0.007072299047047837, 'border_count': 179}. Best is trial 16 with value: 0.24501772249425371.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:10:28,422] Trial 18 finished with value: 0.24584207539517192 and parameters: {'iterations': 475, 'depth': 7, 'learning_rate': 0.01197557569356818, 'random_strength': 7, 'bagging_temperature': 0.1428397548822792, 'l2_leaf_reg': 0.675207208335522, 'border_count': 101}. Best is trial 16 with value: 0.24501772249425371.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:10:40,683] Trial 19 finished with value: 0.2461169801743201 and parameters: {'iterations': 439, 'depth': 6, 'learning_rate': 0.021749603975446546, 'random_strength': 12, 'bagging_temperature': 0.03920431372057043, 'l2_leaf_reg': 5.351538919359017e-05, 'border_count': 166}. Best is trial 16 with value: 0.24501772249425371.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:10:57,847] Trial 20 finished with value: 0.24680446834164632 and parameters: {'iterations': 646, 'depth': 5, 'learning_rate': 0.10921855974104205, 'random_strength': 9, 'bagging_temperature': 0.02051305649499921, 'l2_leaf_reg': 6.098055746616733e-08, 'border_count': 242}. Best is trial 16 with value: 0.24501772249425371.\n",
      "/tmp/ipykernel_28044/11689719.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "/tmp/ipykernel_28044/11689719.py:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"bagging_temperature\": trial.suggest_loguniform(\n",
      "/tmp/ipykernel_28044/11689719.py:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 10),\n",
      "[I 2024-02-24 16:11:08,226] Trial 21 finished with value: 0.24541419031481918 and parameters: {'iterations': 450, 'depth': 4, 'learning_rate': 0.042080979415455015, 'random_strength': 8, 'bagging_temperature': 0.023291217151657623, 'l2_leaf_reg': 0.004274967347911521, 'border_count': 132}. Best is trial 16 with value: 0.24501772249425371.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0.24501772249425371\n",
      "Best params: {'iterations': 477, 'depth': 4, 'learning_rate': 0.03865988030236425, 'random_strength': 7, 'bagging_temperature': 0.021047069450234896, 'l2_leaf_reg': 0.002765756526827921, 'border_count': 152}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'iterations': 477,\n",
       " 'depth': 4,\n",
       " 'learning_rate': 0.03865988030236425,\n",
       " 'random_strength': 7,\n",
       " 'bagging_temperature': 0.021047069450234896,\n",
       " 'l2_leaf_reg': 0.002765756526827921,\n",
       " 'border_count': 152}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_hyperparameters_catboost(data[columns_base], data[target_binary], columns_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "def train_random_forest_stratified_kfold(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    columns_feature: List[str],\n",
    "    target_binary: List[str],  # この実装では使用しないが、型情報を含める\n",
    "    param: Dict[str, any],\n",
    "    n_splits: int = 5,\n",
    ") -> Tuple[List[RandomForestClassifier], List[float]]:\n",
    "    \"\"\"\n",
    "    Stratified k-foldクロスバリデーションを使用してRandom Forestモデルを訓練する関数。\n",
    "    非均衡データを考慮して、各クラスの割合を保持する。\n",
    "\n",
    "    引数:\n",
    "    - X: pandas DataFrame, 特徴量データ。\n",
    "    - y: pandas Series, 目的変数データ。\n",
    "    - columns_feature: list, 特徴量のカラム名のリスト。\n",
    "    - target_binary: list, 目的変数のカラム名のリスト（この関数では使用しないが、一貫性のために残す）。\n",
    "    - param: dict, Random Forestモデルのパラメータ。\n",
    "    - n_splits: int, クロスバリデーションの分割数。\n",
    "\n",
    "    戻り値:\n",
    "    - Tuple[List[RandomForestClassifier], List[float]]: 訓練済みRandom Forestモデルのリストと各foldのlog lossスコアのリスト。\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    models: List[RandomForestClassifier] = []\n",
    "    scores: List[float] = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = (\n",
    "            X.iloc[train_index][columns_feature],\n",
    "            X.iloc[test_index][columns_feature],\n",
    "        )\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model = RandomForestClassifier(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict_proba(X_test)[:, 1]\n",
    "        score = log_loss(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "        models.append(model)\n",
    "\n",
    "    return models, scores\n",
    "\n",
    "\n",
    "def predict_with_randomforest(\n",
    "    models: List[RandomForestClassifier],\n",
    "    X_test: pd.DataFrame,\n",
    "    columns_feature: List[str],\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    訓練済みRandom Forestモデルのリストを使用してテストデータセットの予測を行う関数。\n",
    "\n",
    "    引数:\n",
    "    - models: List[RandomForestClassifier], 訓練済みRandom Forestモデルのリスト。\n",
    "    - X_test: pandas DataFrame, テストデータセット。\n",
    "    - columns_feature: list, 特徴量のカラム名のリスト。\n",
    "\n",
    "    戻り値:\n",
    "    - np.ndarray: テストデータセットの予測値の平均値。\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    for model in models:\n",
    "        y_pred = model.predict_proba(X_test[columns_feature])[:, 1]\n",
    "        predictions.append(y_pred)\n",
    "\n",
    "    predictions_mean = np.mean(predictions, axis=0)\n",
    "\n",
    "    return predictions_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_random_forest(trial, X, y, columns_feature, n_splits=5):\n",
    "    \"\"\"\n",
    "    Optunaの試行に対する目的関数。Random Forestのハイパーパラメータを探索する。\n",
    "\n",
    "    引数:\n",
    "    - trial: optuna.trial.Trial オブジェクト\n",
    "    - X, y: 訓練データ\n",
    "    - columns_feature: 特徴量のカラム名のリスト\n",
    "    - n_splits: クロスバリデーションの分割数\n",
    "\n",
    "    戻り値:\n",
    "    - 試行の平均log lossスコア\n",
    "    \"\"\"\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 6, 30),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 150),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 60),\n",
    "        \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
    "    }\n",
    "\n",
    "    _, scores = train_random_forest_stratified_kfold(\n",
    "        X, y, columns_feature, [], param, n_splits\n",
    "    )\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def optimize_hyperparameters_random_forest(\n",
    "    X, y, columns_feature, n_trials=100, n_splits=5, timeout=300\n",
    "):\n",
    "    \"\"\"\n",
    "    Optunaを使用してRandom Forestモデルのハイパーパラメータを最適化する。\n",
    "\n",
    "    引数:\n",
    "    - X, y: 訓練データ\n",
    "    - columns_feature: 特徴量のカラム名のリスト\n",
    "    - n_trials: 試行回数の上限\n",
    "    - n_splits: クロスバリデーションの分割数\n",
    "    - timeout: 探索にかける時間の上限（秒）\n",
    "\n",
    "    戻り値:\n",
    "    - 最適なハイパーパラメータの辞書\n",
    "    \"\"\"\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(\n",
    "        lambda trial: objective_random_forest(trial, X, y, columns_feature, n_splits),\n",
    "        n_trials=n_trials,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    print(f\"Best trial: {study.best_trial.value}\")\n",
    "    print(f\"Best params: {study.best_trial.params}\")\n",
    "\n",
    "    return study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-24 16:11:31,170] A new study created in memory with name: no-name-4eb6fb01-2d03-4360-9458-aaafb02474c0\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:12:04,717] Trial 0 finished with value: 0.2459574769546644 and parameters: {'n_estimators': 977, 'max_depth': 25, 'min_samples_split': 20, 'min_samples_leaf': 9, 'max_features': 0.16692787524978514}. Best is trial 0 with value: 0.2459574769546644.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:12:38,734] Trial 1 finished with value: 0.2588058905072192 and parameters: {'n_estimators': 365, 'max_depth': 26, 'min_samples_split': 24, 'min_samples_leaf': 3, 'max_features': 0.9663455769257371}. Best is trial 0 with value: 0.2459574769546644.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:13:01,318] Trial 2 finished with value: 0.24732952380898263 and parameters: {'n_estimators': 881, 'max_depth': 22, 'min_samples_split': 83, 'min_samples_leaf': 45, 'max_features': 0.23940979897851558}. Best is trial 0 with value: 0.2459574769546644.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:13:28,664] Trial 3 finished with value: 0.24564570830903346 and parameters: {'n_estimators': 905, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': 0.24598965635859815}. Best is trial 3 with value: 0.24564570830903346.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:13:59,824] Trial 4 finished with value: 0.24593659174864785 and parameters: {'n_estimators': 865, 'max_depth': 17, 'min_samples_split': 74, 'min_samples_leaf': 44, 'max_features': 0.4490256018023613}. Best is trial 3 with value: 0.24564570830903346.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:14:24,306] Trial 5 finished with value: 0.2462353737212001 and parameters: {'n_estimators': 889, 'max_depth': 15, 'min_samples_split': 56, 'min_samples_leaf': 30, 'max_features': 0.13427525832207265}. Best is trial 3 with value: 0.24564570830903346.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:14:32,878] Trial 6 finished with value: 0.24668357604029115 and parameters: {'n_estimators': 143, 'max_depth': 10, 'min_samples_split': 113, 'min_samples_leaf': 59, 'max_features': 0.9166700949834017}. Best is trial 3 with value: 0.24564570830903346.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:14:51,153] Trial 7 finished with value: 0.2523726248191922 and parameters: {'n_estimators': 212, 'max_depth': 24, 'min_samples_split': 53, 'min_samples_leaf': 5, 'max_features': 0.9543379613378075}. Best is trial 3 with value: 0.24564570830903346.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:14:53,799] Trial 8 finished with value: 0.24865972761284777 and parameters: {'n_estimators': 115, 'max_depth': 20, 'min_samples_split': 135, 'min_samples_leaf': 54, 'max_features': 0.11940441325146298}. Best is trial 3 with value: 0.24564570830903346.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:15:19,383] Trial 9 finished with value: 0.24598841061208826 and parameters: {'n_estimators': 644, 'max_depth': 27, 'min_samples_split': 66, 'min_samples_leaf': 23, 'max_features': 0.39121566221461834}. Best is trial 3 with value: 0.24564570830903346.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:15:51,337] Trial 10 finished with value: 0.24659184211141394 and parameters: {'n_estimators': 647, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 18, 'max_features': 0.6673167034931939}. Best is trial 3 with value: 0.24564570830903346.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:16:18,587] Trial 11 finished with value: 0.2459546294866461 and parameters: {'n_estimators': 765, 'max_depth': 15, 'min_samples_split': 101, 'min_samples_leaf': 43, 'max_features': 0.4800490007914182}. Best is trial 3 with value: 0.24564570830903346.\n",
      "/tmp/ipykernel_28044/142444984.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"max_features\": trial.suggest_uniform(\"max_features\", 0.1, 1.0),\n",
      "[I 2024-02-24 16:16:36,121] Trial 12 finished with value: 0.24597497448230632 and parameters: {'n_estimators': 476, 'max_depth': 12, 'min_samples_split': 38, 'min_samples_leaf': 39, 'max_features': 0.34663076447400304}. Best is trial 3 with value: 0.24564570830903346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0.24564570830903346\n",
      "Best params: {'n_estimators': 905, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': 0.24598965635859815}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 905,\n",
       " 'max_depth': 9,\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 7,\n",
       " 'max_features': 0.24598965635859815}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_hyperparameters_random_forest(data[columns_base], data[target_binary], columns_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo Labeling\n",
    "→一度コードを回して、結果を_pseudo_1, pseudo_2と名前を付けて繰り返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_of_dataframes(dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    3つのDataFrameの平均値を計算して新しいDataFrameとして返す関数。\n",
    "\n",
    "    引数:\n",
    "    - dfs: List[pd.DataFrame], 平均を取るDataFrameのリスト。\n",
    "\n",
    "    戻り値:\n",
    "    - pd.DataFrame: 入力されたDataFrameの平均値を含む新しいDataFrame。\n",
    "    \"\"\"\n",
    "    # 全てのDataFrameを確認して同じ形状（行と列）であることを確認\n",
    "    if not all(dfs[0].shape == df.shape for df in dfs):\n",
    "        raise ValueError(\"All DataFrames must have the same shape.\")\n",
    "    \n",
    "    # DataFrameの平均を計算\n",
    "    df_mean = pd.concat(dfs).groupby(level=0).mean()\n",
    "\n",
    "    return df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aquamind-3o0A5rGC-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
